{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**Process results LRC**\n","This notebook is devoted to process the report files generated by the scripts used for Lexical Relation Classification (LRC) and graded Lexical Entailment (LE). The intend is to generate a dataframe to visualize the results for our models/templates, and compare with SoTA results.\n","\n","To reproduct the results in the paper with other result files, change the variables in a bellow cell that contains:\n","\n","```\n","# folder with all datasets\n","DIR_DATASETS = '/content/datasets/'\n","# folder with the results\n","DIR_RESULTS = '/content/results/'\n","LIST_DIR_RES = [DIR_RESULTS + 'K_H+N/',\n","                DIR_RESULTS + 'BLESS/',\n","                DIR_RESULTS + 'EVALution/',\n","                DIR_RESULTS + 'ROOT09/',\n","                DIR_RESULTS + 'CogALexV/',\n","                DIR_RESULTS + 'hyperlex/results_hyperlex_lexical_split/',\n","                DIR_RESULTS + 'hyperlex/results_hyperlex_random_split/'\n","                ]\n","```\n"],"metadata":{"id":"YUDo5LQQFBYJ"}},{"cell_type":"code","source":["!curl -L -O 'https://raw.github.com/sid-unizar/LRC/main/datasets/datasets.zip'\n","!unzip -o datasets.zip\n","!curl -L -O 'https://raw.github.com/sid-unizar/LRC/main/scripts/scripts.zip'\n","!unzip -o scripts.zip"],"metadata":{"id":"KRZ1VjIG0qFE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# download our results. Due to file size limitations, the results are download from google drive\n","!wget --load-cookies /tmp/cookies.txt \"https://drive.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://drive.google.com/uc?export=download&id=1FzIGKGjbrFU_mdaJhEsCkk3FCYeQL6Ju' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1FzIGKGjbrFU_mdaJhEsCkk3FCYeQL6Ju\" -O results.zip && rm -rf /tmp/cookies.txt\n","!unzip -o results.zip"],"metadata":{"id":"C9BgfOsRED8x"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9av5dK1mVLTm"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","source":["\n","###**LRC task: BLESS, K&H+N, ROOT9, EVALution and CogALexV datasets**\n","\n","Lexical relation classification is the task of predict the lexical relation among two words, such as *(horse,animal) - hyponymy*.\n","\n","####**Models in the literature: baselines**\n","The reported results in the literature for BLESS, K&H+N, ROOT9 and EVALution datasets are precision, recall and f1-score, weighted by the support of the labels. We have collected the results for the following models:\n"," - [LexNET](https://aclanthology.org/W16-5304/) (2016)\n"," - [SphereRE](https://aclanthology.org/P19-1169/) (2019)\n"," - [KEML](https://arxiv.org/abs/2002.10903) (2020)\n"," - [RelBERT](https://arxiv.org/abs/2110.15705) (2021)\n","\n","As far as our knowneldge, these are the last SoTA models.\n","\n","The reported results for CogALexV dataset are different. This dataset comes from the [CogALexV shared task (subtask 2)](https://sites.google.com/site/cogalex2016/home/shared-task) and it is well defined what results must be reported. In this dataset, there are five labels, including \"RANDOM\". The report results are the f1-scores for the four labels that are not the \"RANDOM\" one, and the weighted f1-score by the support of these four labels.\n","\n","####**How the baseline results are collected**\n","We collect the results from the regarding papers.\n","The reported results in RelBERT paper do not contain precision and recall values, only micro and macro f1 average, i.e., the accuracy (micro) and the average of the f1-scores (macro) for all labels, repectively.  We have calculated the weighted f1-scores for RelBERT with the data (table 4) in the paper.\n","\n","\n","####**Our proposal for LRC**\n","We fine-tune a pretrained language model (as BERT or RoBERTa) feeding the model with a verbalization of the two words by means of a template (see in a bellow cell the variables `models2abrev` and `templates2abrev` for the chosen models and templates). We need the following components:\n","1. A pretrained language model (PTLM) $M$ and its token vocabulary $V_M$;\n","2. A training set ${\\cal T}=\\{(\\boldsymbol{w}_i, y_i)\\mid i=1,\\dots n\\}$, where $\\boldsymbol{w}_i = (w^1_i, w^2_i)$ is a pair of words and $y_i\\in Y$ is the label of a lexical relation ($|Y|=K$);\n","3. An injective function from the set of labels to the vocabulary of tokens $V_M$, $v\\colon Y\\to V_M$, called the *mask verbalizer* function;\n","4. A training and a testing template, $T_t$ and $T_e$, used to verbalize $\\boldsymbol{w}_i$.\n","In this context, a template $T$ is a function, $T\\colon V\\times V \\to {\\cal S}$, from pairs of the word vocabulary to the set of sentences where the `CLS`, `SEP` and `MASK` special tokens of the PTLM can appear in the sentence. We denote by $T(\\boldsymbol{w})_{C}$ and $T(\\boldsymbol{w})_{M}$ to the `CLS` and `MASK` tokens in the sentence $T(\\boldsymbol{w})$, respectively.\n","\n","Depending on the template used, we adopt one of the following two training objectives:\n","1. It the train template does not contain the `MASK` token, the classification objective estimates the probability $P(Y=y_j| T_t(\\boldsymbol{w}_i)_C)$;\n","2. It the train template contains the `MASK` token, a mask prediction objective is used to estimate $P(T_t(\\boldsymbol{w}_i)_{M}=t_j| T_t(\\boldsymbol{w}_i) )$, where $t_j \\in V_M$ is any token in the vocabulary of the PTLM.\n","\n","At inference time, for a model trained with a classification objective, we use the testing template $T_e$ to predict the label with\n","$argmax_{y_i\\in Y} \\{P(Y=y_i| T_e(\\boldsymbol{w})_C)\\}$, and for the mask objective, $argmax_{y_i\\in Y} \\{P(T_e(\\boldsymbol{w})_{M}=v(y_j)|T_e(\\boldsymbol{w}))\\}$. For this latter case, note that at inference time, we only use the tokens given by the mask verbalizer function $v$.\n","\n","###**Graded lexical entailment task: Hyperlex dataset**\n","Graded Lexical Entailment (graded LE) is a regression task. It consists of giving a score for the hyperonym relationship between two words $(w_1,w_2)$ expressing a degree that \"*$w_1$ is a hyponym of $w_2$*\". [Hyperlex dataset](https://arxiv.org/pdf/1608.02117v2.pdf) contains pairs of words with a score between 0-6. The score is the median of the ratings given by at least $10$ human annotators to the question \"*To what degree is $w1$ a type of $w2$?*\". The inter-annotator agreement (IAA) was calculated with the average Spearman correlation $\\rho$ of a human rater with the average of all the other raters. It was obtained IAA $\\rho = 0.864$. This is considered an \"*upper bound*\" for the performance of automatic systems. Thus, the task is to give a score for all pairs in the dataset and report the Spearman correlation between the median human annotator scores and the calculated ones.\n","\n","The pairs in the dataset were obtained from WordNet. It also annotated the lexical relation in WordNet and the POS. The pairs are nouns and verbs. The annotated lexical relations are:\n","- `hyp-i` where $1\\le$ `i` $\\le 4$: Using the `isA` hierarchy, `hyp-i` means that the word $w_1$ is an hyponym of degree `i` of the word $w_2$. If `i`$=4$, means a degree greater or equal than $4$.\n","- `r-hyp-i` where $1\\le$ `i` $\\le 4$: Same as `hyp-i`, but $w_1$ is a hyperonym of degree `i` of $w_2$.\n","- `syn`, `ant`, `mero`, `cohyp` and `no-rel`: Words are synonyms, antonyms, meronyms, cohyponyms or non the above relations, respectively.\n","\n","\n","The dataset is provided in three configurations:\n","- *all pairs*: It contains all pairs (2616 pairs). It is usually used by unsupervised models.\n","- *random split*: All pairs are randomly divided in train (1831 pairs), validation (130) and test (655) datasets. To train supervised models.\n","- *lexical split*: It is also splitted into train/val/test datasets, but to avoid lexical memorization, there are not words in common between the train+val and test splits. To force this lexical split, the total pairs are reduced to 1133/85/269.\n","\n","####**Models in the literature: baselines**\n","\n","The visited models are: [HyperVec](https://arxiv.org/pdf/1707.07273.pdf) (2017), [Poincaré embeddings](https://arxiv.org/pdf/1705.08039v2.pdf) (2017), [LEAR](https://aclanthology.org/N18-1103.pdf) (2018), [SDNS](https://arxiv.org/pdf/1805.09355v1.pdf) (2018), [GLEN](https://aclanthology.org/P19-1476.pdf) (2019), [POSTLE](https://aclanthology.org/W19-4310.pdf) (2019), [LexSub](https://aclanthology.org/2020.tacl-1.21.pdf) (2020), [Hierchical-fitting](https://www.sciencedirect.com/science/article/abs/pii/S0950705122006517?via%3Dihub) (2022). All papers can be consulted in the paperswithcode web page about Hyperlex (https://paperswithcode.com/dataset/hyperlex).\n","\n","In a nutshell, all the following models start with a set of non-contextual embeddings, such as Skip-gram, Glove, fastText embeddings (except for HyperVec and Poincaré embeddings that starts to train the embeddings from scratch), and using WordNet, ConceptNet or any other resource, they obtain a set of synonyms, antonyms, hyponyms/hyperonyms pairs of words. The set of pairs is used to train new embeddings by means of a specialized loss function that separate the synonyms/hyponyms from antonyms/hyperonyms. The above models differ in the chosen loss function. Once the model is trained, it is defined a distance function to give the hyponymy degree. The distance functions somehow use the Euclidean distance.\n","\n","- HyperVec: For a vocabulary $V$, it is trained from scratch a word embedding $v_w$, for all $w \\in V$, in a similar fashion as Skip-gramm archictecture with negative sampling training objective (SKNS). The usual loss function in SKNS is modified adding some terms to learn *hierarchical embeddings* based on hyperonym/hyperonym hierarchy. It is needed to know the hyponyms/hyeronyms of the words (or at least of some words) during the training. The pairs of training hyponyms/hyperonyms come from WordNet. The final score is calculated with a distance function, *HyperScore*, that mixes the cosine distance and the norms of the calculated embeddings. The authors claim in the paper that all pairs in the evaluation datasets have been removed from the training dataset.\n","\n","- Poincaré embeddings: Similar to HyerVec, embeddings for words in a vocabulary $V$ are trained from scratch. The embeddings are learned optimizing a loss function depending on an hyperbolic distance. Given a set of unordered pairs $D= \\{\\{u,v\\}\\}$, where one of $u$ and $v$ is an hyperonym of the other, the loss function uses as positive examples the pairs of $D$ and, similar to negative sampling, uses as negative examples $10$ pairs that are not in $D$. The unordered pairs of $D$ are obtained from WordNet. The main goal of the hyperbolic embeddings are to reconstruct the complete hierarchy of a network knowing its hyperonym relationships. For graded LE, the authors define a score function based on the norms of the vectors and the hiperbolic distance.\n","\n","- LEAR: The starting point of this method is a set of non-contextual trained word embeddings. In particular, the authors test with SKNS, CBOW, Glove and fastText embeddings. Inspired by the *Attract-Repel* framework, these embeddings are retrained to capture the hypernoym structure of the concepts giving higher and lower norms to word embeddings situated in higher and lower positions of the hierarchy, while trying that the cosine distance mantains its properties about the similiraty of the words. The embeddings are retrained with sets of Attract ($A$), Repel($R$) and Lexical Entailment ($L$) examples. These examples are pairs of words obtained from WordNet and Roget's thesaurus, where the $A$, $R$ and $L$ pairs are $(u,v)$ where $u$ is a synonym, antonym and hyponym of $v$, respectively. The authors use $1,023,082$ synonyms pair, $380,873$ antonym pairs and $ 1,545,630$ hyponym pairs. To solve the graded LE task, a distance over the trained embeddings is defined based on the difference of the norms of the embeddings. Since the hyperonym degree for a pair of words is calculated with a combination of the cosine and the Euclidean distances of the embeddings, and the loss function during training also contains the distance of the embeddings, it should not be trained with pairs that appear in the hyperlex dataset. But this point it is not discussed in the paper. There are only two papers that mention this problem with the training: GLEN and POSTLE. Both papers show that if the LEAR model don't see any word of the hyperlex dataset while the model is retraining, the results are worse. Note that \"*don't see any word*\" is a stronger condition that \"*don't see any pair*\".\n","\n","- SDNS: This paper is entirely devoted to graded LE. As in LEAR, the inputs of the model are non-contextual embeddings (dependency-based word embeddings, a generalization of the SKNS embeddings). A NN is defined that is trained with the scores in the train dataset, so it is a pure regression model. To obtain better results, the authors add to the NN some weights to incorporate: sparse distributional features, model called SDNS+SDF; and some  additional information (SDNS+SDF+AD) of some positive/negatives examples that are pairs of hyponyms/synomys (positive) and hyperonyms/antonyms (negative). These examples are again obtained from WordNet and are used in pretrain stage to push the vectors to the correct side of the decision boundary. They use $102,586$ positive pairs and $42,958$ negative ones. The authors do not inform if these pairs intersects with the Hyperlex pairs. These pairs are used only to push the embedding to the correct side by means of a hinge loss function in a preliminary training.  \n","\n","- GLEN: This model is inspired by LEAR. The difference is the loss function. It also uses sets of pairs of synonyms, antonyms and hyponyms in the training obtained from WordNet. But in this case the authors carry out tests with models that have seen during the training from the 0% to 100% of the words in Hyperlex. Moreover, they conducted the same experiments for LEAR. As it can be appreciated in the bellow table, the performance of LEAR without seeing the Hyperlex pairs is quite poor. The 0% setup will be similar to train a model in the lexical split configuration.\n","\n","<center>\n","\n","|Setup |0% |10% |30% |50% |70% |90% |100%|\n","|-|-|-|-|-|-|-|-|\n","|LEAR |.174 |.188 |.273 |.438 |.548 |.634 |.682\n","|GLEN |.481 |.485 |.478 |.474 |.506 |.504 |.520\n","\n","</center>\n","\n","- POSTLE: This model is a post-specialization of the LEAR embeddings. Since many words has not been seen during training in LEAR model, only the words in the constraints pairs, the original embedding and the embedding produces by LEAR serves as training examples in a post-training, that learns how the embeddings have changed for seen words and try to mimic these changes in not seen words. Again, the authors make controlled experiments with the number of words seen by LEAR during its training. They used two types of NN to do the post-specialization: Deep feed-forward network (DFFN) and Adversarial network (ADV).\n","\n"],"metadata":{"id":"Sg9HP-HNVQh8"}},{"cell_type":"markdown","source":["\n","</center>\n","\n","![image.png](data:image/png;base64,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)\n","\n","</center>"],"metadata":{"id":"FfuuTlJjOI9O"}},{"cell_type":"markdown","source":["\n","- LexSub: Like other previous models, the inputs in LexSub are non-contextual embeddings (Glove embeddings) and by means of a loss function that takes into account hyponyms, antonymns, synomys, the embeddings are retrained. The authors train LEAR and LexSub with: firstly, less lexical resources than in LEAR's paper; secondly, with the same resources. The latter reported Spearman correlation for LEAR should similar than the correlation reported in LEAR's paper, but it doesn't match at all : $0.533$ vs. $0.686$ (may be due to the initial embeddings?). They report the following results:\n","\n","<center>\n","\n","|     | less resorc. | more resor |\n","|----|----|----|\n","|LEAR|0.1384 | 0.5024|\n","|LexSub| 0.2615 | 0.5327|\n","\n","</center>\n","\n","\n","- Hierarchical-fitting: Finally, HF trains again non-contextual embeddings using lexical pairs from WordNet, but with a novel loss function called by the authors *Hierarchical-fitting*.\n","\n","####**How baseline results are obtained**\n","Except for SDNS model, all of the rest models are unsurpervised. But, as we disccuss above, the unsupervised models see the words in the Hyperlex dataset during training in the form of pair constraints. Thus, these models can be compared with our models trained with the datasets under the Hyperlex random configuration, since $100\\%$ of the words in train/val datasets are in the test dataset. GLEN and POSTLE papers also perform controlled experiments in such a way that during their training, it is not seen any word of the Hyperlex dataset, and they also do the same for the LEAR model. In this case, these models are compared with our models trained with the lexical configuration of Hyperlex. Thus, we get the comparable results with the random split from the regarding papers of all models, and the comparable results with the lexical split from GLEN, POSTLE and SDNS papers.\n","\n","####**Our proposal**\n","An elemental form to give a LE grade is to use the probability $p_{hyp}$ for the the `hyp` label calculated by one of our masked/non-masked models: Greater/lower $p_{hyp}$, more/less sure we are that the pair represent an hyponym. But, let's say that one pair gets the probabilities $p_{hyp}=0.8$ and $p_{syn}=0.15$, an another pair obtains $p_{hyp}=0.8$ and $p_{syn}=0.05$. If we have two pairs with similar probabilities to be an hyponym, but one of them with higher probability to be a synonym, as in the above example, this could be an indication that the first pair should be given a higher *hyponym* degree. We can argue the same, but in the reverse sense, with other labels such as $p_{mero}$ or $p_{norel}$. Thus, if the calculated probabilities really represented the certainty about the lexical relations of two words, we could find a linear combination of the probabilities to obtain a grade for LE, that is, we could give some weights $\\beta_{hyp}, \\beta_{syn},\\beta_{norel}, \\dots$, such that knowing the probabilities of a pair $p_{hyp}, p_{syn},p_{norel}, \\dots$, we would get the hyperonym degree as the value,\n","\n"," $$grade = \\beta_{hyp}p_{hyp}+\\beta_{syn}p_{syn}+\\beta_{norel}p_{norel} + \\dots$$\n","Similarly, we can also use the logits instead of the probabilities to find the weights $\\beta_i$.\n","\n","One simple way to obtain the weights is to use the validation set to fit a linear regression model where the response variable is the `grade` given by the human annotators and the predictors are the logtis produce by the fine-tuned model (we also tried to use the probabilities insted of logits, and the results were quite similar). The estimated regresion coefficients will be our weights.\n","\n","Our method follows:\n","1. We collapse all `hyp-i` and `r-hpy-i` labels to `hyp` and `r-hyp`, respectively. Thus, we train the model/template with $7$ classes: `ant`, `syn`, `hyp`, `r-hyp`, `cohyp`, `mero` and `no_rel`. In early testing, it seemed that having too many labels and too little data was hurting performance.\n","2. A model/template is trained with the train/val datasets as it is described in the paper. It is run $10$ epochs and the final model is the best one on the val dataset regarding the metrics: For non-masked trained models, the metric is the macro average; and for masked models, it is the cross-entropy loss for the masked tokens.\n","3. Post-processing: Once the model/template is trained, it is calculated the predicted logit of the labels for each pair in the val dataset. Thus, we get a matrix $A = [l_i^j]$, where $l_i^j$ is the logit of the $j$-th label for the $i$-th pair in the val dataset. A linear regression model is fitted to predict the vector of the median human ratings $\\boldsymbol{r}_{val}=(r_1,\\dots,r_n)$. So, we obtain a vector of $7$ weights, $\\boldsymbol{\\beta} = (\\beta_1, \\dots, \\beta_7)$, such that,\n","$$\\boldsymbol{r}_{val}\\approx \\boldsymbol{\\beta} \\cdot M$$\n","4. The vector $\\boldsymbol{\\beta}$ is used to predict our rating: Given a pair in the test dataset, it is calculated its vector of logits  $\\boldsymbol{l}=(l_1,\\dots, l_7)$ for the labels; our final rating is $\\boldsymbol{\\beta} \\cdot \\boldsymbol{l}$.\n","\n",""],"metadata":{"id":"iN2gDfbUOShQ"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.metrics import classification_report\n","import glob\n","import ast\n","import re\n","import copy\n","import math\n","from scipy import stats\n","from scipy.stats import spearmanr\n","import seaborn as sns\n"],"metadata":{"id":"Ymw0Mwigmlxq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# folder with all datasets\n","DIR_DATASETS = '/content/datasets/'\n","# folder with the results\n","DIR_RESULTS = '/content/results/'\n","LIST_DIR_RES = [DIR_RESULTS + 'K_H+N/',\n","                DIR_RESULTS + 'BLESS/',\n","                DIR_RESULTS + 'EVALution/',\n","                DIR_RESULTS + 'ROOT09/',\n","                DIR_RESULTS + 'CogALexV/',\n","                DIR_RESULTS + 'hyperlex/results_hyperlex_lexical_split/',\n","                DIR_RESULTS + 'hyperlex/results_hyperlex_random_split/'\n","                ]\n"],"metadata":{"id":"EYI5qYdwpJ4S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["models2abrev = {'bert-large-uncased-whole-word-masking'.lower():'Bert',\n","\t\t\t\t   'roberta-large'.lower():'Roberta',\n","                   'roberta-base'.lower(): 'roberta-base',\n","                   'bert-base-uncased'.lower(): \"bert-base\"\n","\t\t\t\t  }\n","templates2abrev = {\"' <W1> ' <SEP> ' <W2> '\".lower(): 'T1',\n","                  \" <W1> <SEP> <W2> \".lower(): 'T2',\n","                  \"Today, I finally discovered the relation between <W1> and <W2>.\".lower() : 'T3',\n","                  \"Today, I finally discovered the relation between <W1> and <W2>: <W1> is the <LABEL> of <W2>.\".lower() : 'T4',\n","                  \"' <W1> ' <MASK> ' <W2> '\".lower(): 'TM1',\n","                  \" <W1> <MASK> <W2> \".lower(): 'TM2',\n","                  \"Today, I finally discovered the relation between <W1> and <W2>: <W1> is the <MASK> of <W2>.\".lower() : 'TM3',\n","                  }\n","reverse_models2abrev = {v:k for k, v in models2abrev.items()}\n","reverse_templates2abrev = {v:k for k, v in templates2abrev.items()}"],"metadata":{"id":"ziFTtdyEmm81"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**Read txt and csv result files and save results in `dict_res`**\n","`dict_res` is a dictionary of dictionaries with the following structure:\n","- `dict_res[dataset]`: dictionary with all results for a dataset. One from:\n"," ```\n"," ['bless', 'k&h+n','cogalexv','evalution','root09']\n"," ```\n","-`dict_res[dataset][model]`: dictionary with all results for a dataset and model\n","-`dict_res[dataset][model][template]`: dictionary with all results for a dataset, model and template\n","-`dict_res[dataset][model][template]['res']`: list of dataframes from csv files. It should contain $5$ dataframes\n","-`dict_res[dataset][model][template]['report']`:  list of classification reports in txt files. It should contain $5$ reports. The reports are the output dictionaries of the function `classification_report` in the `sklearn.metrics` package, adding:\n","  1. For CogALexV dataset, the weighted f1-score taking into account all labels except the `random` label, if such label exists. Otherwise, the  weighted f1-score is set to $-1$;\n","  2. For Hyperlex dataset, the Spearman correlations with the median of the human annotators and the following calculated scores: the logit of one label; the learned combination of all label logits; the learned combination of all label probs; it is also added these correlations rstricted to nouns and verbs.\n","-`dict_res[dataset][model][template]['mean_report']`: classification report with the means and stds of the $5$ classification reports.\n","\n","Classification reports ( the outputs of `classification_report` function) are also dictionaries of dictionaries:\n","\n"," ```\n"," { 'label1': {'precison':xxx, 'recall':yyy, 'f1-score':zzz, 'correlation':ccc (correlation only for hyperlex dataset)}\n","   ....\n","   'labeln': {'precison':xxx, 'recall':yyy, 'f1-score':zzz}\n","   'accuracy': xxx,\n","   'macro avg': {'precison':xxx, 'recall':yyy, 'f1-score':zzz}\n","   'weighted avg': {'precison':xxx, 'recall':yyy, 'f1-score':zzz}\n","   'weigthed f1-score not random':xxxxx},\n","   //only for hyperlex dataset\n","   'spearman_logit': {'correlation':cccc, 'pvalue':pppp},\n","   'spearman_prob': {'correlation':cccc, 'pvalue':pppp},\n","   'spearman_nouns_logit': {'correlation':cccc, 'pvalue':pppp},\n","   'spearman_nouns_prob': {'correlation':cccc, 'pvalue':pppp},\n","   'spearman_verbs_logit': {'correlation':cccc, 'pvalue':pppp},\n","   'spearman_verbs_prob': {'correlation':cccc, 'pvalue':pppp},\n","   'coefs_logit':{'l0':lll,...        ,'l7':lll, 'intercept':iii},\n","   'coefs_prob':{'l0':lll,...,'l6':lll, 'intercept':iii},\n","```\n","The `dict_res[dataset][model][template]['mean_report']` classification report is created using the $5$ classification reports of one experiment for a dataset/model/template. It contains the same structure that the above classification report adding the std for precision, recall, f1-score values and the accuracy:\n"," ```\n","{ 'label1': {'precison':meanxxx, 'recall':meanyyy, 'f1-score':meanzzz, 'correlation':meancccc, (correlation only for hyperlex dataset)\n","             'std_precison':ssx, 'std_recall':ssy, 'std_f1-score':ssz, 'std_correlation':ssc}\n","   ....\n","   'labeln': {'precison':meanxxx, 'recall':meanyyy, 'f1-score':meanzzz,'correlation':meancccc,\n","              'std_precison':ssx, 'std_recall':ssy, 'std_f1-score':ssz, 'std_correlation':ssc}\n","   'accuracy': meanxxx,\n","   'std_accuracy':sss\n","   'macro avg': {'precison':meanxxx, 'recall':meanyyy, 'f1-score':meanzzz,\n","                 'std_precison':ssx, 'std_recall':ssy, 'std_f1-score':ssz}\n","   'weighted avg': {'precison':meanxxx, 'recall':meanyyy, 'f1-score':meanzzz,\n","                    'std_precison':ssx, 'std_recall':ssy, 'std_f1-score':ssz},\n","   'weigthed f1-score not random':meanxxx,\n","   'std_weigthed f1-score not random':ssxxx,}\n","   //only for hyperlex dataset\n","   'spearman_logit': {'correlation':meancc, 'pvalue':meanpp,'std_correlation':sscc, 'std_pvalue':sspp},\n","   'spearman_prob': {'correlation':meancc, 'pvalue':meanpp,'std_correlation':sscc, 'std_pvalue':sspp},\n","   'spearman_nouns_logit': {'correlation':meancc, 'pvalue':meanpp,'std_correlation':sscc, 'std_pvalue':sspp},\n","   'spearman_verbs_logit': {'correlation':meancc, 'pvalue':meanpp,'std_correlation':sscc, 'std_pvalue':sspp},\n","   'spearman_nouns_prob': {'correlation':meancc, 'pvalue':meanpp,'std_correlation':sscc, 'std_pvalue':sspp},\n","   'spearman_verbs_prob': {'correlation':meancc, 'pvalue':meanpp,'std_correlation':sscc, 'std_pvalue':sspp},\n","   'coefs_logit':{'l0':meanl,...        ,'l7':meanl, 'intercept':meani,\n","                 'std_l0':meanl,...      ,'std_l7':meanl, 'std_intercept':meani},\n","   'coefs_prob':{'l0':meanl,...   ,'l6':meanl, 'intercept':meani,\n","                 'std_l0':meanl,... ,'std_l6':meanl, 'std_intercept':meani}\n","```"],"metadata":{"id":"gKjAjyP-6Doj"}},{"cell_type":"markdown","source":["**Read txt and csv result files from our scripts**.\n","\n","They are read from a list of folders in variable `LIST_DIR_RES`"],"metadata":{"id":"7GMv5n05_Qvp"}},{"cell_type":"code","source":["def calculate_weighted_f1_no_random(dict_report):\n","    '''\n","    Function to calculate the weigthed f1-score by support of all labels\n","    except the random label, if the random label exists. If it not exists\n","    return -1\n","    '''\n","    except_list = ['accuracy', 'macro avg', 'weighted avg', 'std_accuracy', 'random']\n","    weighted_f1_no_random = -1\n","    if 'random' in dict_report.keys():\n","        total_support_no_random = 0\n","        for k in dict_report:\n","            if k.lower() not in except_list:\n","                weighted_f1_no_random += dict_report[k]['support']*dict_report[k]['f1-score']\n","                total_support_no_random += dict_report[k]['support']\n","        weighted_f1_no_random = weighted_f1_no_random/total_support_no_random\n","\n","    return weighted_f1_no_random"],"metadata":{"id":"-bCbRBKOWzPP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def from_spearman_string_to_dict(spearman_string):\n","    spearman_string = re.sub(\"SpearmanrResult\", \"\", spearman_string)\n","    spearman_string = re.sub(\"correlation=\",\"'correlation':\",spearman_string)\n","    spearman_string = re.sub(\"pvalue=\",\"'pvalue':\",spearman_string)\n","    spearman_string = re.sub(\"\\(\", \"{\", spearman_string)\n","    spearman_string = re.sub(\"\\)\", \"}\", spearman_string)\n","    spearman = ast.literal_eval(spearman_string)\n","    return spearman\n","\n","dict_res = {}\n","LABEL_WEIGHTED_NOT_RANDOM = 'weighted f1-score not random'\n","\n","for dir in LIST_DIR_RES:\n","    list_txt_files = glob.glob(dir + \"*.txt\")\n","    list_csv_files = [re.sub(\"txt$\", \"csv\", f) for f in list_txt_files]\n","    for txt_file, csv_file in zip(list_txt_files, list_csv_files):\n","        # read and process txt results file\n","        with open(txt_file) as ftxt:\n","            # line 1: arguments\n","            #print(txt_file)\n","            par = ast.literal_eval(ftxt.readline())\n","            if par['dataset'].lower() == 'hyperlex':\n","                if 'hyperlex/random' in par['train_file']:\n","                    par['dataset'] = 'hyperlex-random'\n","                else:\n","                    par['dataset'] = 'hyperlex-lexical'\n","            # line 2: date\n","            ftxt.readline()\n","            # line 3: report\n","            report = ast.literal_eval(ftxt.readline().lower())\n","            # line 4: hyperlex correlation by label\n","            spearman_string = ftxt.readline()\n","            if spearman_string != '':\n","                spearman = from_spearman_string_to_dict(spearman_string)\n","                # add spearman correlations to report\n","                for label in list(spearman.keys()):\n","                    report[label]['correlation'] = spearman[label]['correlation']\n","            # line 5: overall hyperlex correlation logits\n","            all_spearman_logit_string = ftxt.readline()\n","            # line 6: checkpoint overall hyperlex correlation logits\n","            all_spearman_check_string = ftxt.readline()\n","            # line 7: overall hyperlex correlation probs\n","            all_spearman_prob_string = ftxt.readline()\n","            if all_spearman_logit_string != '':\n","                all_spearman_logit = from_spearman_string_to_dict(all_spearman_logit_string)\n","                all_spearman_check = from_spearman_string_to_dict(all_spearman_check_string)\n","                if (all_spearman_logit['correlation'] != all_spearman_check['correlation']):\n","                    raise Exception('Error checkpoint: Different Spearman correlations in ' + txt_file)\n","                all_spearman_prob = from_spearman_string_to_dict(all_spearman_prob_string)\n","                report['spearman_logit'] = all_spearman_logit\n","                report['spearman_prob'] = all_spearman_prob\n","            # line 8: hyperlex logit coefs\n","            coefs_logit_string = ftxt.readline()\n","            # line 9: hyperlex probs coefs\n","            coefs_prob_string = ftxt.readline()\n","            if coefs_logit_string != '':\n","                coefs_logit = ast.literal_eval(coefs_logit_string)\n","                report['coefs_logit'] = {'l'+str(i):c for i,c in enumerate(coefs_logit['coefs'])}\n","                report['coefs_logit']['intercept'] = coefs_logit['intercept']\n","                coefs_prob = ast.literal_eval(coefs_prob_string)\n","                report['coefs_prob'] = {'l'+str(i):c for i,c in enumerate(coefs_prob['coefs'])}\n","                report['coefs_prob']['intercept'] = coefs_prob['intercept']\n","\n","        # read csv results file\n","        res_csv = pd.read_csv(csv_file, quotechar='\"',keep_default_na=False)\n","        # save csv and txt files to dict_res\n","        a = dict_res.setdefault(par['dataset'].lower(), {})\n","        b = a.setdefault(par['model'].lower(), {})\n","        if \"RandomMask\" in dir:\n","            par['train_templates'][0] = re.sub(\"<mask>\", \"<maskr>\", par['train_templates'][0].lower())\n","        c = b.setdefault(par['train_templates'][0].lower(), {})\n","        d1 = c.setdefault('res',[])\n","        d2 = c.setdefault('report',[])\n","        d1.append(res_csv)\n","        report[LABEL_WEIGHTED_NOT_RANDOM] = calculate_weighted_f1_no_random(report)\n","        if 'spearman_logit' in list(report.keys()):\n","            #distinguir non-masked/masked\n","            col_names = [nc for nc in res_csv.columns]\n","            logit_col_names = filter(lambda x: re.match('.*logit$',x), col_names)\n","            prob_col_names = [re.sub(\"_logit$\", \"\", c) for c in logit_col_names]\n","            X_logit = res_csv.filter(regex=('.*logit$')).to_numpy(copy=True)\n","            X_prob = res_csv[prob_col_names].to_numpy(copy=True)\n","            X_prob = np.delete(X_prob, 5, axis=1)\n","            coefs_l = np.array(coefs_logit['coefs'])\n","            coefs_p = np.array(coefs_prob['coefs'])\n","            grades = res_csv['grade']\n","            if 'hyperlex/random' in par['test_file']:\n","                test_data = pd.read_csv(DIR_DATASETS + 'hyperlex/random/test.tsv',\n","                                        sep = '\\t', header=None)\n","            else:\n","                test_data = pd.read_csv(DIR_DATASETS + 'hyperlex/lexical/test.tsv',\n","                                        sep = '\\t', header=None)\n","\n","            check_spearman_logit = spearmanr(np.dot(X_logit,coefs_l), grades)\n","            check_spearman_prob =  spearmanr(np.dot(X_prob,coefs_p), grades)\n","            # checkpoint: It must be equal (upto thousandths) the Spearman correlations\n","            # calculated in the experiments and the ones calculated in this test\n","            if abs(check_spearman_logit[0] - report['spearman_logit']['correlation']) > 0.001:\n","                raise Exception('Check: Different logit prob from experiments and test: ' + str(check_spearman_logit[0]) + '  ' + str(report['spearman_logit']['correlation']) )\n","            if abs(check_spearman_prob[0] - report['spearman_prob']['correlation']) > 0.001:\n","                raise Exception('Check: Different spearman prob from experiments and test: ' + str(check_spearman_prob[0]) + '  ' + str(report['spearman_prob']['correlation']) )\n","\n","            nouns_idx = test_data.iloc[:,2] == 'N'\n","            verbs_idx = test_data.iloc[:,2] == 'V'\n","            spearman_nouns_logit = spearmanr(np.dot(X_logit[nouns_idx,:],coefs_l), grades[nouns_idx])\n","            spearman_verbs_logit = spearmanr(np.dot(X_logit[verbs_idx,:],coefs_l), grades[verbs_idx])\n","            spearman_nouns_prob = spearmanr(np.dot(X_prob[nouns_idx,:],coefs_p), grades[nouns_idx])\n","            spearman_verbs_prob = spearmanr(np.dot(X_prob[verbs_idx,:],coefs_p), grades[verbs_idx])\n","            report['spearman_nouns_logit'] = from_spearman_string_to_dict(str(spearman_nouns_logit))\n","            report['spearman_verbs_logit'] = from_spearman_string_to_dict(str(spearman_verbs_logit))\n","            report['spearman_nouns_prob'] = from_spearman_string_to_dict(str(spearman_nouns_prob))\n","            report['spearman_verbs_prob'] = from_spearman_string_to_dict(str(spearman_verbs_prob))\n","        d2.append(report)"],"metadata":{"id":"U7EIgN6fmpS5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Add the mean report**.\n","\n"],"metadata":{"id":"IJo1begf_tRZ"}},{"cell_type":"code","source":["def get_value(one_report, keys):\n","    val = one_report\n","    for k in keys:\n","        val = val[k]\n","    return val\n","\n","def get_values(list_reports, keys):\n","    values = np.array([get_value(one_report, keys) for one_report in list_reports])\n","    return values\n","\n","def calculateMeansRec(list_reports, one_dict, past_keys, exclude_keys):\n","    for k in list(one_dict.keys()):\n","        if k not in exclude_keys:\n","            copy_past_keys = copy.deepcopy(past_keys)\n","            copy_past_keys.append(k)\n","            if not isinstance(one_dict[k], dict):\n","                values = get_values(list_reports, copy_past_keys)\n","                one_dict[k]= values.mean()\n","                one_dict['std_'+k] = values.std()\n","            else:\n","                calculateMeansRec(list_reports, one_dict[k], copy_past_keys, exclude_keys)\n","\n","def flat_list_reportsRec(list_reports, one_dict, past_keys, exclude_keys):\n","    for k in list(one_dict.keys()):\n","        if k not in exclude_keys:\n","            copy_past_keys = copy.deepcopy(past_keys)\n","            copy_past_keys.append(k)\n","            if not isinstance(one_dict[k], dict):\n","                values = get_values(list_reports, copy_past_keys)\n","                one_dict[k]= values.tolist()\n","            else:\n","                flat_list_reportsRec(list_reports, one_dict[k], copy_past_keys, exclude_keys)\n","\n","def calculateMeans(list_reports):\n","    '''\n","    Given a list of structurally equal reports, the function\n","    returns a report with the means and stds. A report is a dictionary\n","    whose values are either a dictionary or a real number.\n","    '''\n","    means_report = copy.deepcopy(list_reports[0])\n","    calculateMeansRec(list_reports, means_report, past_keys=[], exclude_keys=['support'])\n","\n","    return means_report\n","\n","def flat_list_reports(list_reports):\n","    '''\n","    Given a list of structurally equal reports, the function returns\n","    a structurally equal report join in a list all values that are real numbers.\n","    A report is a dictionary whose values are either a dictionary or a real number.\n","    '''\n","    flat_report = copy.deepcopy(list_reports[0])\n","    flat_list_reportsRec(list_reports, flat_report, past_keys=[], exclude_keys=['support'])\n","\n","    return flat_report"],"metadata":{"id":"Nz9IJTVwL5Qh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for d in dict_res:\n","    print(d.upper())\n","    for m in dict_res[d]:\n","        print(\" -\".join(['Calculating:', d, m]))\n","        for t in dict_res[d][m]:\n","            list_reports = dict_res[d][m][t]['report']\n","            print(\" -\".join([\"    \", t, templates2abrev[t] ]))\n","            dict_res[d][m][t]['mean_report'] = calculateMeans(list_reports)\n","            dict_res[d][m][t]['flat_reports'] = flat_list_reports(list_reports)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BkbbrrSy-Ekb","outputId":"14816a52-343f-4962-9401-2023e45fe5de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["K&H+N\n","Calculating: -k&h+n -bert-base-uncased\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     - <w1> <sep> <w2>  -T2\n","     - <w1> <mask> <w2>  -TM2\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","Calculating: -k&h+n -bert-large-uncased-whole-word-masking\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     - <w1> <sep> <w2>  -T2\n","     - <w1> <mask> <w2>  -TM2\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","Calculating: -k&h+n -roberta-base\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     - <w1> <sep> <w2>  -T2\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","     - <w1> <mask> <w2>  -TM2\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","Calculating: -k&h+n -roberta-large\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     - <w1> <mask> <w2>  -TM2\n","     - <w1> <sep> <w2>  -T2\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","BLESS\n","Calculating: -bless -roberta-large\n","     - <w1> <mask> <w2>  -TM2\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     - <w1> <sep> <w2>  -T2\n","Calculating: -bless -bert-large-uncased-whole-word-masking\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","     - <w1> <mask> <w2>  -TM2\n","     - <w1> <sep> <w2>  -T2\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","Calculating: -bless -roberta-base\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     - <w1> <mask> <w2>  -TM2\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     - <w1> <sep> <w2>  -T2\n","Calculating: -bless -bert-base-uncased\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     - <w1> <sep> <w2>  -T2\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     - <w1> <mask> <w2>  -TM2\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","EVALUTION\n","Calculating: -evalution -roberta-large\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     - <w1> <sep> <w2>  -T2\n","     - <w1> <mask> <w2>  -TM2\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","Calculating: -evalution -bert-large-uncased-whole-word-masking\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     - <w1> <sep> <w2>  -T2\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     - <w1> <mask> <w2>  -TM2\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","Calculating: -evalution -bert-base-uncased\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     - <w1> <mask> <w2>  -TM2\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     - <w1> <sep> <w2>  -T2\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","Calculating: -evalution -roberta-base\n","     - <w1> <mask> <w2>  -TM2\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","     - <w1> <sep> <w2>  -T2\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","ROOT09\n","Calculating: -root09 -roberta-base\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","     - <w1> <sep> <w2>  -T2\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     - <w1> <mask> <w2>  -TM2\n","Calculating: -root09 -bert-large-uncased-whole-word-masking\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     - <w1> <sep> <w2>  -T2\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     - <w1> <mask> <w2>  -TM2\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","Calculating: -root09 -roberta-large\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     - <w1> <sep> <w2>  -T2\n","     - <w1> <mask> <w2>  -TM2\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","Calculating: -root09 -bert-base-uncased\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     - <w1> <sep> <w2>  -T2\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     - <w1> <mask> <w2>  -TM2\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","COGALEXV\n","Calculating: -cogalexv -roberta-base\n","     - <w1> <sep> <w2>  -T2\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     - <w1> <mask> <w2>  -TM2\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","Calculating: -cogalexv -roberta-large\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     - <w1> <sep> <w2>  -T2\n","     - <w1> <mask> <w2>  -TM2\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","Calculating: -cogalexv -bert-large-uncased-whole-word-masking\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","     - <w1> <sep> <w2>  -T2\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     - <w1> <mask> <w2>  -TM2\n","Calculating: -cogalexv -bert-base-uncased\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <label> of <w2>. -T4\n","     - <w1> <sep> <w2>  -T2\n","     - <w1> <mask> <w2>  -TM2\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","HYPERLEX-LEXICAL\n","Calculating: -hyperlex-lexical -bert-large-uncased-whole-word-masking\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     - <w1> <sep> <w2>  -T2\n","     - <w1> <mask> <w2>  -TM2\n","Calculating: -hyperlex-lexical -roberta-large\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     - <w1> <sep> <w2>  -T2\n","     - <w1> <mask> <w2>  -TM2\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","Calculating: -hyperlex-lexical -roberta-base\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     - <w1> <sep> <w2>  -T2\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     - <w1> <mask> <w2>  -TM2\n","Calculating: -hyperlex-lexical -bert-base-uncased\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     - <w1> <sep> <w2>  -T2\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     - <w1> <mask> <w2>  -TM2\n","HYPERLEX-RANDOM\n","Calculating: -hyperlex-random -bert-base-uncased\n","     - <w1> <sep> <w2>  -T2\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     - <w1> <mask> <w2>  -TM2\n","Calculating: -hyperlex-random -roberta-base\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     - <w1> <sep> <w2>  -T2\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     - <w1> <mask> <w2>  -TM2\n","Calculating: -hyperlex-random -roberta-large\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     - <w1> <mask> <w2>  -TM2\n","     - <w1> <sep> <w2>  -T2\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","Calculating: -hyperlex-random -bert-large-uncased-whole-word-masking\n","     - <w1> <sep> <w2>  -T2\n","     -today, i finally discovered the relation between <w1> and <w2>. -T3\n","     -' <w1> ' <sep> ' <w2> ' -T1\n","     -' <w1> ' <mask> ' <w2> ' -TM1\n","     - <w1> <mask> <w2>  -TM2\n","     -today, i finally discovered the relation between <w1> and <w2>: <w1> is the <mask> of <w2>. -TM3\n"]}]},{"cell_type":"markdown","source":["##**Dictionary with best results**\n","Given the dictionary of results `dict_res`, the following functions create `dict_best`, a python dictionary of dictionaries with the best results for any measure and model/template. It has the structure:\n"," - `dict_best[dataset]`: It is a dictionary with the best results for a dataset. One from:\n"," ```\n"," ['bless', 'k&h+n','cogalexv','evalution','root09']\n"," ```\n"," - `dict_best[dataset]`: It is a dictionary with the best results for a dataset:\n","\n","\n"," ```\n"," {label1: { 'precision': {'best_val': xxxx,\n","                          'best_model':mmmm,\n","                          'best_template':tttt,\n","                          'p-vals': {model: { template_1: pppp,\n","                                              ....\n","                                              template_k:pppp}}},\n","              'recall': {'best_val': xxxx,\n","                         'best_model':mmmm,\n","                         'best_template':tttt,\n","                         'p-vals': {model: { template_1: pppp,\n","                                             ....\n","                                             template_k:pppp}}},\n","              'f1-score': {'best_val': xxxx,\n","                           'best_model':mmmm,\n","                           'best_template':tttt,\n","                           'p-vals': {model: { template_1: pppp,\n","                                                ....\n","                                                template_k:pppp}}},\n","           //only for hyperlex dataset\n","           'correlation': {'best_val': xxxx,\n","                           'best_model':mmmm,\n","                           'best_template':tttt,\n","                           'p-vals': {model: { template_1: pppp,\n","                                                ....\n","                                                template_k:pppp}}}}}                                                \n","  ....\n","  labeln: {same label 1 ...}\n","  'accuracy': {'best_val': xxxx,\n","               'best_model':mmmm,\n","               'best_template':tttt,\n","               'p-vals': {model: { template_1: pppp,\n","                                    ....\n","                                    template_k:pppp}}},\n","  'macro avg':{similar to label 1...},\n","  'weighted avg' :{similar to label 1...},\n","  'weigthed f1-score not random': {similar to accuracy...},\n","   //only for hyperlex dataset\n","   'spearman_logit': {...},\n","   'spearman_prob': {...},\n","   'spearman_nouns_logit': {...},\n","   'spearman_verbs_logit': {...},\n","   'spearman_nouns_prob': {...},\n","   'spearman_verbs_prob': {...},\n","   'coefs_logit':{...},\n","   'coefs_prob':{...}\n"," }\n","```                                      \n","\n","\n","For example,\n","- `dict_best['k&h+n']['ant']['precision']['best_val']` contains the best **mean** precision value among all models and templates for the antonyms label,\n","- `dict_best['k&h+n']['ant']['precision']['best_model']` is the model for which the best precision has been obtained,\n","- and  `dict_best['k&h+n']['ant']['precision']['best_template']` is the template for which the best precision has been obtained.\n","\n","The `dict_best` dictionary also contains the p-values comparing the mean of the best model/template with any other mean for a model/template. It is used a Welch's test to check if there is statistical evidence that the means are different. So, for instance the value in\n","```\n","dict_best['k&h+n']['ant']['precision']['p-vals']['roberta-large'][' <w1> <sep> <w2> ']\n","```\n","contains the p-value to check if the mean of the $5$ precision values of our experiments for antonyms in K&H+N dataset trained with the RoBERTa large model and the template ` <W1> <SEP> <W2> ` is different from the mean of the $5$ precision values obtained with the model/template that has got the best mean precision value."],"metadata":{"id":"Qmxgt2_auQuA"}},{"cell_type":"code","source":["def create_empty(one_dict, empty_best_dict, suffix=''):\n","    for label in one_dict:\n","        empty_best_dict[label+suffix]={}\n","        if isinstance(one_dict[label], dict):\n","            for sublabel in one_dict[label]:\n","                if sublabel != 'support':\n","                    empty_best_dict[label+suffix][sublabel] = {}\n","                    empty_best_dict[label+suffix][sublabel]['best_val'] = -1.0\n","                    empty_best_dict[label+suffix][sublabel]['best_model'] = ''\n","                    empty_best_dict[label+suffix][sublabel]['best_template'] = ''\n","        else:\n","            empty_best_dict[label+suffix]['best_val'] = -1.0\n","            empty_best_dict[label+suffix]['best_model'] = ''\n","            empty_best_dict[label+suffix]['best_template'] = ''\n","\n","def create_empty_best_dict(dict_res, dataset):\n","    m0 = list(dict_res[dataset].keys())[0]\n","    t0 = list(dict_res[dataset][m0].keys())[0]\n","    empty_best_dict = {}\n","    one_dict = dict_res[dataset][m0][t0]['report'][0]\n","    create_empty(one_dict, empty_best_dict)\n","    return empty_best_dict\n","\n","def create (dict_mean_rep, m, t, best_dict_dataset):\n","    for label in dict_mean_rep:\n","        if label in list(best_dict_dataset.keys()):\n","            if isinstance(dict_mean_rep[label], dict):\n","                for sublabel in dict_mean_rep[label]:\n","                    if sublabel in list(best_dict_dataset[label].keys()):\n","                        if dict_mean_rep[label][sublabel] > best_dict_dataset[label][sublabel]['best_val']:\n","                            best_dict_dataset[label][sublabel]['best_val'] = dict_mean_rep[label][sublabel]\n","                            best_dict_dataset[label][sublabel]['best_model'] = m\n","                            best_dict_dataset[label][sublabel]['best_template'] = t\n","            else:\n","                if dict_mean_rep[label] >= best_dict_dataset[label]['best_val']:\n","                    best_dict_dataset[label]['best_val'] = dict_mean_rep[label]\n","                    best_dict_dataset[label]['best_model'] = m\n","                    best_dict_dataset[label]['best_template'] = t\n","\n","def create_best_dict_dataset(dict_res, d):\n","    '''\n","    For a dataset d, create the best dictionary without p-values\n","    '''\n","    best_dict_dataset = create_empty_best_dict(dict_res, d)\n","    for m in dict_res[d]:\n","        for t in dict_res[d][m]:\n","            create(dict_res[d][m][t]['mean_report'], m, t, best_dict_dataset)\n","    return best_dict_dataset\n","\n","def create_pvals_dataset(best_dict, dict_res, dataset, label, sublabel=None):\n","    '''\n","    Given a best_dict without p-values and dictionary of results, label and sublabel\n","    create a dictionary containing the p-values for label and sublabel.\n","    '''\n","    dict_pvals = {}\n","    if sublabel is not None:\n","        mref = best_dict[dataset][label][sublabel]['best_model']\n","        tref = best_dict[dataset][label][sublabel]['best_template']\n","        list_reports = dict_res[dataset][mref][tref]['report']\n","        list_ref_max = [rep[label][sublabel] for rep in list_reports]\n","    else:\n","        mref = best_dict[dataset][label]['best_model']\n","        tref = best_dict[dataset][label]['best_template']\n","        list_reports = dict_res[dataset][mref][tref]['report']\n","        list_ref_max = [rep[label] for rep in list_reports]\n","\n","    for m in dict_res[dataset]:\n","        for t in dict_res[dataset][m]:\n","            if not (m == mref and t == tref):\n","                if sublabel is not None:\n","                    list_reports_others = dict_res[dataset][m][t]['report']\n","                    list_vals = [rep[label][sublabel] for rep in list_reports_others]\n","                else:\n","                    list_reports_others = dict_res[dataset][m][t]['report']\n","                    list_vals = [rep[label] for rep in list_reports_others]\n","\n","                pval = stats.ttest_ind(list_ref_max, list_vals, equal_var=False)[1]\n","                dict_1 = dict_pvals.setdefault(m,{})\n","                dict_1[t] = pval\n","    return dict_pvals\n"],"metadata":{"id":"BkqDiBWlbwau"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_dict_best(dict_res):\n","    '''\n","    Given a dictionary of results, it returns a dictionary of best results\n","    '''\n","    # create best dictionary without p-vals\n","    dict_best_1={}\n","    for d in dict_res:\n","        dict_best_1[d] = create_best_dict_dataset(dict_res, d)\n","\n","    # create best dictionary adding p-vals\n","    dict_best = copy.deepcopy(dict_best_1)\n","    for d in dict_best_1:\n","        for label in dict_best_1[d]:\n","            if 'best_val' in list(dict_best_1[d][label]):\n","                dict_best[d][label]['p-vals'] = create_pvals_dataset(dict_best_1, dict_res, d, label)\n","            else:\n","                for sublabel in dict_best_1[d][label]:\n","                    dict_best[d][label][sublabel]['p-vals'] = create_pvals_dataset(dict_best_1, dict_res, d, label,sublabel)\n","    return dict_best\n","\n","dict_best = create_dict_best(dict_res)"],"metadata":{"id":"DhD5FCWPf_lx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##**CogALexV**\n","To process the CogALexV results. Note that the results for templates `T1`-`T4` correspond to the non-masked models, and templates `TM1`-`TM3`for the masked ones. See the dictionary `templates2abrev` in a cell above."],"metadata":{"id":"74KSBwjbExz5"}},{"cell_type":"code","source":["def get_dataframe_results_cogalexv(dict_res, dataset):\n","    except_list = ['accuracy', 'macro avg', 'weighted avg', 'std_accuracy', 'std_'+LABEL_WEIGHTED_NOT_RANDOM, 'random']\n","    dict_df = {'dataset': [], 'model':[], 'template':[]}\n","    col_tuples=[]\n","    create_tuples = True\n","    for m in dict_res[dataset.lower()]:\n","        for t in dict_res[dataset.lower()][m]:\n","            mean_report = dict_res[dataset.lower()][m][t]['mean_report']\n","            dict_df['dataset'].append(dataset)\n","            dict_df['model'].append(m)\n","            dict_df['template'].append(t)\n","            for k in mean_report:\n","                if k not in except_list:\n","                    l = dict_df.setdefault(k, [])\n","                    if k != LABEL_WEIGHTED_NOT_RANDOM:\n","                        l.append(mean_report[k]['f1-score'])\n","                        if create_tuples:\n","                            col_tuples.append((k,'f1-score'))\n","                    else:\n","                        l.append(mean_report[k])\n","            create_tuples = False\n","    res_df = pd.DataFrame.from_dict(dict_df)\n","    res_df['model'] = res_df['model'].apply(lambda x : models2abrev[x])\n","    res_df['template'] = res_df['template'].apply(lambda x : templates2abrev[x])\n","    multi_row = pd.MultiIndex.from_frame(res_df.iloc[:,1:3],sortorder=None)\n","    col_tuples.append(('all','weighted f1-score'))\n","    col_index = pd.MultiIndex.from_tuples(col_tuples)\n","    res_df = res_df.iloc[:, 3:].copy()\n","    res_df.index = multi_row\n","    res_df.columns = col_index\n","    return res_df\n","\n","def get_dataframe_results_max_min_cogalexv(dict_res, dataset):\n","    except_list = ['accuracy', 'macro avg', 'weighted avg', 'std_accuracy', 'std_'+LABEL_WEIGHTED_NOT_RANDOM, 'random']\n","    dict_df = {'dataset': [], 'model':[], 'template':[]}\n","    col_tuples=[]\n","    create_tuples_labels = True\n","    create_tuples_all = True\n","    for m in dict_res[dataset.lower()]:\n","        for t in dict_res[dataset.lower()][m]:\n","            flat_reports = dict_res[dataset.lower()][m][t]['flat_reports']\n","            dict_df['dataset'].append(dataset)\n","            dict_df['model'].append(m)\n","            dict_df['template'].append(t)\n","            for k in flat_reports:\n","                if k not in except_list:\n","                    l_max = dict_df.setdefault('max-'+ k, [])\n","                    l_min = dict_df.setdefault('min-'+ k, [])\n","                    l_std = dict_df.setdefault('std-'+ k, [])\n","                    if k != LABEL_WEIGHTED_NOT_RANDOM:\n","                        l_max.append(np.array(flat_reports[k]['f1-score']).max())\n","                        l_min.append(np.array(flat_reports[k]['f1-score']).min())\n","                        l_std.append(np.array(flat_reports[k]['f1-score']).std())\n","                        if create_tuples_labels:\n","                            col_tuples.append((k,'max-f1-score'))\n","                            col_tuples.append((k,'min-f1-score'))\n","                            col_tuples.append((k,'std-f1-score'))\n","                    else:\n","                        l_max.append(np.array(flat_reports[k]).max())\n","                        l_min.append(np.array(flat_reports[k]).min())\n","                        l_std.append(np.array(flat_reports[k]).std())\n","                        if create_tuples_all:\n","                            col_tuples.append((k,'max-all'))\n","                            col_tuples.append((k,'min-all'))\n","                            col_tuples.append((k,'std-all'))\n","            create_tuples_labels = False\n","            create_tuples_all = False\n","    res_df = pd.DataFrame.from_dict(dict_df)\n","    res_df['model'] = res_df['model'].apply(lambda x : models2abrev[x])\n","    res_df['template'] = res_df['template'].apply(lambda x : templates2abrev[x])\n","    multi_row = pd.MultiIndex.from_frame(res_df.iloc[:,1:3],sortorder=None)\n","    #col_tuples.append(('all','weighted f1-score'))\n","    col_index = pd.MultiIndex.from_tuples(col_tuples)\n","    res_df = res_df.iloc[:, 3:].copy()\n","    res_df.index = multi_row\n","    res_df.columns = col_index\n","    return res_df"],"metadata":{"id":"moVbJ7meDFOH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_cogalexv_final = get_dataframe_results_cogalexv(dict_res, 'CogALexV')\n","df_cogalexv_final = df_cogalexv_final.sort_index(level=['model','template'])"],"metadata":{"id":"bcUBUbN10gve"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["FILE_SOTAS_COGALEXV = DIR_RESULTS + 'sotas_results_literature/cogalexv_Sotas_RC.txt'\n","df_sotas_cogalexv = pd.read_csv(FILE_SOTAS_COGALEXV, header=[0,1], index_col=[0], skipinitialspace=True)\n","multi_row_tuples = list(zip(['Sota']*df_sotas_cogalexv.shape[0], list(df_sotas_cogalexv.index)))\n","multi_row = pd.MultiIndex.from_tuples(multi_row_tuples)\n","df_sotas_cogalexv.index=multi_row\n","df_res_sotas_cogalexv = pd.concat([df_cogalexv_final,df_sotas_cogalexv])\n","\n","#change column order\n","order1 = {'ant':0,'hyper':1,'part_of':2, 'syn':3, 'all':4}\n","multi_col_list = list(df_res_sotas_cogalexv.columns)\n","multi_col_list.sort(key=lambda x: order1[x[0].lower()])\n","multi_col = pd.MultiIndex.from_tuples(multi_col_list)\n","df_res_sotas_cogalexv = pd.DataFrame(df_res_sotas_cogalexv, columns=multi_col)\n","df_res_sotas_cogalexv"],"metadata":{"id":"k6REijakbq8I","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"3e8e8444-aa15-4b4a-ec68-42e86053a5b3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                            ant     hyper   part_of       syn  \\\n","                       f1-score  f1-score  f1-score  f1-score   \n","model        template                                           \n","Bert         T1        0.770474  0.680452  0.715095  0.563975   \n","             T2        0.768676  0.675201  0.727876  0.528010   \n","             T3        0.788689  0.681299  0.735502  0.565756   \n","             T4        0.119323  0.044062  0.077908  0.000000   \n","             TM1       0.798389  0.682221  0.745577  0.584719   \n","             TM2       0.781551  0.687806  0.742477  0.560105   \n","             TM3       0.778578  0.682159  0.742217  0.562916   \n","Roberta      T1        0.872557  0.703143  0.752050  0.603664   \n","             T2        0.863005  0.681854  0.744814  0.583635   \n","             T3        0.883666  0.718214  0.784419  0.628822   \n","             T4        0.236519  0.003704  0.164753  0.084852   \n","             TM1       0.879658  0.708541  0.772999  0.598834   \n","             TM2       0.870704  0.723055  0.787251  0.621032   \n","             TM3       0.870720  0.717585  0.787410  0.615927   \n","bert-base    T1        0.553600  0.590749  0.657085  0.361485   \n","             T2        0.528956  0.544102  0.610356  0.277698   \n","             T3        0.565381  0.605407  0.683618  0.374989   \n","             T4        0.081221  0.000000  0.101444  0.006059   \n","             TM1       0.644556  0.625010  0.707385  0.431301   \n","             TM2       0.570093  0.621784  0.685384  0.393129   \n","             TM3       0.635968  0.648195  0.720730  0.430058   \n","roberta-base T1        0.805550  0.677129  0.732487  0.569636   \n","             T2        0.782981  0.651829  0.692575  0.536492   \n","             T3        0.819614  0.675679  0.731475  0.576918   \n","             T4        0.026575  0.000000  0.102297  0.092189   \n","             TM1       0.809081  0.678229  0.743181  0.560552   \n","             TM2       0.801448  0.673224  0.742456  0.555826   \n","             TM3       0.814963  0.679439  0.729843  0.560999   \n","Sota         LexNET    0.425000  0.526000  0.493000  0.297000   \n","             SphereRE  0.479000  0.538000  0.539000  0.286000   \n","             KEML      0.492000  0.547000  0.652000  0.292000   \n","             RelBert   0.794000  0.616000  0.702000  0.505000   \n","\n","                                    all  \n","                      weighted f1-score  \n","model        template                    \n","Bert         T1                0.690274  \n","             T2                0.683411  \n","             T3                0.700158  \n","             T4                0.063480  \n","             TM1               0.708948  \n","             TM2               0.700283  \n","             TM3               0.698097  \n","Roberta      T1                0.742749  \n","             T2                0.727845  \n","             T3                0.761832  \n","             T4                0.118573  \n","             TM1               0.749557  \n","             TM2               0.758490  \n","             TM3               0.755786  \n","bert-base    T1                0.546293  \n","             T2                0.498959  \n","             T3                0.562078  \n","             T4                0.043619  \n","             TM1               0.607497  \n","             TM2               0.572578  \n","             TM3               0.614543  \n","roberta-base T1                0.704082  \n","             T2                0.675341  \n","             T3                0.709073  \n","             T4                0.044251  \n","             TM1               0.705707  \n","             TM2               0.700768  \n","             TM3               0.705455  \n","Sota         LexNET            0.445000  \n","             SphereRE          0.471000  \n","             KEML              0.500000  \n","             RelBert           0.664000  "],"text/html":["\n","  <div id=\"df-4de5f042-4149-4f66-8503-c9ead76e15c1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>ant</th>\n","      <th>hyper</th>\n","      <th>part_of</th>\n","      <th>syn</th>\n","      <th>all</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>f1-score</th>\n","      <th>f1-score</th>\n","      <th>f1-score</th>\n","      <th>f1-score</th>\n","      <th>weighted f1-score</th>\n","    </tr>\n","    <tr>\n","      <th>model</th>\n","      <th>template</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"7\" valign=\"top\">Bert</th>\n","      <th>T1</th>\n","      <td>0.770474</td>\n","      <td>0.680452</td>\n","      <td>0.715095</td>\n","      <td>0.563975</td>\n","      <td>0.690274</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.768676</td>\n","      <td>0.675201</td>\n","      <td>0.727876</td>\n","      <td>0.528010</td>\n","      <td>0.683411</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.788689</td>\n","      <td>0.681299</td>\n","      <td>0.735502</td>\n","      <td>0.565756</td>\n","      <td>0.700158</td>\n","    </tr>\n","    <tr>\n","      <th>T4</th>\n","      <td>0.119323</td>\n","      <td>0.044062</td>\n","      <td>0.077908</td>\n","      <td>0.000000</td>\n","      <td>0.063480</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.798389</td>\n","      <td>0.682221</td>\n","      <td>0.745577</td>\n","      <td>0.584719</td>\n","      <td>0.708948</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.781551</td>\n","      <td>0.687806</td>\n","      <td>0.742477</td>\n","      <td>0.560105</td>\n","      <td>0.700283</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.778578</td>\n","      <td>0.682159</td>\n","      <td>0.742217</td>\n","      <td>0.562916</td>\n","      <td>0.698097</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"7\" valign=\"top\">Roberta</th>\n","      <th>T1</th>\n","      <td>0.872557</td>\n","      <td>0.703143</td>\n","      <td>0.752050</td>\n","      <td>0.603664</td>\n","      <td>0.742749</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.863005</td>\n","      <td>0.681854</td>\n","      <td>0.744814</td>\n","      <td>0.583635</td>\n","      <td>0.727845</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.883666</td>\n","      <td>0.718214</td>\n","      <td>0.784419</td>\n","      <td>0.628822</td>\n","      <td>0.761832</td>\n","    </tr>\n","    <tr>\n","      <th>T4</th>\n","      <td>0.236519</td>\n","      <td>0.003704</td>\n","      <td>0.164753</td>\n","      <td>0.084852</td>\n","      <td>0.118573</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.879658</td>\n","      <td>0.708541</td>\n","      <td>0.772999</td>\n","      <td>0.598834</td>\n","      <td>0.749557</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.870704</td>\n","      <td>0.723055</td>\n","      <td>0.787251</td>\n","      <td>0.621032</td>\n","      <td>0.758490</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.870720</td>\n","      <td>0.717585</td>\n","      <td>0.787410</td>\n","      <td>0.615927</td>\n","      <td>0.755786</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"7\" valign=\"top\">bert-base</th>\n","      <th>T1</th>\n","      <td>0.553600</td>\n","      <td>0.590749</td>\n","      <td>0.657085</td>\n","      <td>0.361485</td>\n","      <td>0.546293</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.528956</td>\n","      <td>0.544102</td>\n","      <td>0.610356</td>\n","      <td>0.277698</td>\n","      <td>0.498959</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.565381</td>\n","      <td>0.605407</td>\n","      <td>0.683618</td>\n","      <td>0.374989</td>\n","      <td>0.562078</td>\n","    </tr>\n","    <tr>\n","      <th>T4</th>\n","      <td>0.081221</td>\n","      <td>0.000000</td>\n","      <td>0.101444</td>\n","      <td>0.006059</td>\n","      <td>0.043619</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.644556</td>\n","      <td>0.625010</td>\n","      <td>0.707385</td>\n","      <td>0.431301</td>\n","      <td>0.607497</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.570093</td>\n","      <td>0.621784</td>\n","      <td>0.685384</td>\n","      <td>0.393129</td>\n","      <td>0.572578</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.635968</td>\n","      <td>0.648195</td>\n","      <td>0.720730</td>\n","      <td>0.430058</td>\n","      <td>0.614543</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"7\" valign=\"top\">roberta-base</th>\n","      <th>T1</th>\n","      <td>0.805550</td>\n","      <td>0.677129</td>\n","      <td>0.732487</td>\n","      <td>0.569636</td>\n","      <td>0.704082</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.782981</td>\n","      <td>0.651829</td>\n","      <td>0.692575</td>\n","      <td>0.536492</td>\n","      <td>0.675341</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.819614</td>\n","      <td>0.675679</td>\n","      <td>0.731475</td>\n","      <td>0.576918</td>\n","      <td>0.709073</td>\n","    </tr>\n","    <tr>\n","      <th>T4</th>\n","      <td>0.026575</td>\n","      <td>0.000000</td>\n","      <td>0.102297</td>\n","      <td>0.092189</td>\n","      <td>0.044251</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.809081</td>\n","      <td>0.678229</td>\n","      <td>0.743181</td>\n","      <td>0.560552</td>\n","      <td>0.705707</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.801448</td>\n","      <td>0.673224</td>\n","      <td>0.742456</td>\n","      <td>0.555826</td>\n","      <td>0.700768</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.814963</td>\n","      <td>0.679439</td>\n","      <td>0.729843</td>\n","      <td>0.560999</td>\n","      <td>0.705455</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">Sota</th>\n","      <th>LexNET</th>\n","      <td>0.425000</td>\n","      <td>0.526000</td>\n","      <td>0.493000</td>\n","      <td>0.297000</td>\n","      <td>0.445000</td>\n","    </tr>\n","    <tr>\n","      <th>SphereRE</th>\n","      <td>0.479000</td>\n","      <td>0.538000</td>\n","      <td>0.539000</td>\n","      <td>0.286000</td>\n","      <td>0.471000</td>\n","    </tr>\n","    <tr>\n","      <th>KEML</th>\n","      <td>0.492000</td>\n","      <td>0.547000</td>\n","      <td>0.652000</td>\n","      <td>0.292000</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>RelBert</th>\n","      <td>0.794000</td>\n","      <td>0.616000</td>\n","      <td>0.702000</td>\n","      <td>0.505000</td>\n","      <td>0.664000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4de5f042-4149-4f66-8503-c9ead76e15c1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4de5f042-4149-4f66-8503-c9ead76e15c1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4de5f042-4149-4f66-8503-c9ead76e15c1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["df_cogalexv_max_min_final = get_dataframe_results_max_min_cogalexv(dict_res, 'CogALexV')\n","df_cogalexv_max_min_final = df_cogalexv_max_min_final.sort_index(level=['model','template'])\n","df_cogalexv_max_min_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"g5mp3eKfVGC_","outputId":"64892933-aacc-4495-f977-ae40169e89c5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                               ant                                  hyper  \\\n","                      max-f1-score min-f1-score std-f1-score max-f1-score   \n","model        template                                                       \n","Bert         T1           0.788540     0.754986     0.011111     0.693042   \n","             T2           0.784203     0.752044     0.012690     0.697095   \n","             T3           0.797122     0.776406     0.007539     0.687879   \n","             T4           0.220661     0.000000     0.099786     0.138219   \n","             TM1          0.805556     0.789250     0.006764     0.694891   \n","             TM2          0.797768     0.765537     0.011892     0.696296   \n","             TM3          0.812589     0.763948     0.017595     0.691771   \n","Roberta      T1           0.890469     0.836524     0.019903     0.735724   \n","             T2           0.905109     0.830137     0.024201     0.725067   \n","             T3           0.896067     0.874644     0.007488     0.734211   \n","             T4           0.523985     0.000000     0.181011     0.018519   \n","             TM1          0.888252     0.863572     0.008898     0.714286   \n","             TM2          0.886657     0.862119     0.008853     0.732432   \n","             TM3          0.879536     0.861671     0.007292     0.724965   \n","bert-base    T1           0.563415     0.543478     0.006968     0.598854   \n","             T2           0.550336     0.508906     0.015003     0.560647   \n","             T3           0.580132     0.539642     0.015095     0.615385   \n","             T4           0.189547     0.000000     0.077721     0.000000   \n","             TM1          0.655172     0.631136     0.008916     0.634538   \n","             TM2          0.593123     0.550512     0.016477     0.631436   \n","             TM3          0.653061     0.615836     0.012420     0.656381   \n","roberta-base T1           0.821683     0.789400     0.011938     0.703601   \n","             T2           0.802837     0.761134     0.013577     0.673130   \n","             T3           0.832386     0.810512     0.008108     0.701513   \n","             T4           0.080925     0.000000     0.033812     0.000000   \n","             TM1          0.826896     0.792614     0.012819     0.690667   \n","             TM2          0.813097     0.787535     0.008702     0.686192   \n","             TM3          0.827586     0.803443     0.009157     0.698727   \n","\n","                                                     part_of               \\\n","                      min-f1-score std-f1-score max-f1-score min-f1-score   \n","model        template                                                       \n","Bert         T1           0.662953     0.011157     0.744292     0.676724   \n","             T2           0.642336     0.021950     0.749474     0.702820   \n","             T3           0.675250     0.005329     0.740566     0.729670   \n","             T4           0.000000     0.056808     0.289157     0.000000   \n","             TM1          0.670537     0.008846     0.758772     0.726437   \n","             TM2          0.671576     0.008973     0.748837     0.740088   \n","             TM3          0.668648     0.007784     0.766520     0.724221   \n","Roberta      T1           0.662050     0.024285     0.764835     0.730361   \n","             T2           0.643836     0.030330     0.777778     0.718182   \n","             T3           0.699454     0.013026     0.798144     0.769231   \n","             T4           0.000000     0.007407     0.321878     0.100045   \n","             TM1          0.697274     0.006072     0.789238     0.749415   \n","             TM2          0.713092     0.007152     0.828054     0.757991   \n","             TM3          0.709497     0.005322     0.823799     0.771930   \n","bert-base    T1           0.574386     0.008526     0.684564     0.634573   \n","             T2           0.522667     0.012943     0.628450     0.586207   \n","             T3           0.598930     0.005760     0.711111     0.648188   \n","             T4           0.000000     0.000000     0.138322     0.031250   \n","             TM1          0.620321     0.005249     0.716895     0.694690   \n","             TM2          0.616231     0.006214     0.692810     0.672566   \n","             TM3          0.642150     0.006246     0.734066     0.703540   \n","roberta-base T1           0.651748     0.016891     0.746137     0.707158   \n","             T2           0.623881     0.018566     0.723769     0.669663   \n","             T3           0.657895     0.014903     0.745098     0.720358   \n","             T4           0.000000     0.000000     0.173318     0.013363   \n","             TM1          0.658263     0.012111     0.751131     0.738197   \n","             TM2          0.660140     0.009889     0.747204     0.733485   \n","             TM3          0.658192     0.013215     0.745098     0.714588   \n","\n","                                            syn                            \\\n","                      std-f1-score max-f1-score min-f1-score std-f1-score   \n","model        template                                                       \n","Bert         T1           0.022261     0.597895     0.526807     0.023576   \n","             T2           0.016871     0.545024     0.502392     0.016426   \n","             T3           0.003565     0.603306     0.505593     0.033071   \n","             T4           0.112552     0.000000     0.000000     0.000000   \n","             TM1          0.011805     0.616034     0.569593     0.016333   \n","             TM2          0.003289     0.586777     0.541761     0.015535   \n","             TM3          0.014963     0.587196     0.552995     0.012320   \n","Roberta      T1           0.012531     0.622407     0.579775     0.015731   \n","             T2           0.020200     0.600877     0.546535     0.021163   \n","             T3           0.009349     0.641822     0.600000     0.014810   \n","             T4           0.080385     0.222222     0.008299     0.090397   \n","             TM1          0.015826     0.646091     0.574380     0.025951   \n","             TM2          0.023326     0.639004     0.605932     0.013809   \n","             TM3          0.018926     0.639130     0.596950     0.015386   \n","bert-base    T1           0.018373     0.419048     0.309859     0.040520   \n","             T2           0.016889     0.310273     0.250000     0.022780   \n","             T3           0.023506     0.402464     0.343249     0.023584   \n","             T4           0.036721     0.022388     0.000000     0.008720   \n","             TM1          0.009327     0.446352     0.410596     0.014221   \n","             TM2          0.008676     0.409186     0.370203     0.013042   \n","             TM3          0.010298     0.437500     0.424116     0.004361   \n","roberta-base T1           0.013355     0.597849     0.545842     0.017984   \n","             T2           0.023624     0.561404     0.513131     0.015437   \n","             T3           0.010589     0.605578     0.564756     0.015188   \n","             T4           0.051620     0.181244     0.000000     0.059557   \n","             TM1          0.004568     0.593220     0.528455     0.026487   \n","             TM2          0.004731     0.570815     0.543568     0.009878   \n","             TM3          0.011037     0.581443     0.533613     0.016158   \n","\n","                      weighted f1-score not random                      \n","                                           max-all   min-all   std-all  \n","model        template                                                   \n","Bert         T1                           0.704759  0.677656  0.008870  \n","             T2                           0.700384  0.662954  0.014347  \n","             T3                           0.712255  0.687849  0.008922  \n","             T4                           0.117960 -0.000833  0.047692  \n","             TM1                          0.717220  0.702957  0.004713  \n","             TM2                          0.706387  0.692681  0.004527  \n","             TM3                          0.714033  0.687597  0.009353  \n","Roberta      T1                           0.760516  0.712373  0.017246  \n","             T2                           0.763227  0.701886  0.021401  \n","             T3                           0.771118  0.754640  0.005476  \n","             T4                           0.259748  0.019451  0.080573  \n","             TM1                          0.764715  0.742481  0.007857  \n","             TM2                          0.766471  0.750697  0.005891  \n","             TM3                          0.766335  0.746589  0.007618  \n","bert-base    T1                           0.563546  0.530574  0.011261  \n","             T2                           0.515928  0.476910  0.015441  \n","             T3                           0.575422  0.551220  0.007997  \n","             T4                           0.072364  0.018762  0.020278  \n","             TM1                          0.616324  0.596140  0.006960  \n","             TM2                          0.577598  0.564060  0.004835  \n","             TM3                          0.620461  0.607989  0.005315  \n","roberta-base T1                           0.723223  0.698204  0.009664  \n","             T2                           0.694423  0.662422  0.015018  \n","             T3                           0.721743  0.700958  0.007519  \n","             T4                           0.069518  0.017802  0.020213  \n","             TM1                          0.722879  0.690554  0.011276  \n","             TM2                          0.710174  0.693918  0.005279  \n","             TM3                          0.712762  0.692731  0.006741  "],"text/html":["\n","  <div id=\"df-a521ab7c-5ffc-424f-bf65-9165772633b1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th colspan=\"3\" halign=\"left\">ant</th>\n","      <th colspan=\"3\" halign=\"left\">hyper</th>\n","      <th colspan=\"3\" halign=\"left\">part_of</th>\n","      <th colspan=\"3\" halign=\"left\">syn</th>\n","      <th colspan=\"3\" halign=\"left\">weighted f1-score not random</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>max-f1-score</th>\n","      <th>min-f1-score</th>\n","      <th>std-f1-score</th>\n","      <th>max-f1-score</th>\n","      <th>min-f1-score</th>\n","      <th>std-f1-score</th>\n","      <th>max-f1-score</th>\n","      <th>min-f1-score</th>\n","      <th>std-f1-score</th>\n","      <th>max-f1-score</th>\n","      <th>min-f1-score</th>\n","      <th>std-f1-score</th>\n","      <th>max-all</th>\n","      <th>min-all</th>\n","      <th>std-all</th>\n","    </tr>\n","    <tr>\n","      <th>model</th>\n","      <th>template</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"7\" valign=\"top\">Bert</th>\n","      <th>T1</th>\n","      <td>0.788540</td>\n","      <td>0.754986</td>\n","      <td>0.011111</td>\n","      <td>0.693042</td>\n","      <td>0.662953</td>\n","      <td>0.011157</td>\n","      <td>0.744292</td>\n","      <td>0.676724</td>\n","      <td>0.022261</td>\n","      <td>0.597895</td>\n","      <td>0.526807</td>\n","      <td>0.023576</td>\n","      <td>0.704759</td>\n","      <td>0.677656</td>\n","      <td>0.008870</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.784203</td>\n","      <td>0.752044</td>\n","      <td>0.012690</td>\n","      <td>0.697095</td>\n","      <td>0.642336</td>\n","      <td>0.021950</td>\n","      <td>0.749474</td>\n","      <td>0.702820</td>\n","      <td>0.016871</td>\n","      <td>0.545024</td>\n","      <td>0.502392</td>\n","      <td>0.016426</td>\n","      <td>0.700384</td>\n","      <td>0.662954</td>\n","      <td>0.014347</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.797122</td>\n","      <td>0.776406</td>\n","      <td>0.007539</td>\n","      <td>0.687879</td>\n","      <td>0.675250</td>\n","      <td>0.005329</td>\n","      <td>0.740566</td>\n","      <td>0.729670</td>\n","      <td>0.003565</td>\n","      <td>0.603306</td>\n","      <td>0.505593</td>\n","      <td>0.033071</td>\n","      <td>0.712255</td>\n","      <td>0.687849</td>\n","      <td>0.008922</td>\n","    </tr>\n","    <tr>\n","      <th>T4</th>\n","      <td>0.220661</td>\n","      <td>0.000000</td>\n","      <td>0.099786</td>\n","      <td>0.138219</td>\n","      <td>0.000000</td>\n","      <td>0.056808</td>\n","      <td>0.289157</td>\n","      <td>0.000000</td>\n","      <td>0.112552</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.117960</td>\n","      <td>-0.000833</td>\n","      <td>0.047692</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.805556</td>\n","      <td>0.789250</td>\n","      <td>0.006764</td>\n","      <td>0.694891</td>\n","      <td>0.670537</td>\n","      <td>0.008846</td>\n","      <td>0.758772</td>\n","      <td>0.726437</td>\n","      <td>0.011805</td>\n","      <td>0.616034</td>\n","      <td>0.569593</td>\n","      <td>0.016333</td>\n","      <td>0.717220</td>\n","      <td>0.702957</td>\n","      <td>0.004713</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.797768</td>\n","      <td>0.765537</td>\n","      <td>0.011892</td>\n","      <td>0.696296</td>\n","      <td>0.671576</td>\n","      <td>0.008973</td>\n","      <td>0.748837</td>\n","      <td>0.740088</td>\n","      <td>0.003289</td>\n","      <td>0.586777</td>\n","      <td>0.541761</td>\n","      <td>0.015535</td>\n","      <td>0.706387</td>\n","      <td>0.692681</td>\n","      <td>0.004527</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.812589</td>\n","      <td>0.763948</td>\n","      <td>0.017595</td>\n","      <td>0.691771</td>\n","      <td>0.668648</td>\n","      <td>0.007784</td>\n","      <td>0.766520</td>\n","      <td>0.724221</td>\n","      <td>0.014963</td>\n","      <td>0.587196</td>\n","      <td>0.552995</td>\n","      <td>0.012320</td>\n","      <td>0.714033</td>\n","      <td>0.687597</td>\n","      <td>0.009353</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"7\" valign=\"top\">Roberta</th>\n","      <th>T1</th>\n","      <td>0.890469</td>\n","      <td>0.836524</td>\n","      <td>0.019903</td>\n","      <td>0.735724</td>\n","      <td>0.662050</td>\n","      <td>0.024285</td>\n","      <td>0.764835</td>\n","      <td>0.730361</td>\n","      <td>0.012531</td>\n","      <td>0.622407</td>\n","      <td>0.579775</td>\n","      <td>0.015731</td>\n","      <td>0.760516</td>\n","      <td>0.712373</td>\n","      <td>0.017246</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.905109</td>\n","      <td>0.830137</td>\n","      <td>0.024201</td>\n","      <td>0.725067</td>\n","      <td>0.643836</td>\n","      <td>0.030330</td>\n","      <td>0.777778</td>\n","      <td>0.718182</td>\n","      <td>0.020200</td>\n","      <td>0.600877</td>\n","      <td>0.546535</td>\n","      <td>0.021163</td>\n","      <td>0.763227</td>\n","      <td>0.701886</td>\n","      <td>0.021401</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.896067</td>\n","      <td>0.874644</td>\n","      <td>0.007488</td>\n","      <td>0.734211</td>\n","      <td>0.699454</td>\n","      <td>0.013026</td>\n","      <td>0.798144</td>\n","      <td>0.769231</td>\n","      <td>0.009349</td>\n","      <td>0.641822</td>\n","      <td>0.600000</td>\n","      <td>0.014810</td>\n","      <td>0.771118</td>\n","      <td>0.754640</td>\n","      <td>0.005476</td>\n","    </tr>\n","    <tr>\n","      <th>T4</th>\n","      <td>0.523985</td>\n","      <td>0.000000</td>\n","      <td>0.181011</td>\n","      <td>0.018519</td>\n","      <td>0.000000</td>\n","      <td>0.007407</td>\n","      <td>0.321878</td>\n","      <td>0.100045</td>\n","      <td>0.080385</td>\n","      <td>0.222222</td>\n","      <td>0.008299</td>\n","      <td>0.090397</td>\n","      <td>0.259748</td>\n","      <td>0.019451</td>\n","      <td>0.080573</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.888252</td>\n","      <td>0.863572</td>\n","      <td>0.008898</td>\n","      <td>0.714286</td>\n","      <td>0.697274</td>\n","      <td>0.006072</td>\n","      <td>0.789238</td>\n","      <td>0.749415</td>\n","      <td>0.015826</td>\n","      <td>0.646091</td>\n","      <td>0.574380</td>\n","      <td>0.025951</td>\n","      <td>0.764715</td>\n","      <td>0.742481</td>\n","      <td>0.007857</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.886657</td>\n","      <td>0.862119</td>\n","      <td>0.008853</td>\n","      <td>0.732432</td>\n","      <td>0.713092</td>\n","      <td>0.007152</td>\n","      <td>0.828054</td>\n","      <td>0.757991</td>\n","      <td>0.023326</td>\n","      <td>0.639004</td>\n","      <td>0.605932</td>\n","      <td>0.013809</td>\n","      <td>0.766471</td>\n","      <td>0.750697</td>\n","      <td>0.005891</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.879536</td>\n","      <td>0.861671</td>\n","      <td>0.007292</td>\n","      <td>0.724965</td>\n","      <td>0.709497</td>\n","      <td>0.005322</td>\n","      <td>0.823799</td>\n","      <td>0.771930</td>\n","      <td>0.018926</td>\n","      <td>0.639130</td>\n","      <td>0.596950</td>\n","      <td>0.015386</td>\n","      <td>0.766335</td>\n","      <td>0.746589</td>\n","      <td>0.007618</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"7\" valign=\"top\">bert-base</th>\n","      <th>T1</th>\n","      <td>0.563415</td>\n","      <td>0.543478</td>\n","      <td>0.006968</td>\n","      <td>0.598854</td>\n","      <td>0.574386</td>\n","      <td>0.008526</td>\n","      <td>0.684564</td>\n","      <td>0.634573</td>\n","      <td>0.018373</td>\n","      <td>0.419048</td>\n","      <td>0.309859</td>\n","      <td>0.040520</td>\n","      <td>0.563546</td>\n","      <td>0.530574</td>\n","      <td>0.011261</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.550336</td>\n","      <td>0.508906</td>\n","      <td>0.015003</td>\n","      <td>0.560647</td>\n","      <td>0.522667</td>\n","      <td>0.012943</td>\n","      <td>0.628450</td>\n","      <td>0.586207</td>\n","      <td>0.016889</td>\n","      <td>0.310273</td>\n","      <td>0.250000</td>\n","      <td>0.022780</td>\n","      <td>0.515928</td>\n","      <td>0.476910</td>\n","      <td>0.015441</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.580132</td>\n","      <td>0.539642</td>\n","      <td>0.015095</td>\n","      <td>0.615385</td>\n","      <td>0.598930</td>\n","      <td>0.005760</td>\n","      <td>0.711111</td>\n","      <td>0.648188</td>\n","      <td>0.023506</td>\n","      <td>0.402464</td>\n","      <td>0.343249</td>\n","      <td>0.023584</td>\n","      <td>0.575422</td>\n","      <td>0.551220</td>\n","      <td>0.007997</td>\n","    </tr>\n","    <tr>\n","      <th>T4</th>\n","      <td>0.189547</td>\n","      <td>0.000000</td>\n","      <td>0.077721</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.138322</td>\n","      <td>0.031250</td>\n","      <td>0.036721</td>\n","      <td>0.022388</td>\n","      <td>0.000000</td>\n","      <td>0.008720</td>\n","      <td>0.072364</td>\n","      <td>0.018762</td>\n","      <td>0.020278</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.655172</td>\n","      <td>0.631136</td>\n","      <td>0.008916</td>\n","      <td>0.634538</td>\n","      <td>0.620321</td>\n","      <td>0.005249</td>\n","      <td>0.716895</td>\n","      <td>0.694690</td>\n","      <td>0.009327</td>\n","      <td>0.446352</td>\n","      <td>0.410596</td>\n","      <td>0.014221</td>\n","      <td>0.616324</td>\n","      <td>0.596140</td>\n","      <td>0.006960</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.593123</td>\n","      <td>0.550512</td>\n","      <td>0.016477</td>\n","      <td>0.631436</td>\n","      <td>0.616231</td>\n","      <td>0.006214</td>\n","      <td>0.692810</td>\n","      <td>0.672566</td>\n","      <td>0.008676</td>\n","      <td>0.409186</td>\n","      <td>0.370203</td>\n","      <td>0.013042</td>\n","      <td>0.577598</td>\n","      <td>0.564060</td>\n","      <td>0.004835</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.653061</td>\n","      <td>0.615836</td>\n","      <td>0.012420</td>\n","      <td>0.656381</td>\n","      <td>0.642150</td>\n","      <td>0.006246</td>\n","      <td>0.734066</td>\n","      <td>0.703540</td>\n","      <td>0.010298</td>\n","      <td>0.437500</td>\n","      <td>0.424116</td>\n","      <td>0.004361</td>\n","      <td>0.620461</td>\n","      <td>0.607989</td>\n","      <td>0.005315</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"7\" valign=\"top\">roberta-base</th>\n","      <th>T1</th>\n","      <td>0.821683</td>\n","      <td>0.789400</td>\n","      <td>0.011938</td>\n","      <td>0.703601</td>\n","      <td>0.651748</td>\n","      <td>0.016891</td>\n","      <td>0.746137</td>\n","      <td>0.707158</td>\n","      <td>0.013355</td>\n","      <td>0.597849</td>\n","      <td>0.545842</td>\n","      <td>0.017984</td>\n","      <td>0.723223</td>\n","      <td>0.698204</td>\n","      <td>0.009664</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.802837</td>\n","      <td>0.761134</td>\n","      <td>0.013577</td>\n","      <td>0.673130</td>\n","      <td>0.623881</td>\n","      <td>0.018566</td>\n","      <td>0.723769</td>\n","      <td>0.669663</td>\n","      <td>0.023624</td>\n","      <td>0.561404</td>\n","      <td>0.513131</td>\n","      <td>0.015437</td>\n","      <td>0.694423</td>\n","      <td>0.662422</td>\n","      <td>0.015018</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.832386</td>\n","      <td>0.810512</td>\n","      <td>0.008108</td>\n","      <td>0.701513</td>\n","      <td>0.657895</td>\n","      <td>0.014903</td>\n","      <td>0.745098</td>\n","      <td>0.720358</td>\n","      <td>0.010589</td>\n","      <td>0.605578</td>\n","      <td>0.564756</td>\n","      <td>0.015188</td>\n","      <td>0.721743</td>\n","      <td>0.700958</td>\n","      <td>0.007519</td>\n","    </tr>\n","    <tr>\n","      <th>T4</th>\n","      <td>0.080925</td>\n","      <td>0.000000</td>\n","      <td>0.033812</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.173318</td>\n","      <td>0.013363</td>\n","      <td>0.051620</td>\n","      <td>0.181244</td>\n","      <td>0.000000</td>\n","      <td>0.059557</td>\n","      <td>0.069518</td>\n","      <td>0.017802</td>\n","      <td>0.020213</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.826896</td>\n","      <td>0.792614</td>\n","      <td>0.012819</td>\n","      <td>0.690667</td>\n","      <td>0.658263</td>\n","      <td>0.012111</td>\n","      <td>0.751131</td>\n","      <td>0.738197</td>\n","      <td>0.004568</td>\n","      <td>0.593220</td>\n","      <td>0.528455</td>\n","      <td>0.026487</td>\n","      <td>0.722879</td>\n","      <td>0.690554</td>\n","      <td>0.011276</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.813097</td>\n","      <td>0.787535</td>\n","      <td>0.008702</td>\n","      <td>0.686192</td>\n","      <td>0.660140</td>\n","      <td>0.009889</td>\n","      <td>0.747204</td>\n","      <td>0.733485</td>\n","      <td>0.004731</td>\n","      <td>0.570815</td>\n","      <td>0.543568</td>\n","      <td>0.009878</td>\n","      <td>0.710174</td>\n","      <td>0.693918</td>\n","      <td>0.005279</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.827586</td>\n","      <td>0.803443</td>\n","      <td>0.009157</td>\n","      <td>0.698727</td>\n","      <td>0.658192</td>\n","      <td>0.013215</td>\n","      <td>0.745098</td>\n","      <td>0.714588</td>\n","      <td>0.011037</td>\n","      <td>0.581443</td>\n","      <td>0.533613</td>\n","      <td>0.016158</td>\n","      <td>0.712762</td>\n","      <td>0.692731</td>\n","      <td>0.006741</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a521ab7c-5ffc-424f-bf65-9165772633b1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a521ab7c-5ffc-424f-bf65-9165772633b1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a521ab7c-5ffc-424f-bf65-9165772633b1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":17}]},{"cell_type":"markdown","source":["##**K&H+N, BLESS, EVALution, ROOT9**\n","To process the results of these datasets. Note that the results for templates `T1`-`T4` correspond to the non-masked models, and templates `TM1`-`TM3`for the masked ones. See the dictionary `templates2abrev` in a cell above."],"metadata":{"id":"Tdub9432I4PP"}},{"cell_type":"code","source":["def get_dataframe_results_max_min_measure(dict_res, dataset, measure, list_sub_measures=['precision', 'recall', 'f1-score']):\n","    inc_index = 3*len(list_sub_measures)\n","    dict_df = {'dataset': [], 'model':[], 'template':[]}\n","    for m in dict_res[dataset.lower()]:\n","        for t in dict_res[dataset.lower()][m]:\n","            d_measures = dict_res[dataset.lower()][m][t]['flat_reports'][measure]\n","\n","            dict_df['dataset'].append(dataset)\n","            dict_df['model'].append(m)\n","            dict_df['template'].append(t)\n","\n","            for meas in d_measures:\n","                if meas in list_sub_measures:\n","                    l_max = dict_df.setdefault('max-'+meas, [])\n","                    l_max.append(np.array(d_measures[meas]).max())\n","                    l_min = dict_df.setdefault('min-'+meas, [])\n","                    l_min.append(np.array(d_measures[meas]).min())\n","                    l_std = dict_df.setdefault('std-'+meas, [])\n","                    l_std.append(np.array(d_measures[meas]).std())\n","\n","    res_df = pd.DataFrame.from_dict(dict_df)\n","    res_df['model'] = res_df['model'].apply(lambda x : models2abrev[x])\n","    res_df['template'] = res_df['template'].apply(lambda x : templates2abrev[x])\n","    multi_row = pd.MultiIndex.from_frame(res_df.iloc[:,1:3],sortorder=None)\n","    multi_col = pd.MultiIndex.from_tuples(zip([dataset]*inc_index, res_df.columns[3:(3+inc_index)]),sortorder=None)\n","    res_df = res_df.iloc[:,3:(3+inc_index)]\n","    res_df.index = multi_row\n","    res_df.columns = multi_col\n","    return res_df\n","\n","def get_dataframe_results_measure(dict_res, dataset, measure, list_sub_measures=['precision', 'recall', 'f1-score']):\n","    inc_index = len(list_sub_measures)\n","    dict_df = {'dataset': [], 'model':[], 'template':[]}\n","    for m in dict_res[dataset.lower()]:\n","        for t in dict_res[dataset.lower()][m]:\n","            d_measures = dict_res[dataset.lower()][m][t]['mean_report'][measure]\n","\n","            dict_df['dataset'].append(dataset)\n","            dict_df['model'].append(m)\n","            dict_df['template'].append(t)\n","\n","            for meas in d_measures:\n","                if meas in list_sub_measures:\n","                    l = dict_df.setdefault(meas, [])\n","                    l.append(d_measures[meas])\n","\n","    res_df = pd.DataFrame.from_dict(dict_df)\n","    res_df['model'] = res_df['model'].apply(lambda x : models2abrev[x])\n","    res_df['template'] = res_df['template'].apply(lambda x : templates2abrev[x])\n","    multi_row = pd.MultiIndex.from_frame(res_df.iloc[:,1:3],sortorder=None)\n","    multi_col = pd.MultiIndex.from_tuples(zip([dataset]*inc_index, res_df.columns[3:(3+inc_index)]),sortorder=None)\n","    res_df = res_df.iloc[:,3:(3+inc_index)]\n","    res_df.index = multi_row\n","    res_df.columns = multi_col\n","    return res_df"],"metadata":{"id":"35lg0QNuJJlq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_datasets = ['K&H+N', 'BLESS', 'EVALution', 'ROOT09']\n","list_complete_res = []\n","\n","for one_dataset in all_datasets:\n","    if one_dataset.lower() in list(dict_res.keys()):\n","        df_res = get_dataframe_results_measure(dict_res, one_dataset, 'weighted avg') # one of 'weighted avg' and 'macro avg'\n","        list_complete_res.append(df_res)\n","    else:\n","        print(\"WARNING: There are not results for dataset \" + one_dataset)\n","df_datasets_final = pd.concat(list_complete_res, axis = 1)\n","\n","#change column order\n","order1 = {'k&h+n':0,'bless':1,'evalution':2, 'root09':3}\n","order2 = {'precision':0,'recall':1,'f1-score':2}\n","multi_col_list = list(df_datasets_final.columns)\n","multi_col_list.sort(key=lambda x: 10*order1[x[0].lower()] + order2[x[1].lower()])\n","multi_col = pd.MultiIndex.from_tuples(multi_col_list)\n","df_datasets_final = pd.DataFrame(df_datasets_final, columns=multi_col)\n","df_datasets_final.sort_index(level=['model','template'], inplace=True)"],"metadata":{"id":"ajsY7HIUJPl6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SOTAS_FILE_REST = DIR_RESULTS + 'sotas_results_literature/khnBlessEvalRoot_Sotas_RC.txt'\n","sotas_res = pd.read_csv(SOTAS_FILE_REST, header=[0,1], index_col=[0], skipinitialspace=True)\n","multi_row_tuples = list(zip(['Sota']*sotas_res.shape[0], list(sotas_res.index)))\n","multi_row = pd.MultiIndex.from_tuples(multi_row_tuples)\n","sotas_res.index=multi_row\n","df_res_sotas = pd.concat([df_datasets_final,sotas_res])\n","\n","#change column order\n","order1 = {'k&h+n':0,'bless':1,'evalution':2, 'root09':3}\n","order2 = {'precision':0,'recall':1,'f1-score':2}\n","multi_col_list = list(df_res_sotas.columns)\n","multi_col_list.sort(key=lambda x: 10*order1[x[0].lower()] + order2[x[1].lower()])\n","multi_col = pd.MultiIndex.from_tuples(multi_col_list)\n","\n","df_res_sotas = pd.DataFrame(df_res_sotas, columns=multi_col)\n","df_res_sotas.apply(round, ndigits=30)\n"],"metadata":{"cellView":"code","id":"aDAQ_3tS3mMb","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"cd240f7b-b714-4afb-e34d-9598533451b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                          K&H+N                         BLESS            \\\n","                      precision    recall  f1-score precision    recall   \n","model        template                                                     \n","Bert         T1        0.989279  0.989372  0.989283  0.952062  0.950972   \n","             T2        0.988852  0.988955  0.988862  0.949638  0.948079   \n","             T3        0.989652  0.989761  0.989652  0.952650  0.951996   \n","             T4        0.740641  0.587883  0.510361  0.243637  0.200090   \n","             TM1       0.987078  0.987216  0.987016  0.942206  0.940726   \n","             TM2       0.987278  0.987438  0.987288  0.945898  0.944463   \n","             TM3       0.985504  0.985755  0.985431  0.947861  0.946723   \n","Roberta      T1        0.988899  0.988968  0.988911  0.954583  0.953895   \n","             T2        0.988876  0.988955  0.988888  0.955340  0.954347   \n","             T3        0.988944  0.989024  0.988954  0.956224  0.955492   \n","             T4        0.603157  0.325923  0.311507  0.511042  0.194275   \n","             TM1       0.988515  0.988593  0.988496  0.948353  0.946241   \n","             TM2       0.987667  0.987772  0.987678  0.947049  0.945482   \n","             TM3       0.985518  0.985185  0.985282  0.951303  0.950460   \n","bert-base    T1        0.987638  0.987689  0.987644  0.943748  0.941871   \n","             T2        0.986912  0.986993  0.986923  0.943035  0.941058   \n","             T3        0.986869  0.986771  0.986793  0.943626  0.942203   \n","             T4        0.547507  0.428935  0.316018  0.369564  0.228386   \n","             TM1       0.986135  0.986256  0.986119  0.938743  0.936055   \n","             TM2       0.985471  0.985672  0.985414  0.940231  0.939491   \n","             TM3       0.985178  0.985324  0.985048  0.940717  0.939220   \n","roberta-base T1        0.983463  0.983724  0.983494  0.950049  0.948893   \n","             T2        0.987663  0.987703  0.987669  0.948488  0.947235   \n","             T3        0.987439  0.987480  0.987445  0.949862  0.948772   \n","             T4        0.660224  0.455352  0.299090  0.504303  0.138557   \n","             TM1       0.986559  0.986311  0.986338  0.941440  0.939882   \n","             TM2       0.982519  0.982848  0.982503  0.945688  0.944252   \n","             TM3       0.986242  0.986298  0.986152  0.945586  0.943890   \n","Sota         LexNET    0.985000  0.986000  0.985000  0.894000  0.893000   \n","             KEML      0.993000  0.993000  0.993000  0.944000  0.943000   \n","             SphereRE  0.990000  0.989000  0.990000  0.938000  0.938000   \n","             RelBERT        NaN       NaN  0.949000       NaN       NaN   \n","\n","                                EVALution                        ROOT09  \\\n","                       f1-score precision    recall  f1-score precision   \n","model        template                                                     \n","Bert         T1        0.951223  0.747669  0.747562  0.747197  0.926534   \n","             T2        0.948395  0.738647  0.739003  0.736617  0.930032   \n","             T3        0.952156  0.753333  0.750271  0.750660  0.930945   \n","             T4        0.087649  0.115621  0.148537  0.052673  0.929053   \n","             TM1       0.940908  0.754933  0.743987  0.744853  0.926502   \n","             TM2       0.944739  0.738177  0.728711  0.722481  0.925350   \n","             TM3       0.946968  0.729665  0.726327  0.723992  0.926887   \n","Roberta      T1        0.953960  0.768848  0.764789  0.764326  0.937188   \n","             T2        0.954563  0.758895  0.759372  0.757473  0.936314   \n","             T3        0.955660  0.773299  0.771181  0.770558  0.938197   \n","             T4        0.132698  0.229777  0.190683  0.087452  0.935851   \n","             TM1       0.946602  0.771562  0.761863  0.760673  0.936317   \n","             TM2       0.945714  0.771351  0.764680  0.764198  0.929912   \n","             TM3       0.950598  0.774145  0.754171  0.746288  0.926417   \n","bert-base    T1        0.942220  0.690299  0.690574  0.689041  0.925621   \n","             T2        0.941427  0.674987  0.672264  0.672354  0.919290   \n","             T3        0.942477  0.696403  0.693716  0.694414  0.922468   \n","             T4        0.165348  0.213162  0.218202  0.119044  0.920844   \n","             TM1       0.936486  0.706863  0.699675  0.698001  0.917368   \n","             TM2       0.939514  0.689736  0.686457  0.683546  0.917999   \n","             TM3       0.939404  0.696653  0.691874  0.686207  0.917967   \n","roberta-base T1        0.949115  0.748904  0.744204  0.745112  0.932277   \n","             T2        0.947487  0.746132  0.744420  0.744220  0.931237   \n","             T3        0.949017  0.756320  0.753304  0.753849  0.934262   \n","             T4        0.042571  0.120698  0.094908  0.023306  0.923711   \n","             TM1       0.940137  0.758330  0.745179  0.747326  0.927174   \n","             TM2       0.944434  0.740216  0.723835  0.727344  0.925764   \n","             TM3       0.944177  0.740151  0.737486  0.729413  0.924481   \n","Sota         LexNET    0.893000  0.601000  0.607000  0.600000  0.813000   \n","             KEML      0.944000  0.663000  0.660000  0.660000  0.878000   \n","             SphereRE  0.938000  0.620000  0.621000  0.620000  0.860000   \n","             RelBERT   0.921000       NaN       NaN  0.701000       NaN   \n","\n","                                           \n","                         recall  f1-score  \n","model        template                      \n","Bert         T1        0.926418  0.926258  \n","             T2        0.928549  0.928900  \n","             T3        0.931056  0.930907  \n","             T4        0.927922  0.928181  \n","             TM1       0.925227  0.925272  \n","             TM2       0.924726  0.924586  \n","             TM3       0.923660  0.923911  \n","Roberta      T1        0.936133  0.936310  \n","             T2        0.935945  0.936030  \n","             T3        0.937073  0.937334  \n","             T4        0.933626  0.934019  \n","             TM1       0.935569  0.935642  \n","             TM2       0.928612  0.928193  \n","             TM3       0.926042  0.925744  \n","bert-base    T1        0.924036  0.924396  \n","             T2        0.917706  0.918047  \n","             T3        0.921216  0.921417  \n","             T4        0.919210  0.919461  \n","             TM1       0.917330  0.917135  \n","             TM2       0.916578  0.916741  \n","             TM3       0.914886  0.915287  \n","roberta-base T1        0.931181  0.931330  \n","             T2        0.930743  0.930811  \n","             T3        0.933124  0.933323  \n","             T4        0.923347  0.923347  \n","             TM1       0.925729  0.925664  \n","             TM2       0.925541  0.925317  \n","             TM3       0.924287  0.923989  \n","Sota         LexNET    0.814000  0.813000  \n","             KEML      0.877000  0.878000  \n","             SphereRE  0.862000  0.861000  \n","             RelBERT        NaN  0.910000  "],"text/html":["\n","  <div id=\"df-c64ff1eb-5187-41ac-b877-5810e3d28c3d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th colspan=\"3\" halign=\"left\">K&amp;H+N</th>\n","      <th colspan=\"3\" halign=\"left\">BLESS</th>\n","      <th colspan=\"3\" halign=\"left\">EVALution</th>\n","      <th colspan=\"3\" halign=\"left\">ROOT09</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1-score</th>\n","    </tr>\n","    <tr>\n","      <th>model</th>\n","      <th>template</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"7\" valign=\"top\">Bert</th>\n","      <th>T1</th>\n","      <td>0.989279</td>\n","      <td>0.989372</td>\n","      <td>0.989283</td>\n","      <td>0.952062</td>\n","      <td>0.950972</td>\n","      <td>0.951223</td>\n","      <td>0.747669</td>\n","      <td>0.747562</td>\n","      <td>0.747197</td>\n","      <td>0.926534</td>\n","      <td>0.926418</td>\n","      <td>0.926258</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.988852</td>\n","      <td>0.988955</td>\n","      <td>0.988862</td>\n","      <td>0.949638</td>\n","      <td>0.948079</td>\n","      <td>0.948395</td>\n","      <td>0.738647</td>\n","      <td>0.739003</td>\n","      <td>0.736617</td>\n","      <td>0.930032</td>\n","      <td>0.928549</td>\n","      <td>0.928900</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.989652</td>\n","      <td>0.989761</td>\n","      <td>0.989652</td>\n","      <td>0.952650</td>\n","      <td>0.951996</td>\n","      <td>0.952156</td>\n","      <td>0.753333</td>\n","      <td>0.750271</td>\n","      <td>0.750660</td>\n","      <td>0.930945</td>\n","      <td>0.931056</td>\n","      <td>0.930907</td>\n","    </tr>\n","    <tr>\n","      <th>T4</th>\n","      <td>0.740641</td>\n","      <td>0.587883</td>\n","      <td>0.510361</td>\n","      <td>0.243637</td>\n","      <td>0.200090</td>\n","      <td>0.087649</td>\n","      <td>0.115621</td>\n","      <td>0.148537</td>\n","      <td>0.052673</td>\n","      <td>0.929053</td>\n","      <td>0.927922</td>\n","      <td>0.928181</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.987078</td>\n","      <td>0.987216</td>\n","      <td>0.987016</td>\n","      <td>0.942206</td>\n","      <td>0.940726</td>\n","      <td>0.940908</td>\n","      <td>0.754933</td>\n","      <td>0.743987</td>\n","      <td>0.744853</td>\n","      <td>0.926502</td>\n","      <td>0.925227</td>\n","      <td>0.925272</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.987278</td>\n","      <td>0.987438</td>\n","      <td>0.987288</td>\n","      <td>0.945898</td>\n","      <td>0.944463</td>\n","      <td>0.944739</td>\n","      <td>0.738177</td>\n","      <td>0.728711</td>\n","      <td>0.722481</td>\n","      <td>0.925350</td>\n","      <td>0.924726</td>\n","      <td>0.924586</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.985504</td>\n","      <td>0.985755</td>\n","      <td>0.985431</td>\n","      <td>0.947861</td>\n","      <td>0.946723</td>\n","      <td>0.946968</td>\n","      <td>0.729665</td>\n","      <td>0.726327</td>\n","      <td>0.723992</td>\n","      <td>0.926887</td>\n","      <td>0.923660</td>\n","      <td>0.923911</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"7\" valign=\"top\">Roberta</th>\n","      <th>T1</th>\n","      <td>0.988899</td>\n","      <td>0.988968</td>\n","      <td>0.988911</td>\n","      <td>0.954583</td>\n","      <td>0.953895</td>\n","      <td>0.953960</td>\n","      <td>0.768848</td>\n","      <td>0.764789</td>\n","      <td>0.764326</td>\n","      <td>0.937188</td>\n","      <td>0.936133</td>\n","      <td>0.936310</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.988876</td>\n","      <td>0.988955</td>\n","      <td>0.988888</td>\n","      <td>0.955340</td>\n","      <td>0.954347</td>\n","      <td>0.954563</td>\n","      <td>0.758895</td>\n","      <td>0.759372</td>\n","      <td>0.757473</td>\n","      <td>0.936314</td>\n","      <td>0.935945</td>\n","      <td>0.936030</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.988944</td>\n","      <td>0.989024</td>\n","      <td>0.988954</td>\n","      <td>0.956224</td>\n","      <td>0.955492</td>\n","      <td>0.955660</td>\n","      <td>0.773299</td>\n","      <td>0.771181</td>\n","      <td>0.770558</td>\n","      <td>0.938197</td>\n","      <td>0.937073</td>\n","      <td>0.937334</td>\n","    </tr>\n","    <tr>\n","      <th>T4</th>\n","      <td>0.603157</td>\n","      <td>0.325923</td>\n","      <td>0.311507</td>\n","      <td>0.511042</td>\n","      <td>0.194275</td>\n","      <td>0.132698</td>\n","      <td>0.229777</td>\n","      <td>0.190683</td>\n","      <td>0.087452</td>\n","      <td>0.935851</td>\n","      <td>0.933626</td>\n","      <td>0.934019</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.988515</td>\n","      <td>0.988593</td>\n","      <td>0.988496</td>\n","      <td>0.948353</td>\n","      <td>0.946241</td>\n","      <td>0.946602</td>\n","      <td>0.771562</td>\n","      <td>0.761863</td>\n","      <td>0.760673</td>\n","      <td>0.936317</td>\n","      <td>0.935569</td>\n","      <td>0.935642</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.987667</td>\n","      <td>0.987772</td>\n","      <td>0.987678</td>\n","      <td>0.947049</td>\n","      <td>0.945482</td>\n","      <td>0.945714</td>\n","      <td>0.771351</td>\n","      <td>0.764680</td>\n","      <td>0.764198</td>\n","      <td>0.929912</td>\n","      <td>0.928612</td>\n","      <td>0.928193</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.985518</td>\n","      <td>0.985185</td>\n","      <td>0.985282</td>\n","      <td>0.951303</td>\n","      <td>0.950460</td>\n","      <td>0.950598</td>\n","      <td>0.774145</td>\n","      <td>0.754171</td>\n","      <td>0.746288</td>\n","      <td>0.926417</td>\n","      <td>0.926042</td>\n","      <td>0.925744</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"7\" valign=\"top\">bert-base</th>\n","      <th>T1</th>\n","      <td>0.987638</td>\n","      <td>0.987689</td>\n","      <td>0.987644</td>\n","      <td>0.943748</td>\n","      <td>0.941871</td>\n","      <td>0.942220</td>\n","      <td>0.690299</td>\n","      <td>0.690574</td>\n","      <td>0.689041</td>\n","      <td>0.925621</td>\n","      <td>0.924036</td>\n","      <td>0.924396</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.986912</td>\n","      <td>0.986993</td>\n","      <td>0.986923</td>\n","      <td>0.943035</td>\n","      <td>0.941058</td>\n","      <td>0.941427</td>\n","      <td>0.674987</td>\n","      <td>0.672264</td>\n","      <td>0.672354</td>\n","      <td>0.919290</td>\n","      <td>0.917706</td>\n","      <td>0.918047</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.986869</td>\n","      <td>0.986771</td>\n","      <td>0.986793</td>\n","      <td>0.943626</td>\n","      <td>0.942203</td>\n","      <td>0.942477</td>\n","      <td>0.696403</td>\n","      <td>0.693716</td>\n","      <td>0.694414</td>\n","      <td>0.922468</td>\n","      <td>0.921216</td>\n","      <td>0.921417</td>\n","    </tr>\n","    <tr>\n","      <th>T4</th>\n","      <td>0.547507</td>\n","      <td>0.428935</td>\n","      <td>0.316018</td>\n","      <td>0.369564</td>\n","      <td>0.228386</td>\n","      <td>0.165348</td>\n","      <td>0.213162</td>\n","      <td>0.218202</td>\n","      <td>0.119044</td>\n","      <td>0.920844</td>\n","      <td>0.919210</td>\n","      <td>0.919461</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.986135</td>\n","      <td>0.986256</td>\n","      <td>0.986119</td>\n","      <td>0.938743</td>\n","      <td>0.936055</td>\n","      <td>0.936486</td>\n","      <td>0.706863</td>\n","      <td>0.699675</td>\n","      <td>0.698001</td>\n","      <td>0.917368</td>\n","      <td>0.917330</td>\n","      <td>0.917135</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.985471</td>\n","      <td>0.985672</td>\n","      <td>0.985414</td>\n","      <td>0.940231</td>\n","      <td>0.939491</td>\n","      <td>0.939514</td>\n","      <td>0.689736</td>\n","      <td>0.686457</td>\n","      <td>0.683546</td>\n","      <td>0.917999</td>\n","      <td>0.916578</td>\n","      <td>0.916741</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.985178</td>\n","      <td>0.985324</td>\n","      <td>0.985048</td>\n","      <td>0.940717</td>\n","      <td>0.939220</td>\n","      <td>0.939404</td>\n","      <td>0.696653</td>\n","      <td>0.691874</td>\n","      <td>0.686207</td>\n","      <td>0.917967</td>\n","      <td>0.914886</td>\n","      <td>0.915287</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"7\" valign=\"top\">roberta-base</th>\n","      <th>T1</th>\n","      <td>0.983463</td>\n","      <td>0.983724</td>\n","      <td>0.983494</td>\n","      <td>0.950049</td>\n","      <td>0.948893</td>\n","      <td>0.949115</td>\n","      <td>0.748904</td>\n","      <td>0.744204</td>\n","      <td>0.745112</td>\n","      <td>0.932277</td>\n","      <td>0.931181</td>\n","      <td>0.931330</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.987663</td>\n","      <td>0.987703</td>\n","      <td>0.987669</td>\n","      <td>0.948488</td>\n","      <td>0.947235</td>\n","      <td>0.947487</td>\n","      <td>0.746132</td>\n","      <td>0.744420</td>\n","      <td>0.744220</td>\n","      <td>0.931237</td>\n","      <td>0.930743</td>\n","      <td>0.930811</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.987439</td>\n","      <td>0.987480</td>\n","      <td>0.987445</td>\n","      <td>0.949862</td>\n","      <td>0.948772</td>\n","      <td>0.949017</td>\n","      <td>0.756320</td>\n","      <td>0.753304</td>\n","      <td>0.753849</td>\n","      <td>0.934262</td>\n","      <td>0.933124</td>\n","      <td>0.933323</td>\n","    </tr>\n","    <tr>\n","      <th>T4</th>\n","      <td>0.660224</td>\n","      <td>0.455352</td>\n","      <td>0.299090</td>\n","      <td>0.504303</td>\n","      <td>0.138557</td>\n","      <td>0.042571</td>\n","      <td>0.120698</td>\n","      <td>0.094908</td>\n","      <td>0.023306</td>\n","      <td>0.923711</td>\n","      <td>0.923347</td>\n","      <td>0.923347</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.986559</td>\n","      <td>0.986311</td>\n","      <td>0.986338</td>\n","      <td>0.941440</td>\n","      <td>0.939882</td>\n","      <td>0.940137</td>\n","      <td>0.758330</td>\n","      <td>0.745179</td>\n","      <td>0.747326</td>\n","      <td>0.927174</td>\n","      <td>0.925729</td>\n","      <td>0.925664</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.982519</td>\n","      <td>0.982848</td>\n","      <td>0.982503</td>\n","      <td>0.945688</td>\n","      <td>0.944252</td>\n","      <td>0.944434</td>\n","      <td>0.740216</td>\n","      <td>0.723835</td>\n","      <td>0.727344</td>\n","      <td>0.925764</td>\n","      <td>0.925541</td>\n","      <td>0.925317</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.986242</td>\n","      <td>0.986298</td>\n","      <td>0.986152</td>\n","      <td>0.945586</td>\n","      <td>0.943890</td>\n","      <td>0.944177</td>\n","      <td>0.740151</td>\n","      <td>0.737486</td>\n","      <td>0.729413</td>\n","      <td>0.924481</td>\n","      <td>0.924287</td>\n","      <td>0.923989</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"4\" valign=\"top\">Sota</th>\n","      <th>LexNET</th>\n","      <td>0.985000</td>\n","      <td>0.986000</td>\n","      <td>0.985000</td>\n","      <td>0.894000</td>\n","      <td>0.893000</td>\n","      <td>0.893000</td>\n","      <td>0.601000</td>\n","      <td>0.607000</td>\n","      <td>0.600000</td>\n","      <td>0.813000</td>\n","      <td>0.814000</td>\n","      <td>0.813000</td>\n","    </tr>\n","    <tr>\n","      <th>KEML</th>\n","      <td>0.993000</td>\n","      <td>0.993000</td>\n","      <td>0.993000</td>\n","      <td>0.944000</td>\n","      <td>0.943000</td>\n","      <td>0.944000</td>\n","      <td>0.663000</td>\n","      <td>0.660000</td>\n","      <td>0.660000</td>\n","      <td>0.878000</td>\n","      <td>0.877000</td>\n","      <td>0.878000</td>\n","    </tr>\n","    <tr>\n","      <th>SphereRE</th>\n","      <td>0.990000</td>\n","      <td>0.989000</td>\n","      <td>0.990000</td>\n","      <td>0.938000</td>\n","      <td>0.938000</td>\n","      <td>0.938000</td>\n","      <td>0.620000</td>\n","      <td>0.621000</td>\n","      <td>0.620000</td>\n","      <td>0.860000</td>\n","      <td>0.862000</td>\n","      <td>0.861000</td>\n","    </tr>\n","    <tr>\n","      <th>RelBERT</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.949000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.921000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.701000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0.910000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c64ff1eb-5187-41ac-b877-5810e3d28c3d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c64ff1eb-5187-41ac-b877-5810e3d28c3d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c64ff1eb-5187-41ac-b877-5810e3d28c3d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["all_datasets = ['K&H+N', 'BLESS', 'EVALution', 'ROOT09']\n","list_complete_res = []\n","\n","for one_dataset in all_datasets:\n","    if one_dataset.lower() in list(dict_res.keys()):\n","        df_res = get_dataframe_results_max_min_measure(dict_res, one_dataset, 'weighted avg') # one of 'weighted avg' and 'macro avg'\n","        list_complete_res.append(df_res)\n","    else:\n","        print(\"WARNING: There are not results for dataset \" + one_dataset)\n","df_datasets_max_min_final = pd.concat(list_complete_res, axis = 1)\n","\n","df_datasets_max_min_final.sort_index(level=['model','template'], inplace=True)\n","df_datasets_max_min_final"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"tf_86X5VSyPJ","outputId":"6414ded5-4084-4725-8e2a-0465fa1e48f3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                              K&H+N                                         \\\n","                      max-precision min-precision std-precision max-recall   \n","model        template                                                        \n","Bert         T1            0.990061      0.987516      0.000963   0.990123   \n","             T2            0.990036      0.987008      0.001060   0.990123   \n","             T3            0.990883      0.987878      0.001022   0.990958   \n","             T4            0.775743      0.674940      0.035524   0.769354   \n","             TM1           0.989056      0.982043      0.002680   0.989080   \n","             TM2           0.989949      0.986245      0.001364   0.990054   \n","             TM3           0.989805      0.982281      0.002426   0.989914   \n","Roberta      T1            0.989841      0.986780      0.001096   0.989775   \n","             T2            0.989835      0.987854      0.000857   0.989914   \n","             T3            0.990133      0.986657      0.001273   0.990123   \n","             T4            0.743041      0.260714      0.179172   0.615775   \n","             TM1           0.989355      0.987437      0.000640   0.989428   \n","             TM2           0.989101      0.986003      0.001152   0.989219   \n","             TM3           0.987562      0.983772      0.001526   0.987619   \n","bert-base    T1            0.988275      0.986896      0.000539   0.988384   \n","             T2            0.988046      0.985607      0.000889   0.988106   \n","             T3            0.988825      0.983998      0.001578   0.988941   \n","             T4            0.664307      0.195018      0.178643   0.492940   \n","             TM1           0.988435      0.982377      0.002223   0.988593   \n","             TM2           0.988935      0.982502      0.002433   0.989080   \n","             TM3           0.987908      0.983026      0.001857   0.988036   \n","roberta-base T1            0.987826      0.968645      0.007421   0.987897   \n","             T2            0.988303      0.986700      0.000570   0.988384   \n","             T3            0.988901      0.986157      0.000887   0.988941   \n","             T4            0.664321      0.645879      0.007210   0.476386   \n","             TM1           0.989165      0.983657      0.002170   0.989219   \n","             TM2           0.986707      0.978421      0.003474   0.986784   \n","             TM3           0.988230      0.983090      0.001930   0.988245   \n","\n","                                                                       \\\n","                      min-recall std-recall max-f1-score min-f1-score   \n","model        template                                                   \n","Bert         T1         0.987689   0.000924     0.990072     0.987522   \n","             T2         0.987132   0.001049     0.990042     0.987037   \n","             T3         0.988036   0.000991     0.990883     0.987902   \n","             T4         0.483620   0.102657     0.757430     0.345001   \n","             TM1        0.982263   0.002623     0.989043     0.981875   \n","             TM2        0.986367   0.001341     0.989970     0.986266   \n","             TM3        0.982611   0.002355     0.989794     0.982343   \n","Roberta      T1         0.986924   0.001050     0.989794     0.986825   \n","             T2         0.987897   0.000867     0.989857     0.987828   \n","             T3         0.986854   0.001219     0.990122     0.986724   \n","             T4         0.046324   0.190253     0.580858     0.035667   \n","             TM1        0.987480   0.000652     0.989348     0.987418   \n","             TM2        0.985880   0.001203     0.989131     0.985923   \n","             TM3        0.982889   0.001954     0.987564     0.983200   \n","bert-base    T1         0.986924   0.000558     0.988305     0.986905   \n","             T2         0.985672   0.000873     0.988070     0.985632   \n","             T3         0.983585   0.001747     0.988859     0.983743   \n","             T4         0.324616   0.055719     0.418042     0.270556   \n","             TM1        0.982333   0.002262     0.988437     0.982336   \n","             TM2        0.982889   0.002327     0.988956     0.982454   \n","             TM3        0.983307   0.001751     0.987759     0.982582   \n","roberta-base T1         0.969882   0.006934     0.987850     0.968813   \n","             T2         0.986715   0.000605     0.988329     0.986694   \n","             T3         0.986089   0.000913     0.988915     0.986108   \n","             T4         0.441678   0.016612     0.342407     0.270708   \n","             TM1        0.982472   0.002649     0.989172     0.983125   \n","             TM2        0.979064   0.003248     0.986715     0.978287   \n","             TM3        0.983376   0.001797     0.988224     0.982965   \n","\n","                                           BLESS  ...    EVALution  \\\n","                      std-f1-score max-precision  ... std-f1-score   \n","model        template                             ...                \n","Bert         T1           0.000961      0.956109  ...     0.009210   \n","             T2           0.001045      0.953170  ...     0.011065   \n","             T3           0.001014      0.957277  ...     0.005743   \n","             T4           0.146788      0.541156  ...     0.047084   \n","             TM1          0.002737      0.943610  ...     0.007153   \n","             TM2          0.001366      0.949011  ...     0.015470   \n","             TM3          0.002427      0.954229  ...     0.018915   \n","Roberta      T1           0.001076      0.956329  ...     0.010243   \n","             T2           0.000868      0.957248  ...     0.009601   \n","             T3           0.001251      0.959666  ...     0.007716   \n","             T4           0.181140      0.536980  ...     0.027860   \n","             TM1          0.000647      0.951622  ...     0.016098   \n","             TM2          0.001178      0.952524  ...     0.006487   \n","             TM3          0.001788      0.957729  ...     0.031670   \n","bert-base    T1           0.000541      0.945973  ...     0.010015   \n","             T2           0.000893      0.945103  ...     0.009959   \n","             T3           0.001671      0.946859  ...     0.004844   \n","             T4           0.058305      0.461790  ...     0.037842   \n","             TM1          0.002217      0.944484  ...     0.012299   \n","             TM2          0.002492      0.945021  ...     0.009803   \n","             TM3          0.001918      0.945217  ...     0.011889   \n","roberta-base T1           0.007353      0.952677  ...     0.009372   \n","             T2           0.000587      0.952293  ...     0.004836   \n","             T3           0.000903      0.951282  ...     0.002267   \n","             T4           0.034454      0.583433  ...     0.013159   \n","             TM1          0.002448      0.944738  ...     0.012418   \n","             TM2          0.003517      0.952338  ...     0.012260   \n","             TM3          0.001952      0.949587  ...     0.023671   \n","\n","                             ROOT09                                         \\\n","                      max-precision min-precision std-precision max-recall   \n","model        template                                                        \n","Bert         T1            0.932149      0.917239      0.005031   0.929803   \n","             T2            0.932559      0.927252      0.002082   0.931369   \n","             T3            0.933409      0.926036      0.002640   0.933563   \n","             T4            0.935060      0.924590      0.003776   0.933250   \n","             TM1           0.931731      0.919070      0.004255   0.931683   \n","             TM2           0.933665      0.914036      0.008265   0.932936   \n","             TM3           0.931012      0.922350      0.003266   0.927609   \n","Roberta      T1            0.940670      0.934449      0.002258   0.938891   \n","             T2            0.939915      0.933373      0.002098   0.939517   \n","             T3            0.940311      0.936691      0.001280   0.938264   \n","             T4            0.939571      0.930950      0.003201   0.938264   \n","             TM1           0.940061      0.930925      0.003079   0.940144   \n","             TM2           0.936819      0.913685      0.008962   0.936070   \n","             TM3           0.936363      0.907132      0.010221   0.933250   \n","bert-base    T1            0.927133      0.923645      0.001415   0.926042   \n","             T2            0.920412      0.917975      0.000867   0.918521   \n","             T3            0.926868      0.920097      0.002341   0.924475   \n","             T4            0.921739      0.918282      0.001298   0.920715   \n","             TM1           0.927143      0.913169      0.005176   0.926355   \n","             TM2           0.922013      0.910831      0.004343   0.920715   \n","             TM3           0.920768      0.916316      0.001844   0.919461   \n","roberta-base T1            0.934250      0.929058      0.001898   0.934190   \n","             T2            0.936081      0.927822      0.003073   0.935443   \n","             T3            0.937320      0.928950      0.002946   0.937010   \n","             T4            0.927172      0.919651      0.002396   0.926355   \n","             TM1           0.935865      0.919793      0.005838   0.935130   \n","             TM2           0.927513      0.923833      0.001390   0.928236   \n","             TM3           0.930174      0.915562      0.005576   0.929489   \n","\n","                                                                       \\\n","                      min-recall std-recall max-f1-score min-f1-score   \n","model        template                                                   \n","Bert         T1         0.917581   0.004543     0.930315     0.917237   \n","             T2         0.924475   0.002644     0.931695     0.925530   \n","             T3         0.926355   0.002681     0.933420     0.926088   \n","             T4         0.923848   0.003275     0.933742     0.924117   \n","             TM1        0.917581   0.005513     0.931686     0.918737   \n","             TM2        0.915074   0.007205     0.933235     0.913595   \n","             TM3        0.916327   0.003952     0.928325     0.917986   \n","Roberta      T1         0.934190   0.002035     0.938886     0.934528   \n","             T2         0.933250   0.002112     0.939588     0.933267   \n","             T3         0.935443   0.001228     0.938763     0.935859   \n","             T4         0.929176   0.003586     0.938024     0.929781   \n","             TM1        0.929803   0.003308     0.940101     0.929951   \n","             TM2        0.911626   0.009268     0.935949     0.908673   \n","             TM3        0.908493   0.008989     0.933150     0.907248   \n","bert-base    T1         0.921341   0.001768     0.926192     0.922099   \n","             T2         0.916641   0.000783     0.918852     0.917180   \n","             T3         0.918834   0.001968     0.924968     0.919539   \n","             T4         0.915700   0.001842     0.920854     0.916076   \n","             TM1        0.914134   0.004696     0.926672     0.913217   \n","             TM2        0.911313   0.003835     0.920889     0.910897   \n","             TM3        0.906926   0.004630     0.919563     0.908317   \n","roberta-base T1         0.926982   0.002342     0.934093     0.927217   \n","             T2         0.927922   0.002789     0.935578     0.927755   \n","             T3         0.926669   0.003604     0.937046     0.927069   \n","             T4         0.919774   0.002131     0.926457     0.919622   \n","             TM1        0.912253   0.007798     0.935278     0.913088   \n","             TM2        0.922281   0.002027     0.927559     0.922636   \n","             TM3        0.916327   0.004813     0.929074     0.915541   \n","\n","                                    \n","                      std-f1-score  \n","model        template               \n","Bert         T1           0.004693  \n","             T2           0.002468  \n","             T3           0.002664  \n","             T4           0.003366  \n","             TM1          0.005264  \n","             TM2          0.007874  \n","             TM3          0.003618  \n","Roberta      T1           0.002080  \n","             T2           0.002084  \n","             T3           0.001196  \n","             T4           0.003459  \n","             TM1          0.003262  \n","             TM2          0.010440  \n","             TM3          0.009539  \n","bert-base    T1           0.001613  \n","             T2           0.000650  \n","             T3           0.001974  \n","             T4           0.001753  \n","             TM1          0.005008  \n","             TM2          0.003954  \n","             TM3          0.004084  \n","roberta-base T1           0.002272  \n","             T2           0.002883  \n","             T3           0.003476  \n","             T4           0.002184  \n","             TM1          0.007618  \n","             TM2          0.001802  \n","             TM3          0.005228  \n","\n","[28 rows x 36 columns]"],"text/html":["\n","  <div id=\"df-8ff60c60-dcc8-4c86-b6ac-8f8c5bddabc2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th colspan=\"9\" halign=\"left\">K&amp;H+N</th>\n","      <th>BLESS</th>\n","      <th>...</th>\n","      <th>EVALution</th>\n","      <th colspan=\"9\" halign=\"left\">ROOT09</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>max-precision</th>\n","      <th>min-precision</th>\n","      <th>std-precision</th>\n","      <th>max-recall</th>\n","      <th>min-recall</th>\n","      <th>std-recall</th>\n","      <th>max-f1-score</th>\n","      <th>min-f1-score</th>\n","      <th>std-f1-score</th>\n","      <th>max-precision</th>\n","      <th>...</th>\n","      <th>std-f1-score</th>\n","      <th>max-precision</th>\n","      <th>min-precision</th>\n","      <th>std-precision</th>\n","      <th>max-recall</th>\n","      <th>min-recall</th>\n","      <th>std-recall</th>\n","      <th>max-f1-score</th>\n","      <th>min-f1-score</th>\n","      <th>std-f1-score</th>\n","    </tr>\n","    <tr>\n","      <th>model</th>\n","      <th>template</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"7\" valign=\"top\">Bert</th>\n","      <th>T1</th>\n","      <td>0.990061</td>\n","      <td>0.987516</td>\n","      <td>0.000963</td>\n","      <td>0.990123</td>\n","      <td>0.987689</td>\n","      <td>0.000924</td>\n","      <td>0.990072</td>\n","      <td>0.987522</td>\n","      <td>0.000961</td>\n","      <td>0.956109</td>\n","      <td>...</td>\n","      <td>0.009210</td>\n","      <td>0.932149</td>\n","      <td>0.917239</td>\n","      <td>0.005031</td>\n","      <td>0.929803</td>\n","      <td>0.917581</td>\n","      <td>0.004543</td>\n","      <td>0.930315</td>\n","      <td>0.917237</td>\n","      <td>0.004693</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.990036</td>\n","      <td>0.987008</td>\n","      <td>0.001060</td>\n","      <td>0.990123</td>\n","      <td>0.987132</td>\n","      <td>0.001049</td>\n","      <td>0.990042</td>\n","      <td>0.987037</td>\n","      <td>0.001045</td>\n","      <td>0.953170</td>\n","      <td>...</td>\n","      <td>0.011065</td>\n","      <td>0.932559</td>\n","      <td>0.927252</td>\n","      <td>0.002082</td>\n","      <td>0.931369</td>\n","      <td>0.924475</td>\n","      <td>0.002644</td>\n","      <td>0.931695</td>\n","      <td>0.925530</td>\n","      <td>0.002468</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.990883</td>\n","      <td>0.987878</td>\n","      <td>0.001022</td>\n","      <td>0.990958</td>\n","      <td>0.988036</td>\n","      <td>0.000991</td>\n","      <td>0.990883</td>\n","      <td>0.987902</td>\n","      <td>0.001014</td>\n","      <td>0.957277</td>\n","      <td>...</td>\n","      <td>0.005743</td>\n","      <td>0.933409</td>\n","      <td>0.926036</td>\n","      <td>0.002640</td>\n","      <td>0.933563</td>\n","      <td>0.926355</td>\n","      <td>0.002681</td>\n","      <td>0.933420</td>\n","      <td>0.926088</td>\n","      <td>0.002664</td>\n","    </tr>\n","    <tr>\n","      <th>T4</th>\n","      <td>0.775743</td>\n","      <td>0.674940</td>\n","      <td>0.035524</td>\n","      <td>0.769354</td>\n","      <td>0.483620</td>\n","      <td>0.102657</td>\n","      <td>0.757430</td>\n","      <td>0.345001</td>\n","      <td>0.146788</td>\n","      <td>0.541156</td>\n","      <td>...</td>\n","      <td>0.047084</td>\n","      <td>0.935060</td>\n","      <td>0.924590</td>\n","      <td>0.003776</td>\n","      <td>0.933250</td>\n","      <td>0.923848</td>\n","      <td>0.003275</td>\n","      <td>0.933742</td>\n","      <td>0.924117</td>\n","      <td>0.003366</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.989056</td>\n","      <td>0.982043</td>\n","      <td>0.002680</td>\n","      <td>0.989080</td>\n","      <td>0.982263</td>\n","      <td>0.002623</td>\n","      <td>0.989043</td>\n","      <td>0.981875</td>\n","      <td>0.002737</td>\n","      <td>0.943610</td>\n","      <td>...</td>\n","      <td>0.007153</td>\n","      <td>0.931731</td>\n","      <td>0.919070</td>\n","      <td>0.004255</td>\n","      <td>0.931683</td>\n","      <td>0.917581</td>\n","      <td>0.005513</td>\n","      <td>0.931686</td>\n","      <td>0.918737</td>\n","      <td>0.005264</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.989949</td>\n","      <td>0.986245</td>\n","      <td>0.001364</td>\n","      <td>0.990054</td>\n","      <td>0.986367</td>\n","      <td>0.001341</td>\n","      <td>0.989970</td>\n","      <td>0.986266</td>\n","      <td>0.001366</td>\n","      <td>0.949011</td>\n","      <td>...</td>\n","      <td>0.015470</td>\n","      <td>0.933665</td>\n","      <td>0.914036</td>\n","      <td>0.008265</td>\n","      <td>0.932936</td>\n","      <td>0.915074</td>\n","      <td>0.007205</td>\n","      <td>0.933235</td>\n","      <td>0.913595</td>\n","      <td>0.007874</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.989805</td>\n","      <td>0.982281</td>\n","      <td>0.002426</td>\n","      <td>0.989914</td>\n","      <td>0.982611</td>\n","      <td>0.002355</td>\n","      <td>0.989794</td>\n","      <td>0.982343</td>\n","      <td>0.002427</td>\n","      <td>0.954229</td>\n","      <td>...</td>\n","      <td>0.018915</td>\n","      <td>0.931012</td>\n","      <td>0.922350</td>\n","      <td>0.003266</td>\n","      <td>0.927609</td>\n","      <td>0.916327</td>\n","      <td>0.003952</td>\n","      <td>0.928325</td>\n","      <td>0.917986</td>\n","      <td>0.003618</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"7\" valign=\"top\">Roberta</th>\n","      <th>T1</th>\n","      <td>0.989841</td>\n","      <td>0.986780</td>\n","      <td>0.001096</td>\n","      <td>0.989775</td>\n","      <td>0.986924</td>\n","      <td>0.001050</td>\n","      <td>0.989794</td>\n","      <td>0.986825</td>\n","      <td>0.001076</td>\n","      <td>0.956329</td>\n","      <td>...</td>\n","      <td>0.010243</td>\n","      <td>0.940670</td>\n","      <td>0.934449</td>\n","      <td>0.002258</td>\n","      <td>0.938891</td>\n","      <td>0.934190</td>\n","      <td>0.002035</td>\n","      <td>0.938886</td>\n","      <td>0.934528</td>\n","      <td>0.002080</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.989835</td>\n","      <td>0.987854</td>\n","      <td>0.000857</td>\n","      <td>0.989914</td>\n","      <td>0.987897</td>\n","      <td>0.000867</td>\n","      <td>0.989857</td>\n","      <td>0.987828</td>\n","      <td>0.000868</td>\n","      <td>0.957248</td>\n","      <td>...</td>\n","      <td>0.009601</td>\n","      <td>0.939915</td>\n","      <td>0.933373</td>\n","      <td>0.002098</td>\n","      <td>0.939517</td>\n","      <td>0.933250</td>\n","      <td>0.002112</td>\n","      <td>0.939588</td>\n","      <td>0.933267</td>\n","      <td>0.002084</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.990133</td>\n","      <td>0.986657</td>\n","      <td>0.001273</td>\n","      <td>0.990123</td>\n","      <td>0.986854</td>\n","      <td>0.001219</td>\n","      <td>0.990122</td>\n","      <td>0.986724</td>\n","      <td>0.001251</td>\n","      <td>0.959666</td>\n","      <td>...</td>\n","      <td>0.007716</td>\n","      <td>0.940311</td>\n","      <td>0.936691</td>\n","      <td>0.001280</td>\n","      <td>0.938264</td>\n","      <td>0.935443</td>\n","      <td>0.001228</td>\n","      <td>0.938763</td>\n","      <td>0.935859</td>\n","      <td>0.001196</td>\n","    </tr>\n","    <tr>\n","      <th>T4</th>\n","      <td>0.743041</td>\n","      <td>0.260714</td>\n","      <td>0.179172</td>\n","      <td>0.615775</td>\n","      <td>0.046324</td>\n","      <td>0.190253</td>\n","      <td>0.580858</td>\n","      <td>0.035667</td>\n","      <td>0.181140</td>\n","      <td>0.536980</td>\n","      <td>...</td>\n","      <td>0.027860</td>\n","      <td>0.939571</td>\n","      <td>0.930950</td>\n","      <td>0.003201</td>\n","      <td>0.938264</td>\n","      <td>0.929176</td>\n","      <td>0.003586</td>\n","      <td>0.938024</td>\n","      <td>0.929781</td>\n","      <td>0.003459</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.989355</td>\n","      <td>0.987437</td>\n","      <td>0.000640</td>\n","      <td>0.989428</td>\n","      <td>0.987480</td>\n","      <td>0.000652</td>\n","      <td>0.989348</td>\n","      <td>0.987418</td>\n","      <td>0.000647</td>\n","      <td>0.951622</td>\n","      <td>...</td>\n","      <td>0.016098</td>\n","      <td>0.940061</td>\n","      <td>0.930925</td>\n","      <td>0.003079</td>\n","      <td>0.940144</td>\n","      <td>0.929803</td>\n","      <td>0.003308</td>\n","      <td>0.940101</td>\n","      <td>0.929951</td>\n","      <td>0.003262</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.989101</td>\n","      <td>0.986003</td>\n","      <td>0.001152</td>\n","      <td>0.989219</td>\n","      <td>0.985880</td>\n","      <td>0.001203</td>\n","      <td>0.989131</td>\n","      <td>0.985923</td>\n","      <td>0.001178</td>\n","      <td>0.952524</td>\n","      <td>...</td>\n","      <td>0.006487</td>\n","      <td>0.936819</td>\n","      <td>0.913685</td>\n","      <td>0.008962</td>\n","      <td>0.936070</td>\n","      <td>0.911626</td>\n","      <td>0.009268</td>\n","      <td>0.935949</td>\n","      <td>0.908673</td>\n","      <td>0.010440</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.987562</td>\n","      <td>0.983772</td>\n","      <td>0.001526</td>\n","      <td>0.987619</td>\n","      <td>0.982889</td>\n","      <td>0.001954</td>\n","      <td>0.987564</td>\n","      <td>0.983200</td>\n","      <td>0.001788</td>\n","      <td>0.957729</td>\n","      <td>...</td>\n","      <td>0.031670</td>\n","      <td>0.936363</td>\n","      <td>0.907132</td>\n","      <td>0.010221</td>\n","      <td>0.933250</td>\n","      <td>0.908493</td>\n","      <td>0.008989</td>\n","      <td>0.933150</td>\n","      <td>0.907248</td>\n","      <td>0.009539</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"7\" valign=\"top\">bert-base</th>\n","      <th>T1</th>\n","      <td>0.988275</td>\n","      <td>0.986896</td>\n","      <td>0.000539</td>\n","      <td>0.988384</td>\n","      <td>0.986924</td>\n","      <td>0.000558</td>\n","      <td>0.988305</td>\n","      <td>0.986905</td>\n","      <td>0.000541</td>\n","      <td>0.945973</td>\n","      <td>...</td>\n","      <td>0.010015</td>\n","      <td>0.927133</td>\n","      <td>0.923645</td>\n","      <td>0.001415</td>\n","      <td>0.926042</td>\n","      <td>0.921341</td>\n","      <td>0.001768</td>\n","      <td>0.926192</td>\n","      <td>0.922099</td>\n","      <td>0.001613</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.988046</td>\n","      <td>0.985607</td>\n","      <td>0.000889</td>\n","      <td>0.988106</td>\n","      <td>0.985672</td>\n","      <td>0.000873</td>\n","      <td>0.988070</td>\n","      <td>0.985632</td>\n","      <td>0.000893</td>\n","      <td>0.945103</td>\n","      <td>...</td>\n","      <td>0.009959</td>\n","      <td>0.920412</td>\n","      <td>0.917975</td>\n","      <td>0.000867</td>\n","      <td>0.918521</td>\n","      <td>0.916641</td>\n","      <td>0.000783</td>\n","      <td>0.918852</td>\n","      <td>0.917180</td>\n","      <td>0.000650</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.988825</td>\n","      <td>0.983998</td>\n","      <td>0.001578</td>\n","      <td>0.988941</td>\n","      <td>0.983585</td>\n","      <td>0.001747</td>\n","      <td>0.988859</td>\n","      <td>0.983743</td>\n","      <td>0.001671</td>\n","      <td>0.946859</td>\n","      <td>...</td>\n","      <td>0.004844</td>\n","      <td>0.926868</td>\n","      <td>0.920097</td>\n","      <td>0.002341</td>\n","      <td>0.924475</td>\n","      <td>0.918834</td>\n","      <td>0.001968</td>\n","      <td>0.924968</td>\n","      <td>0.919539</td>\n","      <td>0.001974</td>\n","    </tr>\n","    <tr>\n","      <th>T4</th>\n","      <td>0.664307</td>\n","      <td>0.195018</td>\n","      <td>0.178643</td>\n","      <td>0.492940</td>\n","      <td>0.324616</td>\n","      <td>0.055719</td>\n","      <td>0.418042</td>\n","      <td>0.270556</td>\n","      <td>0.058305</td>\n","      <td>0.461790</td>\n","      <td>...</td>\n","      <td>0.037842</td>\n","      <td>0.921739</td>\n","      <td>0.918282</td>\n","      <td>0.001298</td>\n","      <td>0.920715</td>\n","      <td>0.915700</td>\n","      <td>0.001842</td>\n","      <td>0.920854</td>\n","      <td>0.916076</td>\n","      <td>0.001753</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.988435</td>\n","      <td>0.982377</td>\n","      <td>0.002223</td>\n","      <td>0.988593</td>\n","      <td>0.982333</td>\n","      <td>0.002262</td>\n","      <td>0.988437</td>\n","      <td>0.982336</td>\n","      <td>0.002217</td>\n","      <td>0.944484</td>\n","      <td>...</td>\n","      <td>0.012299</td>\n","      <td>0.927143</td>\n","      <td>0.913169</td>\n","      <td>0.005176</td>\n","      <td>0.926355</td>\n","      <td>0.914134</td>\n","      <td>0.004696</td>\n","      <td>0.926672</td>\n","      <td>0.913217</td>\n","      <td>0.005008</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.988935</td>\n","      <td>0.982502</td>\n","      <td>0.002433</td>\n","      <td>0.989080</td>\n","      <td>0.982889</td>\n","      <td>0.002327</td>\n","      <td>0.988956</td>\n","      <td>0.982454</td>\n","      <td>0.002492</td>\n","      <td>0.945021</td>\n","      <td>...</td>\n","      <td>0.009803</td>\n","      <td>0.922013</td>\n","      <td>0.910831</td>\n","      <td>0.004343</td>\n","      <td>0.920715</td>\n","      <td>0.911313</td>\n","      <td>0.003835</td>\n","      <td>0.920889</td>\n","      <td>0.910897</td>\n","      <td>0.003954</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.987908</td>\n","      <td>0.983026</td>\n","      <td>0.001857</td>\n","      <td>0.988036</td>\n","      <td>0.983307</td>\n","      <td>0.001751</td>\n","      <td>0.987759</td>\n","      <td>0.982582</td>\n","      <td>0.001918</td>\n","      <td>0.945217</td>\n","      <td>...</td>\n","      <td>0.011889</td>\n","      <td>0.920768</td>\n","      <td>0.916316</td>\n","      <td>0.001844</td>\n","      <td>0.919461</td>\n","      <td>0.906926</td>\n","      <td>0.004630</td>\n","      <td>0.919563</td>\n","      <td>0.908317</td>\n","      <td>0.004084</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"7\" valign=\"top\">roberta-base</th>\n","      <th>T1</th>\n","      <td>0.987826</td>\n","      <td>0.968645</td>\n","      <td>0.007421</td>\n","      <td>0.987897</td>\n","      <td>0.969882</td>\n","      <td>0.006934</td>\n","      <td>0.987850</td>\n","      <td>0.968813</td>\n","      <td>0.007353</td>\n","      <td>0.952677</td>\n","      <td>...</td>\n","      <td>0.009372</td>\n","      <td>0.934250</td>\n","      <td>0.929058</td>\n","      <td>0.001898</td>\n","      <td>0.934190</td>\n","      <td>0.926982</td>\n","      <td>0.002342</td>\n","      <td>0.934093</td>\n","      <td>0.927217</td>\n","      <td>0.002272</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.988303</td>\n","      <td>0.986700</td>\n","      <td>0.000570</td>\n","      <td>0.988384</td>\n","      <td>0.986715</td>\n","      <td>0.000605</td>\n","      <td>0.988329</td>\n","      <td>0.986694</td>\n","      <td>0.000587</td>\n","      <td>0.952293</td>\n","      <td>...</td>\n","      <td>0.004836</td>\n","      <td>0.936081</td>\n","      <td>0.927822</td>\n","      <td>0.003073</td>\n","      <td>0.935443</td>\n","      <td>0.927922</td>\n","      <td>0.002789</td>\n","      <td>0.935578</td>\n","      <td>0.927755</td>\n","      <td>0.002883</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.988901</td>\n","      <td>0.986157</td>\n","      <td>0.000887</td>\n","      <td>0.988941</td>\n","      <td>0.986089</td>\n","      <td>0.000913</td>\n","      <td>0.988915</td>\n","      <td>0.986108</td>\n","      <td>0.000903</td>\n","      <td>0.951282</td>\n","      <td>...</td>\n","      <td>0.002267</td>\n","      <td>0.937320</td>\n","      <td>0.928950</td>\n","      <td>0.002946</td>\n","      <td>0.937010</td>\n","      <td>0.926669</td>\n","      <td>0.003604</td>\n","      <td>0.937046</td>\n","      <td>0.927069</td>\n","      <td>0.003476</td>\n","    </tr>\n","    <tr>\n","      <th>T4</th>\n","      <td>0.664321</td>\n","      <td>0.645879</td>\n","      <td>0.007210</td>\n","      <td>0.476386</td>\n","      <td>0.441678</td>\n","      <td>0.016612</td>\n","      <td>0.342407</td>\n","      <td>0.270708</td>\n","      <td>0.034454</td>\n","      <td>0.583433</td>\n","      <td>...</td>\n","      <td>0.013159</td>\n","      <td>0.927172</td>\n","      <td>0.919651</td>\n","      <td>0.002396</td>\n","      <td>0.926355</td>\n","      <td>0.919774</td>\n","      <td>0.002131</td>\n","      <td>0.926457</td>\n","      <td>0.919622</td>\n","      <td>0.002184</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.989165</td>\n","      <td>0.983657</td>\n","      <td>0.002170</td>\n","      <td>0.989219</td>\n","      <td>0.982472</td>\n","      <td>0.002649</td>\n","      <td>0.989172</td>\n","      <td>0.983125</td>\n","      <td>0.002448</td>\n","      <td>0.944738</td>\n","      <td>...</td>\n","      <td>0.012418</td>\n","      <td>0.935865</td>\n","      <td>0.919793</td>\n","      <td>0.005838</td>\n","      <td>0.935130</td>\n","      <td>0.912253</td>\n","      <td>0.007798</td>\n","      <td>0.935278</td>\n","      <td>0.913088</td>\n","      <td>0.007618</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.986707</td>\n","      <td>0.978421</td>\n","      <td>0.003474</td>\n","      <td>0.986784</td>\n","      <td>0.979064</td>\n","      <td>0.003248</td>\n","      <td>0.986715</td>\n","      <td>0.978287</td>\n","      <td>0.003517</td>\n","      <td>0.952338</td>\n","      <td>...</td>\n","      <td>0.012260</td>\n","      <td>0.927513</td>\n","      <td>0.923833</td>\n","      <td>0.001390</td>\n","      <td>0.928236</td>\n","      <td>0.922281</td>\n","      <td>0.002027</td>\n","      <td>0.927559</td>\n","      <td>0.922636</td>\n","      <td>0.001802</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.988230</td>\n","      <td>0.983090</td>\n","      <td>0.001930</td>\n","      <td>0.988245</td>\n","      <td>0.983376</td>\n","      <td>0.001797</td>\n","      <td>0.988224</td>\n","      <td>0.982965</td>\n","      <td>0.001952</td>\n","      <td>0.949587</td>\n","      <td>...</td>\n","      <td>0.023671</td>\n","      <td>0.930174</td>\n","      <td>0.915562</td>\n","      <td>0.005576</td>\n","      <td>0.929489</td>\n","      <td>0.916327</td>\n","      <td>0.004813</td>\n","      <td>0.929074</td>\n","      <td>0.915541</td>\n","      <td>0.005228</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>28 rows × 36 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ff60c60-dcc8-4c86-b6ac-8f8c5bddabc2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8ff60c60-dcc8-4c86-b6ac-8f8c5bddabc2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8ff60c60-dcc8-4c86-b6ac-8f8c5bddabc2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["##**Graded LE: Hyperlex**\n","It is reported the Spearman correlation between the median human rates contained in Hyperlex dataset and:\n"," - The calculated score by means of the logits (reported results in the paper).\n"," - The score considering only the probability to be an hyponym.\n"," - Instead of using the logits, the calculated probabilities for each label are used, except one of them (take into account that the sum of all probabilities is $1$, thus one of the values is useless for fitting a linear model)."],"metadata":{"id":"WtuJP0UsJjgU"}},{"cell_type":"code","source":["df_hyperlex_list = []\n","for d in ['hyperlex-lexical', 'hyperlex-random']:\n","    df_data_hyperlex_hyp = get_dataframe_results_measure(dict_res, d, 'hyp', ['correlation'])\n","    df_data_hyperlex_hyp.columns = pd.MultiIndex.from_tuples([(d,'hyp-correlation')])\n","    df_hyperlex_list.append(df_data_hyperlex_hyp)\n","\n","    df_data_hyperlex_logit = get_dataframe_results_measure(dict_res, d, 'spearman_logit', ['correlation'])\n","    df_data_hyperlex_logit.columns = pd.MultiIndex.from_tuples([(d,'logit-correlation')])\n","    df_hyperlex_list.append(df_data_hyperlex_logit)\n","\n","    df_data_hyperlex_prob = get_dataframe_results_measure(dict_res, d, 'spearman_prob', ['correlation'])\n","    df_data_hyperlex_prob.columns = pd.MultiIndex.from_tuples([(d,'prob-correlation')])\n","    df_hyperlex_list.append(df_data_hyperlex_prob)\n","\n","    df_data_hyperlex_nouns_logit = get_dataframe_results_measure(dict_res, d, 'spearman_nouns_logit', ['correlation'])\n","    df_data_hyperlex_nouns_logit.columns = pd.MultiIndex.from_tuples([(d,'noun-logit-correlation')])\n","    df_hyperlex_list.append(df_data_hyperlex_nouns_logit)\n","\n","    df_data_hyperlex_verbs_logit = get_dataframe_results_measure(dict_res, d, 'spearman_verbs_logit', ['correlation'])\n","    df_data_hyperlex_verbs_logit.columns = pd.MultiIndex.from_tuples([(d,'verb-logit-correlation')])\n","    df_hyperlex_list.append(df_data_hyperlex_verbs_logit)\n","\n","    df_data_hyperlex_nouns_prob = get_dataframe_results_measure(dict_res, d, 'spearman_nouns_prob', ['correlation'])\n","    df_data_hyperlex_nouns_prob.columns = pd.MultiIndex.from_tuples([(d,'noun-prob-correlation')])\n","    df_hyperlex_list.append(df_data_hyperlex_nouns_prob)\n","\n","    df_data_hyperlex_verbs_prob = get_dataframe_results_measure(dict_res, d, 'spearman_verbs_prob', ['correlation'])\n","    df_data_hyperlex_verbs_prob.columns = pd.MultiIndex.from_tuples([(d,'verb-prob-correlation')])\n","    df_hyperlex_list.append(df_data_hyperlex_verbs_prob)\n","\n","\n","df_data_hyperlex = pd.concat(df_hyperlex_list, axis=1)\n","df_data_hyperlex.sort_index(level=['model','template'], inplace=True)\n","df_data_hyperlex"],"metadata":{"id":"1gF2TlmAJpW9","colab":{"base_uri":"https://localhost:8080/","height":946},"outputId":"42a9ea36-c1a6-40bd-c139-a6c10a275f44"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                      hyperlex-lexical                                     \\\n","                       hyp-correlation logit-correlation prob-correlation   \n","model        template                                                       \n","Bert         T1               0.657046          0.686073         0.694415   \n","             T2               0.450562          0.402034         0.416582   \n","             T3               0.667674          0.746582         0.755574   \n","             TM1              0.671808          0.766412         0.753963   \n","             TM2              0.589105          0.656697         0.672861   \n","             TM3              0.686035          0.741279         0.755081   \n","Roberta      T1               0.738920          0.754927         0.771282   \n","             T2               0.375061          0.286757         0.297980   \n","             T3               0.636995          0.669128         0.671147   \n","             TM1              0.736504          0.788514         0.796706   \n","             TM2              0.600176          0.653700         0.669882   \n","             TM3              0.721263          0.794234         0.783369   \n","bert-base    T1               0.498647          0.471335         0.474081   \n","             T2               0.406193          0.374065         0.378994   \n","             T3               0.588330          0.614221         0.622301   \n","             TM1              0.569934          0.597293         0.599501   \n","             TM2              0.561259          0.574906         0.610851   \n","             TM3              0.573250          0.583948         0.579535   \n","roberta-base T1               0.651845          0.677077         0.725030   \n","             T2               0.483763          0.406815         0.400610   \n","             T3               0.641070          0.625525         0.664061   \n","             TM1              0.690944          0.736169         0.776089   \n","             TM2              0.641001          0.710913         0.725829   \n","             TM3              0.697356          0.757284         0.770732   \n","\n","                                                                     \\\n","                      noun-logit-correlation verb-logit-correlation   \n","model        template                                                 \n","Bert         T1                     0.737330               0.498642   \n","             T2                     0.433256               0.285916   \n","             T3                     0.781277               0.622566   \n","             TM1                    0.807058               0.672470   \n","             TM2                    0.716757               0.477823   \n","             TM3                    0.781051               0.632722   \n","Roberta      T1                     0.787916               0.531692   \n","             T2                     0.350415               0.063102   \n","             T3                     0.690485               0.515506   \n","             TM1                    0.836832               0.612222   \n","             TM2                    0.705038               0.417199   \n","             TM3                    0.828178               0.656274   \n","bert-base    T1                     0.556778               0.172960   \n","             T2                     0.445601               0.116163   \n","             T3                     0.690729               0.311820   \n","             TM1                    0.680286               0.379775   \n","             TM2                    0.656103               0.276512   \n","             TM3                    0.664762               0.355509   \n","roberta-base T1                     0.713328               0.542603   \n","             T2                     0.482727               0.166631   \n","             T3                     0.692522               0.391105   \n","             TM1                    0.799714               0.552940   \n","             TM2                    0.756986               0.525289   \n","             TM3                    0.806950               0.633745   \n","\n","                                                                   \\\n","                      noun-prob-correlation verb-prob-correlation   \n","model        template                                               \n","Bert         T1                    0.750145              0.459302   \n","             T2                    0.456257              0.248895   \n","             T3                    0.795455              0.597384   \n","             TM1                   0.794629              0.609317   \n","             TM2                   0.728138              0.481895   \n","             TM3                   0.793492              0.609348   \n","Roberta      T1                    0.808948              0.517498   \n","             T2                    0.374889             -0.008955   \n","             T3                    0.699184              0.485816   \n","             TM1                   0.829112              0.618363   \n","             TM2                   0.715934              0.410055   \n","             TM3                   0.827253              0.600486   \n","bert-base    T1                    0.551468              0.137220   \n","             T2                    0.442557              0.126524   \n","             T3                    0.713881              0.309381   \n","             TM1                   0.673157              0.267178   \n","             TM2                   0.685900              0.266175   \n","             TM3                   0.647579              0.316415   \n","roberta-base T1                    0.764511              0.547946   \n","             T2                    0.475401              0.085916   \n","             T3                    0.725598              0.441986   \n","             TM1                   0.819748              0.549569   \n","             TM2                   0.778836              0.442391   \n","             TM3                   0.808939              0.639037   \n","\n","                      hyperlex-random                                     \\\n","                      hyp-correlation logit-correlation prob-correlation   \n","model        template                                                      \n","Bert         T1              0.623897          0.643511         0.668539   \n","             T2              0.540876          0.577157         0.603452   \n","             T3              0.650930          0.727820         0.757310   \n","             TM1             0.721062          0.800457         0.790645   \n","             TM2             0.703471          0.778105         0.784275   \n","             TM3             0.737478          0.794417         0.799238   \n","Roberta      T1              0.708957          0.740859         0.757459   \n","             T2              0.096328          0.152353         0.146603   \n","             T3              0.712420          0.773941         0.794968   \n","             TM1             0.779260          0.828275         0.828471   \n","             TM2             0.627888          0.749403         0.743976   \n","             TM3             0.774364          0.814334         0.791946   \n","bert-base    T1              0.627959          0.642563         0.669358   \n","             T2              0.609193          0.625754         0.626871   \n","             T3              0.605028          0.638078         0.684352   \n","             TM1             0.663666          0.718852         0.714413   \n","             TM2             0.660960          0.706902         0.708351   \n","             TM3             0.655755          0.685267         0.694070   \n","roberta-base T1              0.683489          0.737337         0.743523   \n","             T2              0.608671          0.651969         0.634775   \n","             T3              0.705194          0.742221         0.772627   \n","             TM1             0.719304          0.795759         0.792388   \n","             TM2             0.717575          0.780942         0.786090   \n","             TM3             0.726303          0.782770         0.776317   \n","\n","                                                                     \\\n","                      noun-logit-correlation verb-logit-correlation   \n","model        template                                                 \n","Bert         T1                     0.653573               0.524790   \n","             T2                     0.585964               0.431753   \n","             T3                     0.741746               0.550663   \n","             TM1                    0.822060               0.576625   \n","             TM2                    0.803631               0.553331   \n","             TM3                    0.816571               0.577981   \n","Roberta      T1                     0.752877               0.583824   \n","             T2                     0.169537               0.030114   \n","             T3                     0.789695               0.630920   \n","             TM1                    0.839351               0.716252   \n","             TM2                    0.761168               0.645773   \n","             TM3                    0.830364               0.682727   \n","bert-base    T1                     0.666371               0.426226   \n","             T2                     0.657132               0.305781   \n","             T3                     0.669079               0.374907   \n","             TM1                    0.746955               0.427838   \n","             TM2                    0.743039               0.366064   \n","             TM3                    0.716521               0.416953   \n","roberta-base T1                     0.749482               0.594251   \n","             T2                     0.682594               0.376505   \n","             T3                     0.756931               0.636962   \n","             TM1                    0.811107               0.639123   \n","             TM2                    0.793191               0.663757   \n","             TM3                    0.795358               0.635163   \n","\n","                                                                   \n","                      noun-prob-correlation verb-prob-correlation  \n","model        template                                              \n","Bert         T1                    0.686033              0.490613  \n","             T2                    0.623506              0.391794  \n","             T3                    0.784944              0.482366  \n","             TM1                   0.817262              0.527390  \n","             TM2                   0.811488              0.538746  \n","             TM3                   0.832978              0.525753  \n","Roberta      T1                    0.779921              0.544862  \n","             T2                    0.165167              0.009852  \n","             T3                    0.815623              0.588373  \n","             TM1                   0.843571              0.672157  \n","             TM2                   0.757051              0.607138  \n","             TM3                   0.808761              0.618838  \n","bert-base    T1                    0.691809              0.427355  \n","             T2                    0.658178              0.325007  \n","             T3                    0.723588              0.347461  \n","             TM1                   0.752636              0.356874  \n","             TM2                   0.758504              0.230655  \n","             TM3                   0.721807              0.436931  \n","roberta-base T1                    0.757180              0.566824  \n","             T2                    0.660551              0.391212  \n","             T3                    0.787753              0.599196  \n","             TM1                   0.820118              0.546569  \n","             TM2                   0.808391              0.560856  \n","             TM3                   0.796483              0.556385  "],"text/html":["\n","  <div id=\"df-ff9a2774-a247-4de0-bf55-aa226de8a467\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th colspan=\"7\" halign=\"left\">hyperlex-lexical</th>\n","      <th colspan=\"7\" halign=\"left\">hyperlex-random</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>hyp-correlation</th>\n","      <th>logit-correlation</th>\n","      <th>prob-correlation</th>\n","      <th>noun-logit-correlation</th>\n","      <th>verb-logit-correlation</th>\n","      <th>noun-prob-correlation</th>\n","      <th>verb-prob-correlation</th>\n","      <th>hyp-correlation</th>\n","      <th>logit-correlation</th>\n","      <th>prob-correlation</th>\n","      <th>noun-logit-correlation</th>\n","      <th>verb-logit-correlation</th>\n","      <th>noun-prob-correlation</th>\n","      <th>verb-prob-correlation</th>\n","    </tr>\n","    <tr>\n","      <th>model</th>\n","      <th>template</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"6\" valign=\"top\">Bert</th>\n","      <th>T1</th>\n","      <td>0.657046</td>\n","      <td>0.686073</td>\n","      <td>0.694415</td>\n","      <td>0.737330</td>\n","      <td>0.498642</td>\n","      <td>0.750145</td>\n","      <td>0.459302</td>\n","      <td>0.623897</td>\n","      <td>0.643511</td>\n","      <td>0.668539</td>\n","      <td>0.653573</td>\n","      <td>0.524790</td>\n","      <td>0.686033</td>\n","      <td>0.490613</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.450562</td>\n","      <td>0.402034</td>\n","      <td>0.416582</td>\n","      <td>0.433256</td>\n","      <td>0.285916</td>\n","      <td>0.456257</td>\n","      <td>0.248895</td>\n","      <td>0.540876</td>\n","      <td>0.577157</td>\n","      <td>0.603452</td>\n","      <td>0.585964</td>\n","      <td>0.431753</td>\n","      <td>0.623506</td>\n","      <td>0.391794</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.667674</td>\n","      <td>0.746582</td>\n","      <td>0.755574</td>\n","      <td>0.781277</td>\n","      <td>0.622566</td>\n","      <td>0.795455</td>\n","      <td>0.597384</td>\n","      <td>0.650930</td>\n","      <td>0.727820</td>\n","      <td>0.757310</td>\n","      <td>0.741746</td>\n","      <td>0.550663</td>\n","      <td>0.784944</td>\n","      <td>0.482366</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.671808</td>\n","      <td>0.766412</td>\n","      <td>0.753963</td>\n","      <td>0.807058</td>\n","      <td>0.672470</td>\n","      <td>0.794629</td>\n","      <td>0.609317</td>\n","      <td>0.721062</td>\n","      <td>0.800457</td>\n","      <td>0.790645</td>\n","      <td>0.822060</td>\n","      <td>0.576625</td>\n","      <td>0.817262</td>\n","      <td>0.527390</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.589105</td>\n","      <td>0.656697</td>\n","      <td>0.672861</td>\n","      <td>0.716757</td>\n","      <td>0.477823</td>\n","      <td>0.728138</td>\n","      <td>0.481895</td>\n","      <td>0.703471</td>\n","      <td>0.778105</td>\n","      <td>0.784275</td>\n","      <td>0.803631</td>\n","      <td>0.553331</td>\n","      <td>0.811488</td>\n","      <td>0.538746</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.686035</td>\n","      <td>0.741279</td>\n","      <td>0.755081</td>\n","      <td>0.781051</td>\n","      <td>0.632722</td>\n","      <td>0.793492</td>\n","      <td>0.609348</td>\n","      <td>0.737478</td>\n","      <td>0.794417</td>\n","      <td>0.799238</td>\n","      <td>0.816571</td>\n","      <td>0.577981</td>\n","      <td>0.832978</td>\n","      <td>0.525753</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"6\" valign=\"top\">Roberta</th>\n","      <th>T1</th>\n","      <td>0.738920</td>\n","      <td>0.754927</td>\n","      <td>0.771282</td>\n","      <td>0.787916</td>\n","      <td>0.531692</td>\n","      <td>0.808948</td>\n","      <td>0.517498</td>\n","      <td>0.708957</td>\n","      <td>0.740859</td>\n","      <td>0.757459</td>\n","      <td>0.752877</td>\n","      <td>0.583824</td>\n","      <td>0.779921</td>\n","      <td>0.544862</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.375061</td>\n","      <td>0.286757</td>\n","      <td>0.297980</td>\n","      <td>0.350415</td>\n","      <td>0.063102</td>\n","      <td>0.374889</td>\n","      <td>-0.008955</td>\n","      <td>0.096328</td>\n","      <td>0.152353</td>\n","      <td>0.146603</td>\n","      <td>0.169537</td>\n","      <td>0.030114</td>\n","      <td>0.165167</td>\n","      <td>0.009852</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.636995</td>\n","      <td>0.669128</td>\n","      <td>0.671147</td>\n","      <td>0.690485</td>\n","      <td>0.515506</td>\n","      <td>0.699184</td>\n","      <td>0.485816</td>\n","      <td>0.712420</td>\n","      <td>0.773941</td>\n","      <td>0.794968</td>\n","      <td>0.789695</td>\n","      <td>0.630920</td>\n","      <td>0.815623</td>\n","      <td>0.588373</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.736504</td>\n","      <td>0.788514</td>\n","      <td>0.796706</td>\n","      <td>0.836832</td>\n","      <td>0.612222</td>\n","      <td>0.829112</td>\n","      <td>0.618363</td>\n","      <td>0.779260</td>\n","      <td>0.828275</td>\n","      <td>0.828471</td>\n","      <td>0.839351</td>\n","      <td>0.716252</td>\n","      <td>0.843571</td>\n","      <td>0.672157</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.600176</td>\n","      <td>0.653700</td>\n","      <td>0.669882</td>\n","      <td>0.705038</td>\n","      <td>0.417199</td>\n","      <td>0.715934</td>\n","      <td>0.410055</td>\n","      <td>0.627888</td>\n","      <td>0.749403</td>\n","      <td>0.743976</td>\n","      <td>0.761168</td>\n","      <td>0.645773</td>\n","      <td>0.757051</td>\n","      <td>0.607138</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.721263</td>\n","      <td>0.794234</td>\n","      <td>0.783369</td>\n","      <td>0.828178</td>\n","      <td>0.656274</td>\n","      <td>0.827253</td>\n","      <td>0.600486</td>\n","      <td>0.774364</td>\n","      <td>0.814334</td>\n","      <td>0.791946</td>\n","      <td>0.830364</td>\n","      <td>0.682727</td>\n","      <td>0.808761</td>\n","      <td>0.618838</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"6\" valign=\"top\">bert-base</th>\n","      <th>T1</th>\n","      <td>0.498647</td>\n","      <td>0.471335</td>\n","      <td>0.474081</td>\n","      <td>0.556778</td>\n","      <td>0.172960</td>\n","      <td>0.551468</td>\n","      <td>0.137220</td>\n","      <td>0.627959</td>\n","      <td>0.642563</td>\n","      <td>0.669358</td>\n","      <td>0.666371</td>\n","      <td>0.426226</td>\n","      <td>0.691809</td>\n","      <td>0.427355</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.406193</td>\n","      <td>0.374065</td>\n","      <td>0.378994</td>\n","      <td>0.445601</td>\n","      <td>0.116163</td>\n","      <td>0.442557</td>\n","      <td>0.126524</td>\n","      <td>0.609193</td>\n","      <td>0.625754</td>\n","      <td>0.626871</td>\n","      <td>0.657132</td>\n","      <td>0.305781</td>\n","      <td>0.658178</td>\n","      <td>0.325007</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.588330</td>\n","      <td>0.614221</td>\n","      <td>0.622301</td>\n","      <td>0.690729</td>\n","      <td>0.311820</td>\n","      <td>0.713881</td>\n","      <td>0.309381</td>\n","      <td>0.605028</td>\n","      <td>0.638078</td>\n","      <td>0.684352</td>\n","      <td>0.669079</td>\n","      <td>0.374907</td>\n","      <td>0.723588</td>\n","      <td>0.347461</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.569934</td>\n","      <td>0.597293</td>\n","      <td>0.599501</td>\n","      <td>0.680286</td>\n","      <td>0.379775</td>\n","      <td>0.673157</td>\n","      <td>0.267178</td>\n","      <td>0.663666</td>\n","      <td>0.718852</td>\n","      <td>0.714413</td>\n","      <td>0.746955</td>\n","      <td>0.427838</td>\n","      <td>0.752636</td>\n","      <td>0.356874</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.561259</td>\n","      <td>0.574906</td>\n","      <td>0.610851</td>\n","      <td>0.656103</td>\n","      <td>0.276512</td>\n","      <td>0.685900</td>\n","      <td>0.266175</td>\n","      <td>0.660960</td>\n","      <td>0.706902</td>\n","      <td>0.708351</td>\n","      <td>0.743039</td>\n","      <td>0.366064</td>\n","      <td>0.758504</td>\n","      <td>0.230655</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.573250</td>\n","      <td>0.583948</td>\n","      <td>0.579535</td>\n","      <td>0.664762</td>\n","      <td>0.355509</td>\n","      <td>0.647579</td>\n","      <td>0.316415</td>\n","      <td>0.655755</td>\n","      <td>0.685267</td>\n","      <td>0.694070</td>\n","      <td>0.716521</td>\n","      <td>0.416953</td>\n","      <td>0.721807</td>\n","      <td>0.436931</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"6\" valign=\"top\">roberta-base</th>\n","      <th>T1</th>\n","      <td>0.651845</td>\n","      <td>0.677077</td>\n","      <td>0.725030</td>\n","      <td>0.713328</td>\n","      <td>0.542603</td>\n","      <td>0.764511</td>\n","      <td>0.547946</td>\n","      <td>0.683489</td>\n","      <td>0.737337</td>\n","      <td>0.743523</td>\n","      <td>0.749482</td>\n","      <td>0.594251</td>\n","      <td>0.757180</td>\n","      <td>0.566824</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.483763</td>\n","      <td>0.406815</td>\n","      <td>0.400610</td>\n","      <td>0.482727</td>\n","      <td>0.166631</td>\n","      <td>0.475401</td>\n","      <td>0.085916</td>\n","      <td>0.608671</td>\n","      <td>0.651969</td>\n","      <td>0.634775</td>\n","      <td>0.682594</td>\n","      <td>0.376505</td>\n","      <td>0.660551</td>\n","      <td>0.391212</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.641070</td>\n","      <td>0.625525</td>\n","      <td>0.664061</td>\n","      <td>0.692522</td>\n","      <td>0.391105</td>\n","      <td>0.725598</td>\n","      <td>0.441986</td>\n","      <td>0.705194</td>\n","      <td>0.742221</td>\n","      <td>0.772627</td>\n","      <td>0.756931</td>\n","      <td>0.636962</td>\n","      <td>0.787753</td>\n","      <td>0.599196</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.690944</td>\n","      <td>0.736169</td>\n","      <td>0.776089</td>\n","      <td>0.799714</td>\n","      <td>0.552940</td>\n","      <td>0.819748</td>\n","      <td>0.549569</td>\n","      <td>0.719304</td>\n","      <td>0.795759</td>\n","      <td>0.792388</td>\n","      <td>0.811107</td>\n","      <td>0.639123</td>\n","      <td>0.820118</td>\n","      <td>0.546569</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.641001</td>\n","      <td>0.710913</td>\n","      <td>0.725829</td>\n","      <td>0.756986</td>\n","      <td>0.525289</td>\n","      <td>0.778836</td>\n","      <td>0.442391</td>\n","      <td>0.717575</td>\n","      <td>0.780942</td>\n","      <td>0.786090</td>\n","      <td>0.793191</td>\n","      <td>0.663757</td>\n","      <td>0.808391</td>\n","      <td>0.560856</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.697356</td>\n","      <td>0.757284</td>\n","      <td>0.770732</td>\n","      <td>0.806950</td>\n","      <td>0.633745</td>\n","      <td>0.808939</td>\n","      <td>0.639037</td>\n","      <td>0.726303</td>\n","      <td>0.782770</td>\n","      <td>0.776317</td>\n","      <td>0.795358</td>\n","      <td>0.635163</td>\n","      <td>0.796483</td>\n","      <td>0.556385</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff9a2774-a247-4de0-bf55-aa226de8a467')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ff9a2774-a247-4de0-bf55-aa226de8a467 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ff9a2774-a247-4de0-bf55-aa226de8a467');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["### **Hyperlex: Reported results in the paper**"],"metadata":{"id":"f0xNZFsjH1vX"}},{"cell_type":"code","source":["columns_paper =[(\"hyperlex-random\", 'logit-correlation'),(\"hyperlex-random\", 'noun-logit-correlation'), (\"hyperlex-random\", 'verb-logit-correlation'),\n","                (\"hyperlex-lexical\", 'logit-correlation'),(\"hyperlex-lexical\", 'noun-logit-correlation'), (\"hyperlex-lexical\", 'verb-logit-correlation')]\n","df_res_hyperlex_paper = df_data_hyperlex[columns_paper]\n","df_res_hyperlex_paper\n","df_res_hyperlex_paper.to_csv(\"datos.csv\")"],"metadata":{"id":"isicaq2yCP5n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SOTAS_FILE_REST = DIR_RESULTS + 'sotas_results_literature/hyperlex_Sotas.txt'\n","df_hyperlex_sotas = pd.read_csv(SOTAS_FILE_REST, header=[0,1], index_col=[0], skipinitialspace=True)\n","\n","multi_row_tuples = list(zip(['Sota']*df_hyperlex_sotas.shape[0], list(df_hyperlex_sotas.index)))\n","multi_row = pd.MultiIndex.from_tuples(multi_row_tuples)\n","df_hyperlex_sotas.index=multi_row\n","df_res_sotas_hyperlex = pd.concat([df_res_hyperlex_paper,df_hyperlex_sotas])\n","df_res_sotas_hyperlex"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6M--RnvGEtN6","outputId":"2e9af251-cffe-4b56-daf4-14883205ace9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                        hyperlex-random                         \\\n","                      logit-correlation noun-logit-correlation   \n","model        template                                            \n","Bert         T1                0.643511               0.653573   \n","             T2                0.577157               0.585964   \n","             T3                0.727820               0.741746   \n","             TM1               0.800457                0.82206   \n","             TM2               0.778105               0.803631   \n","             TM3               0.794417               0.816571   \n","Roberta      T1                0.740859               0.752877   \n","             T2                0.152353               0.169537   \n","             T3                0.773941               0.789695   \n","             TM1               0.828275               0.839351   \n","             TM2               0.749403               0.761168   \n","             TM3               0.814334               0.830364   \n","bert-base    T1                0.642563               0.666371   \n","             T2                0.625754               0.657132   \n","             T3                0.638078               0.669079   \n","             TM1               0.718852               0.746955   \n","             TM2               0.706902               0.743039   \n","             TM3               0.685267               0.716521   \n","roberta-base T1                0.737337               0.749482   \n","             T2                0.651969               0.682594   \n","             T3                0.742221               0.756931   \n","             TM1               0.795759               0.811107   \n","             TM2               0.780942               0.793191   \n","             TM3               0.782770               0.795358   \n","Sota         LEAR              0.686000                   0.71   \n","             SDNS              0.692000                     na   \n","             GLEN              0.520000                     na   \n","             POSTLE            0.686000                     na   \n","             LexSub            0.533000                     na   \n","             HF                0.690000                     na   \n","\n","                                              hyperlex-lexical  \\\n","                      verb-logit-correlation logit-correlation   \n","model        template                                            \n","Bert         T1                      0.52479          0.686073   \n","             T2                     0.431753          0.402034   \n","             T3                     0.550663          0.746582   \n","             TM1                    0.576625          0.766412   \n","             TM2                    0.553331          0.656697   \n","             TM3                    0.577981          0.741279   \n","Roberta      T1                     0.583824          0.754927   \n","             T2                     0.030114          0.286757   \n","             T3                      0.63092          0.669128   \n","             TM1                    0.716252          0.788514   \n","             TM2                    0.645773            0.6537   \n","             TM3                    0.682727          0.794234   \n","bert-base    T1                     0.426226          0.471335   \n","             T2                     0.305781          0.374065   \n","             T3                     0.374907          0.614221   \n","             TM1                    0.427838          0.597293   \n","             TM2                    0.366064          0.574906   \n","             TM3                    0.416953          0.583948   \n","roberta-base T1                     0.594251          0.677077   \n","             T2                     0.376505          0.406815   \n","             T3                     0.636962          0.625525   \n","             TM1                    0.639123          0.736169   \n","             TM2                    0.663757          0.710913   \n","             TM3                    0.635163          0.757284   \n","Sota         LEAR                         na             0.174   \n","             SDNS                         na             0.544   \n","             GLEN                         na             0.481   \n","             POSTLE                       na                na   \n","             LexSub                       na                na   \n","             HF                           na                na   \n","\n","                                                                     \n","                      noun-logit-correlation verb-logit-correlation  \n","model        template                                                \n","Bert         T1                      0.73733               0.498642  \n","             T2                     0.433256               0.285916  \n","             T3                     0.781277               0.622566  \n","             TM1                    0.807058                0.67247  \n","             TM2                    0.716757               0.477823  \n","             TM3                    0.781051               0.632722  \n","Roberta      T1                     0.787916               0.531692  \n","             T2                     0.350415               0.063102  \n","             T3                     0.690485               0.515506  \n","             TM1                    0.836832               0.612222  \n","             TM2                    0.705038               0.417199  \n","             TM3                    0.828178               0.656274  \n","bert-base    T1                     0.556778                0.17296  \n","             T2                     0.445601               0.116163  \n","             T3                     0.690729                0.31182  \n","             TM1                    0.680286               0.379775  \n","             TM2                    0.656103               0.276512  \n","             TM3                    0.664762               0.355509  \n","roberta-base T1                     0.713328               0.542603  \n","             T2                     0.482727               0.166631  \n","             T3                     0.692522               0.391105  \n","             TM1                    0.799714                0.55294  \n","             TM2                    0.756986               0.525289  \n","             TM3                     0.80695               0.633745  \n","Sota         LEAR                         na                     na  \n","             SDNS                         na                     na  \n","             GLEN                         na                     na  \n","             POSTLE                     0.60                     na  \n","             LexSub                       na                     na  \n","             HF                           na                     na  "],"text/html":["\n","  <div id=\"df-d288624f-65f4-4850-842d-ea06680d6f51\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th colspan=\"3\" halign=\"left\">hyperlex-random</th>\n","      <th colspan=\"3\" halign=\"left\">hyperlex-lexical</th>\n","    </tr>\n","    <tr>\n","      <th></th>\n","      <th></th>\n","      <th>logit-correlation</th>\n","      <th>noun-logit-correlation</th>\n","      <th>verb-logit-correlation</th>\n","      <th>logit-correlation</th>\n","      <th>noun-logit-correlation</th>\n","      <th>verb-logit-correlation</th>\n","    </tr>\n","    <tr>\n","      <th>model</th>\n","      <th>template</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"6\" valign=\"top\">Bert</th>\n","      <th>T1</th>\n","      <td>0.643511</td>\n","      <td>0.653573</td>\n","      <td>0.52479</td>\n","      <td>0.686073</td>\n","      <td>0.73733</td>\n","      <td>0.498642</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.577157</td>\n","      <td>0.585964</td>\n","      <td>0.431753</td>\n","      <td>0.402034</td>\n","      <td>0.433256</td>\n","      <td>0.285916</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.727820</td>\n","      <td>0.741746</td>\n","      <td>0.550663</td>\n","      <td>0.746582</td>\n","      <td>0.781277</td>\n","      <td>0.622566</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.800457</td>\n","      <td>0.82206</td>\n","      <td>0.576625</td>\n","      <td>0.766412</td>\n","      <td>0.807058</td>\n","      <td>0.67247</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.778105</td>\n","      <td>0.803631</td>\n","      <td>0.553331</td>\n","      <td>0.656697</td>\n","      <td>0.716757</td>\n","      <td>0.477823</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.794417</td>\n","      <td>0.816571</td>\n","      <td>0.577981</td>\n","      <td>0.741279</td>\n","      <td>0.781051</td>\n","      <td>0.632722</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"6\" valign=\"top\">Roberta</th>\n","      <th>T1</th>\n","      <td>0.740859</td>\n","      <td>0.752877</td>\n","      <td>0.583824</td>\n","      <td>0.754927</td>\n","      <td>0.787916</td>\n","      <td>0.531692</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.152353</td>\n","      <td>0.169537</td>\n","      <td>0.030114</td>\n","      <td>0.286757</td>\n","      <td>0.350415</td>\n","      <td>0.063102</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.773941</td>\n","      <td>0.789695</td>\n","      <td>0.63092</td>\n","      <td>0.669128</td>\n","      <td>0.690485</td>\n","      <td>0.515506</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.828275</td>\n","      <td>0.839351</td>\n","      <td>0.716252</td>\n","      <td>0.788514</td>\n","      <td>0.836832</td>\n","      <td>0.612222</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.749403</td>\n","      <td>0.761168</td>\n","      <td>0.645773</td>\n","      <td>0.6537</td>\n","      <td>0.705038</td>\n","      <td>0.417199</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.814334</td>\n","      <td>0.830364</td>\n","      <td>0.682727</td>\n","      <td>0.794234</td>\n","      <td>0.828178</td>\n","      <td>0.656274</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"6\" valign=\"top\">bert-base</th>\n","      <th>T1</th>\n","      <td>0.642563</td>\n","      <td>0.666371</td>\n","      <td>0.426226</td>\n","      <td>0.471335</td>\n","      <td>0.556778</td>\n","      <td>0.17296</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.625754</td>\n","      <td>0.657132</td>\n","      <td>0.305781</td>\n","      <td>0.374065</td>\n","      <td>0.445601</td>\n","      <td>0.116163</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.638078</td>\n","      <td>0.669079</td>\n","      <td>0.374907</td>\n","      <td>0.614221</td>\n","      <td>0.690729</td>\n","      <td>0.31182</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.718852</td>\n","      <td>0.746955</td>\n","      <td>0.427838</td>\n","      <td>0.597293</td>\n","      <td>0.680286</td>\n","      <td>0.379775</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.706902</td>\n","      <td>0.743039</td>\n","      <td>0.366064</td>\n","      <td>0.574906</td>\n","      <td>0.656103</td>\n","      <td>0.276512</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.685267</td>\n","      <td>0.716521</td>\n","      <td>0.416953</td>\n","      <td>0.583948</td>\n","      <td>0.664762</td>\n","      <td>0.355509</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"6\" valign=\"top\">roberta-base</th>\n","      <th>T1</th>\n","      <td>0.737337</td>\n","      <td>0.749482</td>\n","      <td>0.594251</td>\n","      <td>0.677077</td>\n","      <td>0.713328</td>\n","      <td>0.542603</td>\n","    </tr>\n","    <tr>\n","      <th>T2</th>\n","      <td>0.651969</td>\n","      <td>0.682594</td>\n","      <td>0.376505</td>\n","      <td>0.406815</td>\n","      <td>0.482727</td>\n","      <td>0.166631</td>\n","    </tr>\n","    <tr>\n","      <th>T3</th>\n","      <td>0.742221</td>\n","      <td>0.756931</td>\n","      <td>0.636962</td>\n","      <td>0.625525</td>\n","      <td>0.692522</td>\n","      <td>0.391105</td>\n","    </tr>\n","    <tr>\n","      <th>TM1</th>\n","      <td>0.795759</td>\n","      <td>0.811107</td>\n","      <td>0.639123</td>\n","      <td>0.736169</td>\n","      <td>0.799714</td>\n","      <td>0.55294</td>\n","    </tr>\n","    <tr>\n","      <th>TM2</th>\n","      <td>0.780942</td>\n","      <td>0.793191</td>\n","      <td>0.663757</td>\n","      <td>0.710913</td>\n","      <td>0.756986</td>\n","      <td>0.525289</td>\n","    </tr>\n","    <tr>\n","      <th>TM3</th>\n","      <td>0.782770</td>\n","      <td>0.795358</td>\n","      <td>0.635163</td>\n","      <td>0.757284</td>\n","      <td>0.80695</td>\n","      <td>0.633745</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"6\" valign=\"top\">Sota</th>\n","      <th>LEAR</th>\n","      <td>0.686000</td>\n","      <td>0.71</td>\n","      <td>na</td>\n","      <td>0.174</td>\n","      <td>na</td>\n","      <td>na</td>\n","    </tr>\n","    <tr>\n","      <th>SDNS</th>\n","      <td>0.692000</td>\n","      <td>na</td>\n","      <td>na</td>\n","      <td>0.544</td>\n","      <td>na</td>\n","      <td>na</td>\n","    </tr>\n","    <tr>\n","      <th>GLEN</th>\n","      <td>0.520000</td>\n","      <td>na</td>\n","      <td>na</td>\n","      <td>0.481</td>\n","      <td>na</td>\n","      <td>na</td>\n","    </tr>\n","    <tr>\n","      <th>POSTLE</th>\n","      <td>0.686000</td>\n","      <td>na</td>\n","      <td>na</td>\n","      <td>na</td>\n","      <td>0.60</td>\n","      <td>na</td>\n","    </tr>\n","    <tr>\n","      <th>LexSub</th>\n","      <td>0.533000</td>\n","      <td>na</td>\n","      <td>na</td>\n","      <td>na</td>\n","      <td>na</td>\n","      <td>na</td>\n","    </tr>\n","    <tr>\n","      <th>HF</th>\n","      <td>0.690000</td>\n","      <td>na</td>\n","      <td>na</td>\n","      <td>na</td>\n","      <td>na</td>\n","      <td>na</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d288624f-65f4-4850-842d-ea06680d6f51')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-d288624f-65f4-4850-842d-ea06680d6f51 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d288624f-65f4-4850-842d-ea06680d6f51');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["#Graphs"],"metadata":{"id":"qF_nqf4495GH"}},{"cell_type":"markdown","source":["First some plots to visualize the best performing model and template per dataset. The worse performing ones are excluded to obtain better visualization. Used boxplots for visualization to also observe the variability of the 5 iterations conducted per experiment."],"metadata":{"id":"864nTZEN4p2N"}},{"cell_type":"code","source":["preds_plot = []\n","model_plot = []\n","template_plot = []\n","dataset_plot = []\n","\n","for dataset in dict_res:\n","  if dataset == 'cogalexv':\n","    for model in dict_res['cogalexv']:\n","      for template in dict_res['cogalexv'][model]:\n","        for i in dict_res['cogalexv'][model][template]['report']:\n","          preds_plot.append(i['weighted f1-score not random'])\n","          template_plot.append(templates2abrev[template])\n","          model_plot.append(models2abrev[model])\n","          dataset_plot.append(dataset)\n","  else:\n","    for model in dict_res[dataset]:\n","      for template in dict_res[dataset][model]:\n","        for i in dict_res[dataset][model][template]['report']:\n","          preds_plot.append(i['weighted avg']['f1-score'])\n","          template_plot.append(templates2abrev[template])\n","          model_plot.append(models2abrev[model])\n","          dataset_plot.append(dataset)\n","\n","df_plot = plot = pd.DataFrame([preds_plot, model_plot, template_plot, dataset_plot])\n","df_plot = df_plot.T\n","df_plot.columns = ['preds', 'model', 'template', 'dataset']\n","df_plot['label'] = df_plot.model.str.cat(df_plot.template)"],"metadata":{"id":"o90jSwSoTXpe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_plot_prov = df_plot[df_plot['preds']>0.7] #just take weight averages higher than 0.7\n","#to avoid the ones in which data didnt converge and visualize better.\n","#to see al data, comment above line, and change data below to 'df_plot'\n","sns.boxplot(data = df_plot_prov, x=\"template\", y=\"preds\", hue=\"dataset\")"],"metadata":{"id":"FG0N6zZCSGDL","colab":{"base_uri":"https://localhost:8080/","height":297},"outputId":"7f5221cd-0659-4398-e7c6-13712bc918b1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f8d66f48be0>"]},"metadata":{},"execution_count":26},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["#df_plot_prov = df_plot[df_plot['preds']>0.7]\n","sns.boxplot(data = df_plot, x=\"model\", y=\"preds\", hue=\"dataset\")"],"metadata":{"id":"j9xRT9EUXyhq","colab":{"base_uri":"https://localhost:8080/","height":296},"outputId":"2721d295-53f1-45d0-85ac-1cef663ced0f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f8d66b2d3a0>"]},"metadata":{},"execution_count":27},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["Cogalexv weighed f1 of all categories compared to SOTA"],"metadata":{"id":"-RapkEHxa6YQ"}},{"cell_type":"code","source":["dfm_cogalexv = df_res_sotas_cogalexv.T\n","dfm_cogalexv = pd.melt(dfm_cogalexv)\n","dfm_cogalexv"],"metadata":{"id":"jmG3HwxTcTE1","colab":{"base_uri":"https://localhost:8080/","height":424},"outputId":"e919e2e9-55b2-4dae-c7f1-d89c8beb6f2c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    model template     value\n","0    Bert       T1  0.770474\n","1    Bert       T1  0.680452\n","2    Bert       T1  0.715095\n","3    Bert       T1  0.563975\n","4    Bert       T1  0.690274\n","..    ...      ...       ...\n","155  Sota  RelBert  0.794000\n","156  Sota  RelBert  0.616000\n","157  Sota  RelBert  0.702000\n","158  Sota  RelBert  0.505000\n","159  Sota  RelBert  0.664000\n","\n","[160 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-6595e753-2e27-4147-8686-24f53d3363e2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>template</th>\n","      <th>value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Bert</td>\n","      <td>T1</td>\n","      <td>0.770474</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Bert</td>\n","      <td>T1</td>\n","      <td>0.680452</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Bert</td>\n","      <td>T1</td>\n","      <td>0.715095</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Bert</td>\n","      <td>T1</td>\n","      <td>0.563975</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Bert</td>\n","      <td>T1</td>\n","      <td>0.690274</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>155</th>\n","      <td>Sota</td>\n","      <td>RelBert</td>\n","      <td>0.794000</td>\n","    </tr>\n","    <tr>\n","      <th>156</th>\n","      <td>Sota</td>\n","      <td>RelBert</td>\n","      <td>0.616000</td>\n","    </tr>\n","    <tr>\n","      <th>157</th>\n","      <td>Sota</td>\n","      <td>RelBert</td>\n","      <td>0.702000</td>\n","    </tr>\n","    <tr>\n","      <th>158</th>\n","      <td>Sota</td>\n","      <td>RelBert</td>\n","      <td>0.505000</td>\n","    </tr>\n","    <tr>\n","      <th>159</th>\n","      <td>Sota</td>\n","      <td>RelBert</td>\n","      <td>0.664000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>160 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6595e753-2e27-4147-8686-24f53d3363e2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6595e753-2e27-4147-8686-24f53d3363e2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6595e753-2e27-4147-8686-24f53d3363e2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["sns.barplot(data=dfm_cogalexv, x= 'template', y='value', hue='model')"],"metadata":{"id":"dbpZZl5CbbtG","colab":{"base_uri":"https://localhost:8080/","height":296},"outputId":"20952f45-439d-434c-f607-96db621e278e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f8d66441b20>"]},"metadata":{},"execution_count":29},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["sns.barplot(data=dfm_cogalexv, x= 'model', y='value', hue='template')"],"metadata":{"id":"RvWF7kIQfhf4","colab":{"base_uri":"https://localhost:8080/","height":296},"outputId":"56ef40d3-3b72-4e30-f115-6e38218e9053"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f8d662be940>"]},"metadata":{},"execution_count":30},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["Bert Large experiments (the ones with better results and less variability on first sight), with T1(simplest template) compared to SOTA with bar plots. Here variability is not taken into account, just overall f1 weighed score."],"metadata":{"id":"WGdhfizEf4Ek"}},{"cell_type":"code","source":["compare_f1_sota = pd.DataFrame()\n","for dataset in ['K&H+N', 'BLESS', 'EVALution', 'ROOT09']:\n","  df_prov = pd.melt(df_res_sotas[dataset].T)\n","  df_prov['dataset'] = dataset\n","  compare_f1_sota = pd.concat([df_prov, compare_f1_sota])\n","\n"],"metadata":{"id":"KFE_jBFmoPzN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["compare_f1_sota"],"metadata":{"id":"9x3ylhKjvODr","colab":{"base_uri":"https://localhost:8080/","height":424},"outputId":"d01fc567-eb69-4a38-97ff-6256dd01aa0e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   model  template     value dataset\n","0   Bert        T1  0.926534  ROOT09\n","1   Bert        T1  0.926418  ROOT09\n","2   Bert        T1  0.926258  ROOT09\n","3   Bert        T2  0.930032  ROOT09\n","4   Bert        T2  0.928549  ROOT09\n","..   ...       ...       ...     ...\n","91  Sota  SphereRE  0.989000   K&H+N\n","92  Sota  SphereRE  0.990000   K&H+N\n","93  Sota   RelBERT       NaN   K&H+N\n","94  Sota   RelBERT       NaN   K&H+N\n","95  Sota   RelBERT  0.949000   K&H+N\n","\n","[384 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-510eeb52-a799-4c96-a998-350d28672e58\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>model</th>\n","      <th>template</th>\n","      <th>value</th>\n","      <th>dataset</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Bert</td>\n","      <td>T1</td>\n","      <td>0.926534</td>\n","      <td>ROOT09</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Bert</td>\n","      <td>T1</td>\n","      <td>0.926418</td>\n","      <td>ROOT09</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Bert</td>\n","      <td>T1</td>\n","      <td>0.926258</td>\n","      <td>ROOT09</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Bert</td>\n","      <td>T2</td>\n","      <td>0.930032</td>\n","      <td>ROOT09</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Bert</td>\n","      <td>T2</td>\n","      <td>0.928549</td>\n","      <td>ROOT09</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>91</th>\n","      <td>Sota</td>\n","      <td>SphereRE</td>\n","      <td>0.989000</td>\n","      <td>K&amp;H+N</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>Sota</td>\n","      <td>SphereRE</td>\n","      <td>0.990000</td>\n","      <td>K&amp;H+N</td>\n","    </tr>\n","    <tr>\n","      <th>93</th>\n","      <td>Sota</td>\n","      <td>RelBERT</td>\n","      <td>NaN</td>\n","      <td>K&amp;H+N</td>\n","    </tr>\n","    <tr>\n","      <th>94</th>\n","      <td>Sota</td>\n","      <td>RelBERT</td>\n","      <td>NaN</td>\n","      <td>K&amp;H+N</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>Sota</td>\n","      <td>RelBERT</td>\n","      <td>0.949000</td>\n","      <td>K&amp;H+N</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>384 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-510eeb52-a799-4c96-a998-350d28672e58')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-510eeb52-a799-4c96-a998-350d28672e58 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-510eeb52-a799-4c96-a998-350d28672e58');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["sns.barplot(data=compare_f1_sota, x= 'model', y='value', hue='dataset')"],"metadata":{"id":"QAo2ZVWEvVG2","colab":{"base_uri":"https://localhost:8080/","height":296},"outputId":"a1967952-82fb-41a0-fe53-9900e93aa1ad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f8d660f8b50>"]},"metadata":{},"execution_count":33},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["sns.barplot(data=compare_f1_sota, x= 'template', y='value', hue='dataset')"],"metadata":{"id":"pJDFG80rvkpr","colab":{"base_uri":"https://localhost:8080/","height":296},"outputId":"f9a6ec42-a218-4b2c-c705-b4d453d11b8a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f8d66054370>"]},"metadata":{},"execution_count":34},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}