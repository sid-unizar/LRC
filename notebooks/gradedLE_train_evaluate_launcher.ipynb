{"cells":[{"cell_type":"markdown","source":["##**Paper \"No clues, good clues: Out of context Lexical Relation Classification\"**\n","####Experiment reproducibility for graded lexical entailment: Templates T1-T4"],"metadata":{"id":"8psMwZmn4i6L"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7M5oO7o9_rJ7"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","source":["**Download datasets and scripts**"],"metadata":{"id":"M37eaDeLFKvg"}},{"cell_type":"code","source":["!curl -L -O 'https://raw.github.com/sid-unizar/LRC/main/datasets/datasets.zip'\n","!unzip -o datasets.zip\n","!curl -L -O 'https://raw.github.com/sid-unizar/LRC/main/scripts/scripts.zip'\n","!unzip -o scripts.zip"],"metadata":{"id":"Jt1A6kA3mCo4"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ib-yPJGZ3SdR"},"outputs":[],"source":["# to mount google drive\n","# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","source":["# THESE ARE THE PACKAGES USED IN THE EXPERIMENTS\n","# UNCOMMENT THE FOLLOWING LINES, IF YOU DO NOT WANT TO USE THE LAST VERSIONS\n","# OF THE TRANSFORMERS AND DATASETS PACKAGES\n","\n","# !pip install 'transformers==4.25.1' --force-reinstall\n","# !pip install 'datasets==2.8.0' --force-reinstall"],"metadata":{"id":"glUTf9aJ8Uji"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zb8Wv1jG3IL1"},"outputs":[],"source":["!pip install transformers\n","!pip install datasets\n","!pip install accelerate"]},{"cell_type":"code","source":["#########\n","# Parameter --model, one of:\n","#    \"roberta-large\"\n","#    \"roberta-base\"\n","#    \"bert-large-uncased-whole-word-masking\"\n","#    \"bert-base-uncased\"\n","#\n","# Parameters --train_templates and --test_templates:\n","#   templates T1: train and test,\n","#          \"' <W1> ' <SEP> ' <W2> '\"\n","#   templates T2: train and test,\n","#          \" <W1> <SEP> <W2> \"\n","#   templates T3: train and test,\n","#          \"Today, I finally discovered the relation between <W1> and <W2>.\"\n","#   template T4:\n","#       train,\n","#          \"Today, I finally discovered the relation between <W1> and <W2>: <W1> is the <LABEL> of <W2>.\"\n","#       test,\n","#          \"Today, I finally discovered the relation between <W1> and <W2>.\"\n","#\n","# Modify the rute to the folder containing the `gradedLE_train_evaluate.py` script\n","# and the folder containing Hyperlex dataset and split: a)lexical; b)random\n","\n","!python /content/scripts/gradedLE_train_evaluate.py \\\n","\t--train_templates \"' <W1> ' <SEP> ' <W2> '\"   \\\n","\t--test_templates \"' <W1> ' <SEP> ' <W2> '\"   \\\n","\t--model  \"roberta-base\" \\\n","\t--nepochs 10 \\\n","\t--dir_output_results \"/content/res/\" \\\n","\t--batch_size 32 \\\n","\t--warm_up 0.1 \\\n","\t--nrepetitions 1 \\\n","\t--dataset \"hyperlex\" \\\n","\t--date `date \"+%D-%H:%M:%S\"` \\\n","\t--train_file \"/content/datasets/hyperlex/lexical/train.tsv\" \\\n","\t--test_file \"/content/datasets/hyperlex/lexical/test.tsv\" \\\n","\t--val_file \"/content/datasets/hyperlex/lexical/val.tsv\" #lexical or random"],"metadata":{"id":"TBObPdYYn9rz"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}