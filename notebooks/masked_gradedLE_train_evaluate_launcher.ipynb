{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Paper \"No clues, good clues: Out of context Lexical Relation Classification\"**\n",
        "####Experiment reproducibility for graded lexical entailment: Templates TM1-TM3"
      ],
      "metadata": {
        "id": "8psMwZmn4i6L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7M5oO7o9_rJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd1800c0-3d8e-45b1-9f8c-5cc397d2ab3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 25 13:24:48 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P0    28W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ib-yPJGZ3SdR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b92d7f60-9174-46ea-fe57-8189731160e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# THESE ARE THE PACKAGES USED IN THE EXPERIMENTS\n",
        "# UNCOMMENT THE FOLLOWING LINES, IF YOU DO NOT WANT TO USE THE LAST VERSIONS\n",
        "# OF THE TRANSFORMERS AND DATASETS PACKAGES\n",
        "\n",
        "# !pip install 'transformers==4.25.1' --force-reinstall\n",
        "# !pip install 'datasets==2.8.0' --force-reinstall"
      ],
      "metadata": {
        "id": "glUTf9aJ8Uji"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb8Wv1jG3IL1"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#########\n",
        "# Parameter --model, one of:\n",
        "#    \"roberta-large\"\n",
        "#    \"roberta-base\"\n",
        "#    \"bert-large-uncased-whole-word-masking\"\n",
        "#    \"bert-base-uncased\"\n",
        "#\n",
        "# Parameter --train_templates:\n",
        "#   template TM1:, \n",
        "#          \"' <W1> ' <MASK> ' <W2> '\"\n",
        "#   template TM2:\n",
        "#          \" <W1> <MASK> <W2> \"\n",
        "#   template TM3: \n",
        "#          \"Today, I finally discovered the relation between <W1> and <W2>: <W1> is the <MASK> of <W2>.\" \n",
        "#\n",
        "# Modify the rute to the folder containing the `masked_gradedLE_train_evaluate.py` script \n",
        "# and the folder containing Hyperlex dataset and splits: a)lexical; b)random\n",
        "\n",
        "!python /content/drive/MyDrive/scripts/masked_gradedLE_train_evaluate.py \\\n",
        "\t--train_templates \"' <W1> ' <MASK> ' <W2> '\"   \\\n",
        "\t--model  \"roberta-base\" \\\n",
        "\t--nepochs 10 \\\n",
        "\t--dir_output_results \"/content/drive/MyDrive/res/\" \\\n",
        "\t--batch_size 32 \\\n",
        "\t--warm_up 0.1 \\\n",
        "\t--nrepetitions 1 \\\n",
        "\t--dataset \"hyperlex\" \\\n",
        "\t--date `date \"+%D-%H:%M:%S\"` \\\n",
        "\t--train_file \"/content/drive/MyDrive/datasets/hyperlex/lexical/train.tsv\" \\\n",
        "\t--test_file \"/content/drive/MyDrive/datasets/hyperlex/lexical/test.tsv\" \\\n",
        "\t--val_file \"/content/drive/MyDrive/datasets/hyperlex/lexical/val.tsv\" #lexical or random "
      ],
      "metadata": {
        "id": "TBObPdYYn9rz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}