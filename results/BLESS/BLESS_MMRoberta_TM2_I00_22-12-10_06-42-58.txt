{'train_file': '/kaggle/input/lexicalrelationdataset/BLESS/train.tsv', 'val_file': '/kaggle/input/lexicalrelationdataset/BLESS/val.tsv', 'test_file': '/kaggle/input/lexicalrelationdataset/BLESS/test.tsv', 'train_templates': [' <W1> <MASK> <W2> '], 'model': 'roberta-large', 'nepochs': 10, 'dir_output_results': './results/', 'nrepetitions': 1, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'BLESS', 'parameters_list': None, 'date': '12/10/22-06:03:36', 'raw_model': False}
12/10/22-06:03:36
{'attri': {'precision': 0.8822768434670116, 'recall': 0.9798850574712644, 'f1-score': 0.9285228046289994, 'support': 696}, 'coord': {'precision': 0.9721603563474388, 'recall': 0.9897959183673469, 'f1-score': 0.9808988764044944, 'support': 882}, 'event': {'precision': 0.927645788336933, 'recall': 0.8994764397905759, 'f1-score': 0.9133439659755448, 'support': 955}, 'hyper': {'precision': 0.952247191011236, 'recall': 0.9685714285714285, 'f1-score': 0.9603399433427763, 'support': 350}, 'mero': {'precision': 0.9227799227799228, 'recall': 0.9611260053619303, 'f1-score': 0.9415627051871307, 'support': 746}, 'random': {'precision': 0.978328173374613, 'recall': 0.9454787234042553, 'f1-score': 0.961622992392223, 'support': 3008}, 'accuracy': 0.9513334337803224, 'macro avg': {'precision': 0.9392397125528591, 'recall': 0.9573889288278002, 'f1-score': 0.9477152146551947, 'support': 6637}, 'weighted avg': {'precision': 0.9525242323296433, 'recall': 0.9513334337803224, 'f1-score': 0.9514441596915129, 'support': 6637}}
