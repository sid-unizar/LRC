{'train_file': '/content/drive/MyDrive/PhD/METAFORAS/RelationClassification/DATASETS/BLESS/train.tsv', 'val_file': '/content/drive/MyDrive/PhD/METAFORAS/RelationClassification/DATASETS/BLESS/val.tsv', 'test_file': '/content/drive/MyDrive/PhD/METAFORAS/RelationClassification/DATASETS/BLESS/test.tsv', 'train_templates': [' <W1> <SEP> <W2> '], 'test_templates': [' <W1> <SEP> <W2> '], 'model': 'bert-large-uncased-whole-word-masking', 'nepochs': 10, 'dir_output_results': '/content/drive/MyDrive/results/', 'nrepetitions': 1, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'BLESS', 'parameters_list': None, 'date': '11/22/22-13:09:28', 'raw_model': False}
11/22/22-13:09:28
{'attri': {'precision': 0.9379407616361072, 'recall': 0.9554597701149425, 'f1-score': 0.9466192170818506, 'support': 696}, 'coord': {'precision': 0.9699666295884316, 'recall': 0.9886621315192744, 'f1-score': 0.9792251544076361, 'support': 882}, 'event': {'precision': 0.8703703703703703, 'recall': 0.9350785340314136, 'f1-score': 0.9015648662291772, 'support': 955}, 'hyper': {'precision': 0.9449035812672176, 'recall': 0.98, 'f1-score': 0.9621318373071529, 'support': 350}, 'mero': {'precision': 0.9213630406290957, 'recall': 0.9423592493297587, 'f1-score': 0.9317428760768721, 'support': 746}, 'random': {'precision': 0.9822732012513035, 'recall': 0.9394946808510638, 'f1-score': 0.9604078164825829, 'support': 3008}, 'accuracy': 0.9495253879764954, 'macro avg': {'precision': 0.9378029307904211, 'recall': 0.9568423943077423, 'f1-score': 0.9469486279308786, 'support': 6637}, 'weighted avg': {'precision': 0.9510700485484681, 'recall': 0.9495253879764954, 'f1-score': 0.9498645546355019, 'support': 6637}}
