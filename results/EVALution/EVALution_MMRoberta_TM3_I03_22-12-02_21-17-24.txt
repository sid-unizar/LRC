{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': ['Today, I finally discovered the relation between <W1> and <W2>: <W1> is the <MASK> of <W2>.'], 'model': 'roberta-large', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '12/02/22-19:28:15', 'raw_model': False}
12/02/22-19:28:15
{'antonym': {'precision': 0.8820638820638821, 'recall': 0.8650602409638555, 'f1-score': 0.8734793187347931, 'support': 415}, 'hasa': {'precision': 0.7228915662650602, 'recall': 0.8450704225352113, 'f1-score': 0.7792207792207793, 'support': 142}, 'hasproperty': {'precision': 0.9064516129032258, 'recall': 0.8726708074534162, 'f1-score': 0.8892405063291139, 'support': 322}, 'isa': {'precision': 0.7617866004962779, 'recall': 0.6688453159041394, 'f1-score': 0.7122969837587008, 'support': 459}, 'madeof': {'precision': 0.8382352941176471, 'recall': 0.6627906976744186, 'f1-score': 0.7402597402597402, 'support': 86}, 'partof': {'precision': 0.7647058823529411, 'recall': 0.8068965517241379, 'f1-score': 0.7852348993288589, 'support': 145}, 'synonym': {'precision': 0.5634218289085545, 'recall': 0.6895306859205776, 'f1-score': 0.6201298701298701, 'support': 277}, 'accuracy': 0.7757313109425785, 'macro avg': {'precision': 0.7770795238725127, 'recall': 0.7729806745965366, 'f1-score': 0.7714088711088366, 'support': 1846}, 'weighted avg': {'precision': 0.7850937255101538, 'recall': 0.7757313109425785, 'f1-score': 0.7777466947987562, 'support': 1846}}
