{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': ["' <W1> ' <SEP> ' <W2> '"], 'test_templates': ["' <W1> ' <SEP> ' <W2> '"], 'model': 'bert-base-uncased', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '11/29/22-10:42:49', 'raw_model': False}
11/29/22-10:42:49
{'Antonym': {'precision': 0.7456359102244389, 'recall': 0.7204819277108434, 'f1-score': 0.732843137254902, 'support': 415}, 'HasA': {'precision': 0.7746478873239436, 'recall': 0.7746478873239436, 'f1-score': 0.7746478873239436, 'support': 142}, 'HasProperty': {'precision': 0.8403614457831325, 'recall': 0.8664596273291926, 'f1-score': 0.8532110091743119, 'support': 322}, 'IsA': {'precision': 0.6722338204592901, 'recall': 0.7015250544662309, 'f1-score': 0.6865671641791045, 'support': 459}, 'MadeOf': {'precision': 0.7012987012987013, 'recall': 0.627906976744186, 'f1-score': 0.6625766871165645, 'support': 86}, 'PartOf': {'precision': 0.7446808510638298, 'recall': 0.7241379310344828, 'f1-score': 0.7342657342657343, 'support': 145}, 'Synonym': {'precision': 0.4343065693430657, 'recall': 0.4296028880866426, 'f1-score': 0.4319419237749546, 'support': 277}, 'accuracy': 0.6977248104008668, 'macro avg': {'precision': 0.7018807407852002, 'recall': 0.6921088989565032, 'f1-score': 0.6965790775842164, 'support': 1846}, 'weighted avg': {'precision': 0.6972827428494571, 'recall': 0.6977248104008668, 'f1-score': 0.6972352192412459, 'support': 1846}}
