{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': ["' <W1> ' <MASK> ' <W2> '"], 'model': 'bert-large-uncased-whole-word-masking', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '12/02/22-14:54:34', 'raw_model': False}
12/02/22-14:54:34
{'antonym': {'precision': 0.8818681318681318, 'recall': 0.7734939759036145, 'f1-score': 0.8241335044929397, 'support': 415}, 'hasa': {'precision': 0.6823529411764706, 'recall': 0.8169014084507042, 'f1-score': 0.7435897435897436, 'support': 142}, 'hasproperty': {'precision': 0.8226744186046512, 'recall': 0.8788819875776398, 'f1-score': 0.8498498498498499, 'support': 322}, 'isa': {'precision': 0.7537688442211056, 'recall': 0.6535947712418301, 'f1-score': 0.7001166861143524, 'support': 459}, 'madeof': {'precision': 0.8245614035087719, 'recall': 0.5465116279069767, 'f1-score': 0.6573426573426573, 'support': 86}, 'partof': {'precision': 0.835820895522388, 'recall': 0.7724137931034483, 'f1-score': 0.8028673835125447, 'support': 145}, 'synonym': {'precision': 0.46965699208443273, 'recall': 0.6425992779783394, 'f1-score': 0.5426829268292683, 'support': 277}, 'accuracy': 0.7351029252437703, 'macro avg': {'precision': 0.7529576609979932, 'recall': 0.7263424060232219, 'f1-score': 0.731511821675908, 'support': 1846}, 'weighted avg': {'precision': 0.7562035493068294, 'recall': 0.7351029252437703, 'f1-score': 0.7399137423645438, 'support': 1846}}
