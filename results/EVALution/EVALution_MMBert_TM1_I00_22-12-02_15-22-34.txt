{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': ["' <W1> ' <MASK> ' <W2> '"], 'model': 'bert-large-uncased-whole-word-masking', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '12/02/22-14:54:34', 'raw_model': False}
12/02/22-14:54:34
{'antonym': {'precision': 0.8367346938775511, 'recall': 0.7903614457831325, 'f1-score': 0.8128872366790583, 'support': 415}, 'hasa': {'precision': 0.8, 'recall': 0.7605633802816901, 'f1-score': 0.779783393501805, 'support': 142}, 'hasproperty': {'precision': 0.8549848942598187, 'recall': 0.8788819875776398, 'f1-score': 0.8667687595712098, 'support': 322}, 'isa': {'precision': 0.7400990099009901, 'recall': 0.6514161220043573, 'f1-score': 0.6929316338354576, 'support': 459}, 'madeof': {'precision': 0.8055555555555556, 'recall': 0.6744186046511628, 'f1-score': 0.7341772151898734, 'support': 86}, 'partof': {'precision': 0.7579617834394905, 'recall': 0.8206896551724138, 'f1-score': 0.7880794701986754, 'support': 145}, 'synonym': {'precision': 0.5098591549295775, 'recall': 0.6534296028880866, 'f1-score': 0.5727848101265822, 'support': 277}, 'accuracy': 0.7453954496208017, 'macro avg': {'precision': 0.757885013137569, 'recall': 0.7471086854797832, 'f1-score': 0.7496303598718088, 'support': 1846}, 'weighted avg': {'precision': 0.7563752447168995, 'recall': 0.7453954496208017, 'f1-score': 0.7482691016802114, 'support': 1846}}
