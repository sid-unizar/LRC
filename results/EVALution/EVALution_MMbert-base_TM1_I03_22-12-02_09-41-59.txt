{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': ["' <W1> ' <MASK> ' <W2> '"], 'model': 'bert-base-uncased', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '12/02/22-09:14:06', 'raw_model': False}
12/02/22-09:14:06
{'antonym': {'precision': 0.5952380952380952, 'recall': 0.8433734939759037, 'f1-score': 0.6979062811565305, 'support': 415}, 'hasa': {'precision': 0.831858407079646, 'recall': 0.6619718309859155, 'f1-score': 0.7372549019607842, 'support': 142}, 'hasproperty': {'precision': 0.8412698412698413, 'recall': 0.8229813664596274, 'f1-score': 0.8320251177394035, 'support': 322}, 'isa': {'precision': 0.6785714285714286, 'recall': 0.6209150326797386, 'f1-score': 0.6484641638225256, 'support': 459}, 'madeof': {'precision': 0.8421052631578947, 'recall': 0.5581395348837209, 'f1-score': 0.6713286713286712, 'support': 86}, 'partof': {'precision': 0.8807339449541285, 'recall': 0.6620689655172414, 'f1-score': 0.7559055118110236, 'support': 145}, 'synonym': {'precision': 0.45491803278688525, 'recall': 0.4007220216606498, 'f1-score': 0.42610364683301344, 'support': 277}, 'accuracy': 0.6765980498374865, 'macro avg': {'precision': 0.7320992875797029, 'recall': 0.6528817494518283, 'f1-score': 0.681284042093136, 'support': 1846}, 'weighted avg': {'precision': 0.6899461796664077, 'recall': 0.6765980498374865, 'f1-score': 0.6745664772397765, 'support': 1846}}
