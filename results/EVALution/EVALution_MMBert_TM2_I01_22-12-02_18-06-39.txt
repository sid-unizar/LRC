{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': [' <W1> <MASK> <W2> '], 'model': 'bert-large-uncased-whole-word-masking', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '12/02/22-17:11:44', 'raw_model': False}
12/02/22-17:11:44
{'antonym': {'precision': 0.6473684210526316, 'recall': 0.8891566265060241, 'f1-score': 0.749238578680203, 'support': 415}, 'hasa': {'precision': 0.7202380952380952, 'recall': 0.852112676056338, 'f1-score': 0.7806451612903226, 'support': 142}, 'hasproperty': {'precision': 0.9041095890410958, 'recall': 0.8198757763975155, 'f1-score': 0.8599348534201955, 'support': 322}, 'isa': {'precision': 0.7679558011049724, 'recall': 0.6056644880174292, 'f1-score': 0.6772228989037758, 'support': 459}, 'madeof': {'precision': 0.8166666666666667, 'recall': 0.5697674418604651, 'f1-score': 0.6712328767123289, 'support': 86}, 'partof': {'precision': 0.7354838709677419, 'recall': 0.7862068965517242, 'f1-score': 0.76, 'support': 145}, 'synonym': {'precision': 0.5564853556485355, 'recall': 0.48014440433212996, 'f1-score': 0.5155038759689923, 'support': 277}, 'accuracy': 0.7193932827735645, 'macro avg': {'precision': 0.7354725428171056, 'recall': 0.7147040442459466, 'f1-score': 0.7162540349965454, 'support': 1846}, 'weighted avg': {'precision': 0.7289120491751717, 'recall': 0.7193932827735645, 'f1-score': 0.7151953182526095, 'support': 1846}}
