{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': ["' <W1> ' <SEP> ' <W2> '"], 'test_templates': ["' <W1> ' <SEP> ' <W2> '"], 'model': 'roberta-large', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '12/01/22-12:12:14', 'raw_model': False}
12/01/22-12:12:14
{'Antonym': {'precision': 0.918848167539267, 'recall': 0.8457831325301205, 'f1-score': 0.8808030112923463, 'support': 415}, 'HasA': {'precision': 0.7619047619047619, 'recall': 0.7887323943661971, 'f1-score': 0.7750865051903114, 'support': 142}, 'HasProperty': {'precision': 0.8704819277108434, 'recall': 0.8975155279503105, 'f1-score': 0.8837920489296636, 'support': 322}, 'IsA': {'precision': 0.6900584795321637, 'recall': 0.7712418300653595, 'f1-score': 0.7283950617283951, 'support': 459}, 'MadeOf': {'precision': 0.7142857142857143, 'recall': 0.7558139534883721, 'f1-score': 0.7344632768361582, 'support': 86}, 'PartOf': {'precision': 0.7925925925925926, 'recall': 0.7379310344827587, 'f1-score': 0.7642857142857143, 'support': 145}, 'Synonym': {'precision': 0.6138211382113821, 'recall': 0.5451263537906137, 'f1-score': 0.5774378585086042, 'support': 277}, 'accuracy': 0.7741061755146262, 'macro avg': {'precision': 0.7659989688252465, 'recall': 0.7631634609533903, 'f1-score': 0.7634662109673133, 'support': 1846}, 'weighted avg': {'precision': 0.7762337167857404, 'recall': 0.7741061755146262, 'f1-score': 0.7738057766512755, 'support': 1846}}
