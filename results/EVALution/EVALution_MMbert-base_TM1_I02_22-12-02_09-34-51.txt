{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': ["' <W1> ' <MASK> ' <W2> '"], 'model': 'bert-base-uncased', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '12/02/22-09:14:06', 'raw_model': False}
12/02/22-09:14:06
{'antonym': {'precision': 0.7417840375586855, 'recall': 0.7614457831325301, 'f1-score': 0.751486325802616, 'support': 415}, 'hasa': {'precision': 0.7605633802816901, 'recall': 0.7605633802816901, 'f1-score': 0.7605633802816902, 'support': 142}, 'hasproperty': {'precision': 0.8363636363636363, 'recall': 0.8571428571428571, 'f1-score': 0.8466257668711655, 'support': 322}, 'isa': {'precision': 0.6586345381526104, 'recall': 0.7145969498910676, 'f1-score': 0.6854754440961337, 'support': 459}, 'madeof': {'precision': 0.7777777777777778, 'recall': 0.5697674418604651, 'f1-score': 0.6577181208053691, 'support': 86}, 'partof': {'precision': 0.7449664429530202, 'recall': 0.7655172413793103, 'f1-score': 0.7551020408163265, 'support': 145}, 'synonym': {'precision': 0.5, 'recall': 0.4296028880866426, 'f1-score': 0.4621359223300971, 'support': 277}, 'accuracy': 0.7080173347778982, 'macro avg': {'precision': 0.7171556875839171, 'recall': 0.6940909345392232, 'f1-score': 0.702729571571914, 'support': 1846}, 'weighted avg': {'precision': 0.7046975853873622, 'recall': 0.7080173347778982, 'f1-score': 0.7048638980356403, 'support': 1846}}
