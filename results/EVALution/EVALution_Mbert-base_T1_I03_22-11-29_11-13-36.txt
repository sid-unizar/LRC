{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': ["' <W1> ' <SEP> ' <W2> '"], 'test_templates': ["' <W1> ' <SEP> ' <W2> '"], 'model': 'bert-base-uncased', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '11/29/22-10:42:49', 'raw_model': False}
11/29/22-10:42:49
{'Antonym': {'precision': 0.7241379310344828, 'recall': 0.6578313253012048, 'f1-score': 0.6893939393939393, 'support': 415}, 'HasA': {'precision': 0.7272727272727273, 'recall': 0.7323943661971831, 'f1-score': 0.7298245614035087, 'support': 142}, 'HasProperty': {'precision': 0.8269794721407625, 'recall': 0.8757763975155279, 'f1-score': 0.8506787330316743, 'support': 322}, 'IsA': {'precision': 0.6914414414414415, 'recall': 0.6688453159041394, 'f1-score': 0.6799557032115172, 'support': 459}, 'MadeOf': {'precision': 0.7236842105263158, 'recall': 0.6395348837209303, 'f1-score': 0.6790123456790124, 'support': 86}, 'PartOf': {'precision': 0.7266666666666667, 'recall': 0.7517241379310344, 'f1-score': 0.7389830508474577, 'support': 145}, 'Synonym': {'precision': 0.4253968253968254, 'recall': 0.48375451263537905, 'f1-score': 0.45270270270270263, 'support': 277}, 'accuracy': 0.6847237269772481, 'macro avg': {'precision': 0.6922256106398889, 'recall': 0.6871229913150569, 'f1-score': 0.6886501480385446, 'support': 1846}, 'weighted avg': {'precision': 0.6895381417713085, 'recall': 0.6847237269772481, 'f1-score': 0.6861852898851536, 'support': 1846}}
