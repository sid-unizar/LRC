{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': ["' <W1> ' <MASK> ' <W2> '"], 'model': 'roberta-large', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '12/02/22-21:44:31', 'raw_model': False}
12/02/22-21:44:31
{'antonym': {'precision': 0.9015151515151515, 'recall': 0.8602409638554217, 'f1-score': 0.8803945745992602, 'support': 415}, 'hasa': {'precision': 0.6685082872928176, 'recall': 0.852112676056338, 'f1-score': 0.7492260061919503, 'support': 142}, 'hasproperty': {'precision': 0.8703703703703703, 'recall': 0.8757763975155279, 'f1-score': 0.873065015479876, 'support': 322}, 'isa': {'precision': 0.6372881355932203, 'recall': 0.8191721132897604, 'f1-score': 0.7168732125834127, 'support': 459}, 'madeof': {'precision': 0.9107142857142857, 'recall': 0.5930232558139535, 'f1-score': 0.7183098591549295, 'support': 86}, 'partof': {'precision': 0.8102189781021898, 'recall': 0.7655172413793103, 'f1-score': 0.7872340425531915, 'support': 145}, 'synonym': {'precision': 0.6790123456790124, 'recall': 0.3971119133574007, 'f1-score': 0.501138952164009, 'support': 277}, 'accuracy': 0.7627302275189599, 'macro avg': {'precision': 0.7825182220381498, 'recall': 0.7375649373239589, 'f1-score': 0.7466059518180899, 'support': 1846}, 'weighted avg': {'precision': 0.7723299449188776, 'recall': 0.7627302275189599, 'f1-score': 0.7565897371100886, 'support': 1846}}
