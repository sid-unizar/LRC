{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': ["' <W1> ' <SEP> ' <W2> '"], 'test_templates': ["' <W1> ' <SEP> ' <W2> '"], 'model': 'bert-large-uncased-whole-word-masking', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '11/30/22-18:24:14', 'raw_model': False}
11/30/22-18:24:14
{'Antonym': {'precision': 0.8181818181818182, 'recall': 0.8457831325301205, 'f1-score': 0.8317535545023697, 'support': 415}, 'HasA': {'precision': 0.75, 'recall': 0.8028169014084507, 'f1-score': 0.7755102040816326, 'support': 142}, 'HasProperty': {'precision': 0.8706624605678234, 'recall': 0.8571428571428571, 'f1-score': 0.863849765258216, 'support': 322}, 'IsA': {'precision': 0.696969696969697, 'recall': 0.7015250544662309, 'f1-score': 0.6992399565689468, 'support': 459}, 'MadeOf': {'precision': 0.6962025316455697, 'recall': 0.6395348837209303, 'f1-score': 0.6666666666666667, 'support': 86}, 'PartOf': {'precision': 0.75, 'recall': 0.7448275862068966, 'f1-score': 0.7474048442906573, 'support': 145}, 'Synonym': {'precision': 0.5551330798479087, 'recall': 0.5270758122743683, 'f1-score': 0.5407407407407407, 'support': 277}, 'accuracy': 0.7432286023835319, 'macro avg': {'precision': 0.7338785124589738, 'recall': 0.7312437468214077, 'f1-score': 0.7321665331584614, 'support': 1846}, 'weighted avg': {'precision': 0.7414426536277218, 'recall': 0.7432286023835319, 'f1-score': 0.7420927191316526, 'support': 1846}}
