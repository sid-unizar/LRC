{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': ["' <W1> ' <MASK> ' <W2> '"], 'model': 'bert-large-uncased-whole-word-masking', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '12/02/22-14:54:34', 'raw_model': False}
12/02/22-14:54:34
{'antonym': {'precision': 0.7910112359550562, 'recall': 0.8481927710843373, 'f1-score': 0.8186046511627908, 'support': 415}, 'hasa': {'precision': 0.7417218543046358, 'recall': 0.7887323943661971, 'f1-score': 0.7645051194539249, 'support': 142}, 'hasproperty': {'precision': 0.8906752411575563, 'recall': 0.860248447204969, 'f1-score': 0.8751974723538705, 'support': 322}, 'isa': {'precision': 0.8005952380952381, 'recall': 0.5860566448801743, 'f1-score': 0.6767295597484277, 'support': 459}, 'madeof': {'precision': 0.7702702702702703, 'recall': 0.6627906976744186, 'f1-score': 0.7124999999999999, 'support': 86}, 'partof': {'precision': 0.74375, 'recall': 0.8206896551724138, 'f1-score': 0.780327868852459, 'support': 145}, 'synonym': {'precision': 0.5094850948509485, 'recall': 0.6787003610108303, 'f1-score': 0.5820433436532507, 'support': 277}, 'accuracy': 0.7443120260021668, 'macro avg': {'precision': 0.7496441335191008, 'recall': 0.7493444244847628, 'f1-score': 0.7442725736035319, 'support': 1846}, 'weighted avg': {'precision': 0.7600645572524432, 'recall': 0.7443120260021668, 'f1-score': 0.7455913642432543, 'support': 1846}}
