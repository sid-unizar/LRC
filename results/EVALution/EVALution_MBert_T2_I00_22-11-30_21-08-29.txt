{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': [' <W1> <SEP> <W2> '], 'test_templates': [' <W1> <SEP> <W2> '], 'model': 'bert-large-uncased-whole-word-masking', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '11/30/22-20:40:44', 'raw_model': False}
11/30/22-20:40:44
{'Antonym': {'precision': 0.7784946236559139, 'recall': 0.8722891566265061, 'f1-score': 0.8227272727272728, 'support': 415}, 'HasA': {'precision': 0.672316384180791, 'recall': 0.8380281690140845, 'f1-score': 0.7460815047021943, 'support': 142}, 'HasProperty': {'precision': 0.8668730650154799, 'recall': 0.8695652173913043, 'f1-score': 0.8682170542635658, 'support': 322}, 'IsA': {'precision': 0.7475490196078431, 'recall': 0.664488017429194, 'f1-score': 0.7035755478662054, 'support': 459}, 'MadeOf': {'precision': 0.726027397260274, 'recall': 0.6162790697674418, 'f1-score': 0.6666666666666667, 'support': 86}, 'PartOf': {'precision': 0.8029197080291971, 'recall': 0.7586206896551724, 'f1-score': 0.7801418439716313, 'support': 145}, 'Synonym': {'precision': 0.532319391634981, 'recall': 0.5054151624548736, 'f1-score': 0.5185185185185185, 'support': 277}, 'accuracy': 0.7416034669555797, 'macro avg': {'precision': 0.7323570841977828, 'recall': 0.7320979260483682, 'f1-score': 0.7294183441022936, 'support': 1846}, 'weighted avg': {'precision': 0.7405831568891486, 'recall': 0.7416034669555797, 'f1-score': 0.7388764843617744, 'support': 1846}}
