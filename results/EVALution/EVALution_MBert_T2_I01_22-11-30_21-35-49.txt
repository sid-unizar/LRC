{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': [' <W1> <SEP> <W2> '], 'test_templates': [' <W1> <SEP> <W2> '], 'model': 'bert-large-uncased-whole-word-masking', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '11/30/22-20:40:44', 'raw_model': False}
11/30/22-20:40:44
{'Antonym': {'precision': 0.725609756097561, 'recall': 0.8602409638554217, 'f1-score': 0.7872105843439912, 'support': 415}, 'HasA': {'precision': 0.6647058823529411, 'recall': 0.795774647887324, 'f1-score': 0.7243589743589745, 'support': 142}, 'HasProperty': {'precision': 0.811965811965812, 'recall': 0.8850931677018633, 'f1-score': 0.8469539375928677, 'support': 322}, 'IsA': {'precision': 0.7362110311750599, 'recall': 0.6688453159041394, 'f1-score': 0.7009132420091325, 'support': 459}, 'MadeOf': {'precision': 0.7073170731707317, 'recall': 0.6744186046511628, 'f1-score': 0.6904761904761904, 'support': 86}, 'PartOf': {'precision': 0.7394366197183099, 'recall': 0.7241379310344828, 'f1-score': 0.7317073170731707, 'support': 145}, 'Synonym': {'precision': 0.5833333333333334, 'recall': 0.4043321299638989, 'f1-score': 0.4776119402985075, 'support': 277}, 'accuracy': 0.7242686890574215, 'macro avg': {'precision': 0.7097970725448212, 'recall': 0.7161203944283275, 'f1-score': 0.7084617408789763, 'support': 1846}, 'weighted avg': {'precision': 0.7175086946490361, 'recall': 0.7242686890574215, 'f1-score': 0.7160166487909396, 'support': 1846}}
