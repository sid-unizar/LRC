{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': [' <W1> <MASK> <W2> '], 'model': 'bert-base-uncased', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '12/02/22-09:49:04', 'raw_model': False}
12/02/22-09:49:04
{'antonym': {'precision': 0.7053364269141531, 'recall': 0.7325301204819277, 'f1-score': 0.718676122931442, 'support': 415}, 'hasa': {'precision': 0.7225806451612903, 'recall': 0.7887323943661971, 'f1-score': 0.7542087542087541, 'support': 142}, 'hasproperty': {'precision': 0.8498498498498499, 'recall': 0.8788819875776398, 'f1-score': 0.8641221374045801, 'support': 322}, 'isa': {'precision': 0.6834061135371179, 'recall': 0.681917211328976, 'f1-score': 0.6826608505997819, 'support': 459}, 'madeof': {'precision': 0.7903225806451613, 'recall': 0.5697674418604651, 'f1-score': 0.6621621621621622, 'support': 86}, 'partof': {'precision': 0.6855345911949685, 'recall': 0.7517241379310344, 'f1-score': 0.7171052631578947, 'support': 145}, 'synonym': {'precision': 0.47580645161290325, 'recall': 0.4259927797833935, 'f1-score': 0.4495238095238095, 'support': 277}, 'accuracy': 0.6977248104008668, 'macro avg': {'precision': 0.7018338084164919, 'recall': 0.6899351533328048, 'f1-score': 0.6926370142840608, 'support': 1846}, 'weighted avg': {'precision': 0.6943796160904626, 'recall': 0.6977248104008668, 'f1-score': 0.6946810385296328, 'support': 1846}}
