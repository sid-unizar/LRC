{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': ["' <W1> ' <MASK> ' <W2> '"], 'model': 'bert-large-uncased-whole-word-masking', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '12/02/22-14:54:34', 'raw_model': False}
12/02/22-14:54:34
{'antonym': {'precision': 0.8670212765957447, 'recall': 0.7855421686746988, 'f1-score': 0.8242730720606828, 'support': 415}, 'hasa': {'precision': 0.7687074829931972, 'recall': 0.795774647887324, 'f1-score': 0.7820069204152249, 'support': 142}, 'hasproperty': {'precision': 0.8622754491017964, 'recall': 0.8944099378881988, 'f1-score': 0.8780487804878049, 'support': 322}, 'isa': {'precision': 0.7451923076923077, 'recall': 0.6753812636165577, 'f1-score': 0.7085714285714285, 'support': 459}, 'madeof': {'precision': 0.796875, 'recall': 0.5930232558139535, 'f1-score': 0.6799999999999999, 'support': 86}, 'partof': {'precision': 0.782312925170068, 'recall': 0.7931034482758621, 'f1-score': 0.7876712328767124, 'support': 145}, 'synonym': {'precision': 0.5138121546961326, 'recall': 0.6714801444043321, 'f1-score': 0.5821596244131455, 'support': 277}, 'accuracy': 0.7524377031419285, 'macro avg': {'precision': 0.7623137994641781, 'recall': 0.7441021237944182, 'f1-score': 0.7489615798321427, 'support': 1846}, 'weighted avg': {'precision': 0.7654164936155495, 'recall': 0.7524377031419285, 'f1-score': 0.7557068501435908, 'support': 1846}}
