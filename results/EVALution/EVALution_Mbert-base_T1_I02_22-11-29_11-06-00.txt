{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': ["' <W1> ' <SEP> ' <W2> '"], 'test_templates': ["' <W1> ' <SEP> ' <W2> '"], 'model': 'bert-base-uncased', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '11/29/22-10:42:49', 'raw_model': False}
11/29/22-10:42:49
{'Antonym': {'precision': 0.6852300242130751, 'recall': 0.6819277108433734, 'f1-score': 0.6835748792270531, 'support': 415}, 'HasA': {'precision': 0.6629834254143646, 'recall': 0.8450704225352113, 'f1-score': 0.7430340557275541, 'support': 142}, 'HasProperty': {'precision': 0.8536585365853658, 'recall': 0.8695652173913043, 'f1-score': 0.8615384615384616, 'support': 322}, 'IsA': {'precision': 0.6469387755102041, 'recall': 0.690631808278867, 'f1-score': 0.6680716543730242, 'support': 459}, 'MadeOf': {'precision': 0.7575757575757576, 'recall': 0.5813953488372093, 'f1-score': 0.6578947368421053, 'support': 86}, 'PartOf': {'precision': 0.7430555555555556, 'recall': 0.7379310344827587, 'f1-score': 0.740484429065744, 'support': 145}, 'Synonym': {'precision': 0.4330357142857143, 'recall': 0.35018050541516244, 'f1-score': 0.3872255489021956, 'support': 277}, 'accuracy': 0.6793066088840737, 'macro avg': {'precision': 0.683211112734291, 'recall': 0.6795288639691267, 'f1-score': 0.6774033950965911, 'support': 1846}, 'weighted avg': {'precision': 0.6734466504664957, 'recall': 0.6793066088840737, 'f1-score': 0.6741415771365138, 'support': 1846}}
