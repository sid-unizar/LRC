{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': ["' <W1> ' <MASK> ' <W2> '"], 'model': 'bert-base-uncased', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '12/02/22-09:14:06', 'raw_model': False}
12/02/22-09:14:06
{'antonym': {'precision': 0.7526315789473684, 'recall': 0.689156626506024, 'f1-score': 0.719496855345912, 'support': 415}, 'hasa': {'precision': 0.7835820895522388, 'recall': 0.7394366197183099, 'f1-score': 0.7608695652173914, 'support': 142}, 'hasproperty': {'precision': 0.8949152542372881, 'recall': 0.8198757763975155, 'f1-score': 0.8557536466774717, 'support': 322}, 'isa': {'precision': 0.7189054726368159, 'recall': 0.6296296296296297, 'f1-score': 0.6713124274099883, 'support': 459}, 'madeof': {'precision': 0.847457627118644, 'recall': 0.5813953488372093, 'f1-score': 0.689655172413793, 'support': 86}, 'partof': {'precision': 0.7761194029850746, 'recall': 0.7172413793103448, 'f1-score': 0.7455197132616487, 'support': 145}, 'synonym': {'precision': 0.4276018099547511, 'recall': 0.6823104693140795, 'f1-score': 0.525730180806676, 'support': 277}, 'accuracy': 0.6971830985915493, 'macro avg': {'precision': 0.7430304622045973, 'recall': 0.6941494071018732, 'f1-score': 0.7097625087332686, 'support': 1846}, 'weighted avg': {'precision': 0.7289357835898086, 'recall': 0.6971830985915493, 'f1-score': 0.7060442659668084, 'support': 1846}}
