{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': ["' <W1> ' <SEP> ' <W2> '"], 'test_templates': ["' <W1> ' <SEP> ' <W2> '"], 'model': 'bert-large-uncased-whole-word-masking', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '11/30/22-18:24:14', 'raw_model': False}
11/30/22-18:24:14
{'Antonym': {'precision': 0.85, 'recall': 0.8192771084337349, 'f1-score': 0.8343558282208589, 'support': 415}, 'HasA': {'precision': 0.7171052631578947, 'recall': 0.7676056338028169, 'f1-score': 0.7414965986394557, 'support': 142}, 'HasProperty': {'precision': 0.8619631901840491, 'recall': 0.8726708074534162, 'f1-score': 0.867283950617284, 'support': 322}, 'IsA': {'precision': 0.6742738589211619, 'recall': 0.7080610021786492, 'f1-score': 0.6907545164718384, 'support': 459}, 'MadeOf': {'precision': 0.6666666666666666, 'recall': 0.6511627906976745, 'f1-score': 0.6588235294117646, 'support': 86}, 'PartOf': {'precision': 0.7724137931034483, 'recall': 0.7724137931034483, 'f1-score': 0.7724137931034483, 'support': 145}, 'Synonym': {'precision': 0.5214007782101168, 'recall': 0.48375451263537905, 'f1-score': 0.50187265917603, 'support': 277}, 'accuracy': 0.7351029252437703, 'macro avg': {'precision': 0.7234033643204768, 'recall': 0.7249922354721597, 'f1-score': 0.7238572679486684, 'support': 1846}, 'weighted avg': {'precision': 0.734227597372716, 'recall': 0.7351029252437703, 'f1-score': 0.7343171673883914, 'support': 1846}}
