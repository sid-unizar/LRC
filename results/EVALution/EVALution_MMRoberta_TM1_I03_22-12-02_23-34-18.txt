{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': ["' <W1> ' <MASK> ' <W2> '"], 'model': 'roberta-large', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '12/02/22-21:44:31', 'raw_model': False}
12/02/22-21:44:31
{'antonym': {'precision': 0.9228650137741047, 'recall': 0.8072289156626506, 'f1-score': 0.8611825192802057, 'support': 415}, 'hasa': {'precision': 0.7177914110429447, 'recall': 0.823943661971831, 'f1-score': 0.7672131147540984, 'support': 142}, 'hasproperty': {'precision': 0.8910256410256411, 'recall': 0.8633540372670807, 'f1-score': 0.8769716088328077, 'support': 322}, 'isa': {'precision': 0.5978915662650602, 'recall': 0.8649237472766884, 'f1-score': 0.7070347284060552, 'support': 459}, 'madeof': {'precision': 0.8382352941176471, 'recall': 0.6627906976744186, 'f1-score': 0.7402597402597402, 'support': 86}, 'partof': {'precision': 0.8521739130434782, 'recall': 0.6758620689655173, 'f1-score': 0.7538461538461537, 'support': 145}, 'synonym': {'precision': 0.6459627329192547, 'recall': 0.37545126353790614, 'f1-score': 0.47488584474885853, 'support': 277}, 'accuracy': 0.7508125677139762, 'macro avg': {'precision': 0.7808493674554473, 'recall': 0.724793484622299, 'f1-score': 0.7401991014468458, 'support': 1846}, 'weighted avg': {'precision': 0.7696874193468722, 'recall': 0.7508125677139762, 'f1-score': 0.7463500623750676, 'support': 1846}}
