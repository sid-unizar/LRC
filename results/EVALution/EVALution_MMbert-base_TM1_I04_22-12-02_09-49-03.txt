{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': ["' <W1> ' <MASK> ' <W2> '"], 'model': 'bert-base-uncased', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '12/02/22-09:14:06', 'raw_model': False}
12/02/22-09:14:06
{'antonym': {'precision': 0.7783505154639175, 'recall': 0.727710843373494, 'f1-score': 0.7521793275217933, 'support': 415}, 'hasa': {'precision': 0.7300613496932515, 'recall': 0.8380281690140845, 'f1-score': 0.780327868852459, 'support': 142}, 'hasproperty': {'precision': 0.8148148148148148, 'recall': 0.8881987577639752, 'f1-score': 0.8499257057949479, 'support': 322}, 'isa': {'precision': 0.6391554702495201, 'recall': 0.7254901960784313, 'f1-score': 0.6795918367346939, 'support': 459}, 'madeof': {'precision': 0.8153846153846154, 'recall': 0.6162790697674418, 'f1-score': 0.7019867549668873, 'support': 86}, 'partof': {'precision': 0.8416666666666667, 'recall': 0.696551724137931, 'f1-score': 0.7622641509433962, 'support': 145}, 'synonym': {'precision': 0.4957983193277311, 'recall': 0.4259927797833935, 'f1-score': 0.458252427184466, 'support': 277}, 'accuracy': 0.7107258938244854, 'macro avg': {'precision': 0.7307473930857882, 'recall': 0.702607362845536, 'f1-score': 0.7120754388569492, 'support': 1846}, 'weighted avg': {'precision': 0.7106867740153808, 'recall': 0.7107258938244854, 'f1-score': 0.7076949045340374, 'support': 1846}}
