{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': ["' <W1> ' <MASK> ' <W2> '"], 'model': 'roberta-large', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '12/02/22-21:44:31', 'raw_model': False}
12/02/22-21:44:31
{'antonym': {'precision': 0.9065656565656566, 'recall': 0.8650602409638555, 'f1-score': 0.8853267570900124, 'support': 415}, 'hasa': {'precision': 0.7622377622377622, 'recall': 0.7676056338028169, 'f1-score': 0.7649122807017543, 'support': 142}, 'hasproperty': {'precision': 0.8546511627906976, 'recall': 0.9130434782608695, 'f1-score': 0.8828828828828829, 'support': 322}, 'isa': {'precision': 0.7130801687763713, 'recall': 0.7363834422657952, 'f1-score': 0.7245444801714899, 'support': 459}, 'madeof': {'precision': 0.7857142857142857, 'recall': 0.6395348837209303, 'f1-score': 0.7051282051282051, 'support': 86}, 'partof': {'precision': 0.7972027972027972, 'recall': 0.7862068965517242, 'f1-score': 0.7916666666666666, 'support': 145}, 'synonym': {'precision': 0.5833333333333334, 'recall': 0.5812274368231047, 'f1-score': 0.5822784810126583, 'support': 277}, 'accuracy': 0.7746478873239436, 'macro avg': {'precision': 0.7718264523744148, 'recall': 0.7555802874841566, 'f1-score': 0.7623913933790957, 'support': 1846}, 'weighted avg': {'precision': 0.7755759204217965, 'recall': 0.7746478873239436, 'f1-score': 0.7744345527016279, 'support': 1846}}
