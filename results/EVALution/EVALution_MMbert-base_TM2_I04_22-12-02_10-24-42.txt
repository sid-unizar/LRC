{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': [' <W1> <MASK> <W2> '], 'model': 'bert-base-uncased', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '12/02/22-09:49:04', 'raw_model': False}
12/02/22-09:49:04
{'antonym': {'precision': 0.7272727272727273, 'recall': 0.636144578313253, 'f1-score': 0.6786632390745502, 'support': 415}, 'hasa': {'precision': 0.7142857142857143, 'recall': 0.704225352112676, 'f1-score': 0.7092198581560283, 'support': 142}, 'hasproperty': {'precision': 0.8422619047619048, 'recall': 0.8788819875776398, 'f1-score': 0.8601823708206687, 'support': 322}, 'isa': {'precision': 0.5929824561403508, 'recall': 0.7363834422657952, 'f1-score': 0.6569484936831875, 'support': 459}, 'madeof': {'precision': 0.7272727272727273, 'recall': 0.5581395348837209, 'f1-score': 0.6315789473684211, 'support': 86}, 'partof': {'precision': 0.6903225806451613, 'recall': 0.7379310344827587, 'f1-score': 0.7133333333333333, 'support': 145}, 'synonym': {'precision': 0.4675925925925926, 'recall': 0.36462093862815886, 'f1-score': 0.40973630831643004, 'support': 277}, 'accuracy': 0.6722643553629469, 'macro avg': {'precision': 0.6802843861387398, 'recall': 0.6594752668948576, 'f1-score': 0.6656660786789456, 'support': 1846}, 'weighted avg': {'precision': 0.671072270225167, 'recall': 0.6722643553629469, 'f1-score': 0.6674532103410624, 'support': 1846}}
