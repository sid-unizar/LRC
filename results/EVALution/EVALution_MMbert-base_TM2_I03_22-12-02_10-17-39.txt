{'train_file': 'DATASETS/EVALution/train.tsv', 'val_file': 'DATASETS/EVALution/val.tsv', 'test_file': 'DATASETS/EVALution/test.tsv', 'train_templates': [' <W1> <MASK> <W2> '], 'model': 'bert-base-uncased', 'nepochs': 10, 'dir_output_results': 'results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'EVALution', 'parameters_list': None, 'date': '12/02/22-09:49:04', 'raw_model': False}
12/02/22-09:49:04
{'antonym': {'precision': 0.8089171974522293, 'recall': 0.6120481927710844, 'f1-score': 0.6968449931412894, 'support': 415}, 'hasa': {'precision': 0.782258064516129, 'recall': 0.6830985915492958, 'f1-score': 0.7293233082706767, 'support': 142}, 'hasproperty': {'precision': 0.8181818181818182, 'recall': 0.8944099378881988, 'f1-score': 0.85459940652819, 'support': 322}, 'isa': {'precision': 0.5855704697986577, 'recall': 0.7603485838779956, 'f1-score': 0.6616113744075829, 'support': 459}, 'madeof': {'precision': 0.725, 'recall': 0.6744186046511628, 'f1-score': 0.6987951807228916, 'support': 86}, 'partof': {'precision': 0.7615384615384615, 'recall': 0.6827586206896552, 'f1-score': 0.7200000000000001, 'support': 145}, 'synonym': {'precision': 0.452, 'recall': 0.40794223826714804, 'f1-score': 0.42884250474383306, 'support': 277}, 'accuracy': 0.6814734561213435, 'macro avg': {'precision': 0.7047808587838994, 'recall': 0.67357496709922, 'f1-score': 0.6842881096877804, 'support': 1846}, 'weighted avg': {'precision': 0.6917604280168861, 'recall': 0.6814734561213435, 'f1-score': 0.6797946755359909, 'support': 1846}}
