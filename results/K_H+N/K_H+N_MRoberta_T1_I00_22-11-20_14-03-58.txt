{'train_file': '/kaggle/input/lexical-relation-dataset/K&H+N/train.tsv', 'val_file': '/kaggle/input/lexical-relation-dataset/K&H+N/val.tsv', 'test_file': '/kaggle/input/lexical-relation-dataset/K&H+N/test.tsv', 'train_templates': ["' <W1> ' <SEP> ' <W2> '"], 'test_templates': None, 'model': 'roberta-large', 'nepochs': 10, 'dir_output_results': './results/', 'nrepetitions': 1, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'K&H+N', 'parameters_list': None, 'date': '11/20/22-11:22:50', 'raw_model': False}
11/20/22-11:22:50
{'false': {'precision': 0.9930132302660919, 'recall': 0.9902164245478803, 'f1-score': 0.9916128553403104, 'support': 6746}, 'hypo': {'precision': 0.9765853658536585, 'recall': 0.9606525911708254, 'f1-score': 0.968553459119497, 'support': 1042}, 'mero': {'precision': 0.8533333333333334, 'recall': 0.8, 'f1-score': 0.8258064516129033, 'support': 240}, 'sibl': {'precision': 0.986875, 'recall': 0.99480233107576, 'f1-score': 0.990822809632128, 'support': 6349}, 'accuracy': 0.9869235584614314, 'macro avg': {'precision': 0.952451732363271, 'recall': 0.9364178366986164, 'f1-score': 0.9441988939262097, 'support': 14377}, 'weighted avg': {'precision': 0.9867801751126499, 'recall': 0.9869235584614314, 'f1-score': 0.9868248308596874, 'support': 14377}}
