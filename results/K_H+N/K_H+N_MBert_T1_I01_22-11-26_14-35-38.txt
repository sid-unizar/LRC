{'train_file': '/kaggle/input/lexicalrelationdataset/K&H+N/train.tsv', 'val_file': '/kaggle/input/lexicalrelationdataset/K&H+N/val.tsv', 'test_file': '/kaggle/input/lexicalrelationdataset/K&H+N/test.tsv', 'train_templates': ["' <W1> ' <SEP> ' <W2> '"], 'test_templates': ["' <W1> ' <SEP> ' <W2> '"], 'model': 'bert-large-uncased-whole-word-masking', 'nepochs': 10, 'dir_output_results': './results/', 'nrepetitions': 2, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'K&H+N', 'parameters_list': None, 'date': '11/26/22-09:13:19', 'raw_model': False}
11/26/22-09:13:19
{'false': {'precision': 0.9908324707969836, 'recall': 0.9933293803735547, 'f1-score': 0.9920793545044044, 'support': 6746}, 'hypo': {'precision': 0.9793307086614174, 'recall': 0.95489443378119, 'f1-score': 0.966958211856171, 'support': 1042}, 'mero': {'precision': 0.9142857142857143, 'recall': 0.8, 'f1-score': 0.8533333333333333, 'support': 240}, 'sibl': {'precision': 0.9881026925485284, 'recall': 0.9941723106000945, 'f1-score': 0.991128209154432, 'support': 6349}, 'accuracy': 0.9876886694025179, 'macro avg': {'precision': 0.9681378965731608, 'recall': 0.9355990311887098, 'f1-score': 0.9508747772120851, 'support': 14377}, 'weighted avg': {'precision': 0.9875155465563628, 'recall': 0.9876886694025179, 'f1-score': 0.9875224860654053, 'support': 14377}}
