{'train_file': '/content/drive/MyDrive/Research/NLP/Datasets/CogALexV/train.tsv', 'val_file': None, 'test_file': '/content/drive/MyDrive/Research/NLP/Datasets/CogALexV/test.tsv', 'train_templates': ["' <W1> ' <SEP> ' <W2> '"], 'test_templates': ["' <W1> ' <SEP> ' <W2> '"], 'model': 'roberta-large', 'nepochs': 10, 'dir_output_results': '/content/drive/MyDrive/Research/NLP/results/', 'nrepetitions': 5, 'batch_size': 32, 'warm_up': 0.1, 'dataset': 'CogALexV', 'parameters_list': None, 'date': '11/25/22-11:32:46', 'raw_model': False}
11/25/22-11:32:46
{'ANT': {'precision': 0.9171597633136095, 'recall': 0.8611111111111112, 'f1-score': 0.8882521489971347, 'support': 360}, 'HYPER': {'precision': 0.7466307277628033, 'recall': 0.725130890052356, 'f1-score': 0.7357237715803452, 'support': 382}, 'PART_OF': {'precision': 0.7636363636363637, 'recall': 0.75, 'f1-score': 0.7567567567567568, 'support': 224}, 'RANDOM': {'precision': 0.9563962808592498, 'recall': 0.9751552795031055, 'f1-score': 0.9656846876011653, 'support': 3059}, 'SYN': {'precision': 0.6462264150943396, 'recall': 0.5829787234042553, 'f1-score': 0.6129753914988814, 'support': 235}, 'accuracy': 0.9096244131455399, 'macro avg': {'precision': 0.8060099101332732, 'recall': 0.7788752008141656, 'f1-score': 0.7918785512868567, 'support': 4260}, 'weighted avg': {'precision': 0.9070245138376645, 'recall': 0.9096244131455399, 'f1-score': 0.9080773343357689, 'support': 4260}}
